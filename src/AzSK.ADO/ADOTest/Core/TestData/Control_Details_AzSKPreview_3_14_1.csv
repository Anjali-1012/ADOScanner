"FeatureName","ControlID","Description","ControlSeverity","IsBaselineControl","IsPreviewBaselineControl","Rationale","Recommendation","Automated","SupportsAutoFix","Tags"
"RedisCache","Azure_RedisCache_AuthZ_Grant_Min_RBAC_Access","All users/identities must be granted minimum required permissions using Role Based Access Control (RBAC)","Moderate","No","No","Granting minimum access by leveraging RBAC feature ensures that users are granted just enough permissions to perform their tasks. This minimizes exposure of the resources in case of user/service account compromise.","Remove any excessive privileges granted on the Redis Cache. Assign 'Redis Cache Contributor' RBAC role to developers who manages Redis Cache configurations. Run command: Remove-AzRoleAssignment -SignInName '{signInName}' -Scope '{scope}' -RoleDefinitionName '{role definition name}'. Run 'Get-Help Remove-AzRoleAssignment -full' for more help. Refer: https://docs.microsoft.com/en-us/azure/active-directory/role-based-access-control-manage-access-powershell","Yes","No","SDL, TCP, Automated, AuthZ, RBAC, RedisCache"
"RedisCache","Azure_RedisCache_Audit_Enable_Diagnostics_Log","Diagnostics logs must be enabled with a retention period of at least 365 days.","Moderate","No","No","Logs should be retained for a long enough period so that activity trail can be recreated when investigations are required in the event of an incident or a compromise. A period of 1 year is typical for several compliance requirements as well.","You can change the diagnostic settings from the Azure Portal by following the steps given here: https://docs.microsoft.com/en-us/azure/monitoring-and-diagnostics/monitoring-archive-diagnostic-logs#archive-diagnostic-logs-using-the-portal","No","No","SDL, TCP, Manual, Audit, Diagnostics, RedisCache"
"RedisCache","Azure_RedisCache_AuthZ_Configure_IP_Range","Configure Redis Cache firewall settings for additional protection","Moderate","No","No","Using the firewall feature ensures that access to the data or the service is restricted to a specific set/group of clients. NOTE: While this control does provide an extra layer of access control protection, it may not always be feasible to implement in all scenarios.","Enable firewall and add rules specifying permitted IPs/ranges. Do not add IP range 0.0.0.0-255.255.255.255 as that allows access to all possible IPs. Refer: https://docs.microsoft.com/en-us/azure/redis-cache/cache-configure#firewall, (REST API) https://docs.microsoft.com/en-in/rest/api/redis/redisfirewallrule.  Note: In case the IP range is indeterminate (for instance, if the client is a PaaS endpoint), you may need to attest this control.","Yes","No","SDL, Best Practice, Automated, AuthZ, RedisCache"
"RedisCache","Azure_RedisCache_BCDR_Use_RDB_Backup","Redis Data Persistence should be enabled to back up Redis Cache data","Moderate","No","No","Enabling backup on Redis Cache ensures that there is always a previous snapshot of data that can be leveraged towards recovery scenarios.","Configure data persistence. Refer: https://docs.microsoft.com/en-us/azure/redis-cache/cache-configure#redis-data-persistence","Yes","No","SDL, Best Practice, Automated, BCDR, RedisCache"
"RedisCache","Azure_RedisCache_DP_Use_SSL_Port","Non-SSL port must not be enabled","Important","Yes","No","Use of HTTPS ensures server/service authentication and protects data in transit from network layer man-in-the-middle, eavesdropping, session-hijacking attacks.","To disable Non-SSL port for Redis Cache, run command : Set-AzRedisCache -ResourceGroupName <String> -Name <String> -EnableNonSslPort $false","Yes","Yes","SDL, TCP, Automated, DP, RedisCache"
"RedisCache","Azure_RedisCache_DP_Rotate_Keys","Access keys must be rotated periodically","Moderate","No","No","Periodic key/password rotation is a good security hygiene practice as, over time, it minimizes the likelihood of data loss/compromise which can arise from key theft/brute forcing/recovery attacks.","Rotate keys at regular intervals. To generate a new key, run command 'New-AzRedisCacheKey'. Run 'Get-Help New-AzRedisCacheKey -full' for more help.","No","No","SDL, TCP, Manual, DP, RedisCache"
"RedisCache","Azure_RedisCache_AuthN_Dont_Share_Cache_Instances","Do not share cache instances across applications","Important","No","No","There is no access control within a cache. If multiple applications share the same cache they will be able to freely access each others cached data which may lead to compromise.","Create a separate Redis Cache instance for each application. Refer: https://docs.microsoft.com/en-us/azure/redis-cache/cache-web-app-howto#configure-the-application-to-use-redis-cache","No","No","SDL, TCP, Manual, AuthN, RedisCache"
"RedisCache","Azure_RedisCache_NetSec_Configure_Virtual_Network_For_Domain_App","Redis Cache instance should be confined within a virtual network for domain-joined scenarios","Moderate","No","No","Azure Virtual Network (VNet) deployment provides enhanced security and isolation for Azure Redis Cache, as well as subnets, access control policies, and other features to further restrict access.","For steps to configure Azure Redis Cache on a Virtual Network, refer: https://docs.microsoft.com/en-us/azure/redis-cache/cache-how-to-premium-vnet","No","No","SDL, TCP, Manual, NetSec, RedisCache"
"StreamAnalytics","Azure_StreamAnalytics_AuthZ_Grant_Min_RBAC_Access","All users/identities must be granted minimum required permissions using Role Based Access Control (RBAC)","Moderate","No","No","Granting minimum access by leveraging RBAC feature ensures that users are granted just enough permissions to perform their tasks. This minimizes exposure of the resources in case of user/service account compromise.","Remove any excessive privileges granted on the Stream Analytics. Assign 'Log Analytics Contributor' RBAC role to developers who manages Stream Analytics configurations. Run command: Remove-AzRoleAssignment -SignInName '{signInName}' -Scope '{scope}' -RoleDefinitionName '{role definition name}'. Run 'Get-Help Remove-AzRoleAssignment -full' for more help. Refer: https://docs.microsoft.com/en-us/azure/active-directory/role-based-access-control-manage-access-powershell","Yes","No","SDL, TCP, Automated, AuthZ, RBAC, StreamAnalytics"
"StreamAnalytics","Azure_StreamAnalytics_Audit_Enable_Diagnostics_Log","Diagnostics logs must be enabled with a retention period of at least 365 days.","Moderate","No","No","Logs should be retained for a long enough period so that activity trail can be recreated when investigations are required in the event of an incident or a compromise. A period of 1 year is typical for several compliance requirements as well.","You can change the diagnostic settings from the Azure Portal by following the steps given here: https://docs.microsoft.com/en-us/azure/monitoring-and-diagnostics/monitoring-archive-diagnostic-logs#archive-diagnostic-logs-using-the-portal","Yes","No","SDL, TCP, Automated, Audit, Diagnostics, StreamAnalytics"
"StreamAnalytics","Azure_StreamAnalytics_BCDR_Backup_Job_Queries","Backup must be planned for Stream Analytics job queries.","Moderate","No","No","Stream Analytics does not offer features to cover backup/disaster recovery out-of-the-box. As a result, for critical Stream Analytics queries, a team must have adequate backups of the data.","Ensure the queries in the Stream Analytics Job has been backed up from a BC-DR standpoint.","No","No","SDL, TCP, Manual, BCDR, StreamAnalytics"
"StreamAnalytics","Azure_StreamAnalytics_Audit_Issue_Alert_Runtime_Errors_Failed_Functions","Alert rules must be configured for Runtime Errors and Failed Functions","Important","No","No","Using alert rules, one can ensure high availability of important/critical services by monitoring jobs and getting alerts for runtime errors and job failures.","To setup alert rule for 'Failed Function Requests' and 'Runtime Errors' events: (1) Go to Stream Analytics service -> 'Alerts' -> 'New alert rule' -> 'Add condition' (2) Select Signal type as 'Metrics' -> Select 'Failed Function Requests'/'Runtime Errors' -> Select a. Operator =  'Greater Than' b. Aggregation type = 'Total' c. Threshold value = '0' and d. Aggregation granularity = '5 minute' (3) Select an existing Action Group or create a new one of type 'Email/SMS/Push/Voice'. Select 'Email' option and specify the email id.","Yes","No","SDL, TCP, Automated, Audit, StreamAnalytics"
"StreamAnalytics","Azure_StreamAnalytics_BCDR_Configure_Paired_Region","Paired Regions should be configured for disaster recovery","Low","No","No","Paired namespaces help maintain consistent availability of a Stream Analytics based solution in case of an outage (e.g. throttling, storage issue, subsystem failure) in the primary region.","Critical jobs of Stream Analytics should be deployed to both paired regions. In addition to Stream Analytics internal monitoring capabilities, customers are also advised to monitor the jobs. If a break is identified to be a result of the Stream Analytics service update, escalate appropriately and fail over any downstream consumers to the healthy job output. Escalation to support will prevent the paired region from being affected by the new deployment and maintain the integrity of the paired jobs. Refer: https://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-job-reliability","No","No","SDL, Best Practice, Manual, BCDR, StreamAnalytics"
"AppService","Azure_AppService_AuthZ_Grant_Min_RBAC_Access","All users/identities must be granted minimum required permissions using Role Based Access Control (RBAC)","Moderate","No","No","Granting minimum access by leveraging RBAC feature ensures that users are granted just enough permissions to perform their tasks. This minimizes exposure of the resources in case of user/service account compromise.","Remove any excessive privileges granted on the App Service. Run command: Remove-AzRoleAssignment -SignInName '<SignInName>' -Scope '<Scope>' RoleDefinitionName '<RoleDefinitionName>'. Run 'Get-Help Remove-AzRoleAssignment -full' for more help.","Yes","No","SDL, TCP, Automated, AuthZ, RBAC, AppService, FunctionApp"
"AppService","Azure_AppService_DP_Use_CNAME_With_SSL","Custom domain with SSL binding must be configured for App Service","Moderate","No","No","Use of custom domain protects a web application from common attacks such as phishing, session hijacking and other DNS-related attacks.","Go to Azure Portal --> your App Service --> Settings --> Custom Domains and follow the steps mentioned to configure a custom domain. Run command 'New-AzWebAppSSLBinding' to enable the SSL binding for your custom domain. Run 'Get-Help New-AzWebAppSSLBinding -full' for more help.","Yes","No","SDL, TCP, Automated, DP, AppService, FunctionApp"
"AppService","Azure_AppService_AuthN_Use_AAD_for_Client_AuthN","App Service must authenticate users using Azure Active Directory backed credentials","Important","Yes","No","Using the native enterprise directory for authentication ensures that there is a built-in high level of assurance in the user identity established for subsequent access control.All Enterprise subscriptions are automatically associated with their enterprise directory (xxx.onmicrosoft.com) and users in the native directory are trusted for authentication to enterprise subscriptions.","Go to Azure Portal --> your App Service --> Settings --> Authentication/Authorization --> turn on 'App Service Authentication' --> Click on 'Azure Active Directory' under Authentication Providers to configure the AAD authentication. There will be a list of options to choose from under 'Action to take when request is not authenticated'. Please make sure that this value is not set to 'Allow Anonymous requests (no action)'. Note: If you are implementing this control via code, then you can attest to the same and mark this as passed. Note: In case of Functions apps, AAD authentication is required only for 'Http Trigger' functions.","Yes","No","SDL, TCP, Automated, AuthN, OwnerAccess, AppService, FunctionApp"
"AppService","Azure_AppService_Deploy_Dont_Use_Publish_Profiles","Publish profile credentials must not be used for App Service deployment","Important","No","No","Publish profile of App Services contains deployment and FTP credentials. There are 2 risks with this. First, the credentials can get easily leaked during the various workflows involving the publish profile. Secondly, use of public profiles weakens auditability of deployment actions.","No predefined role should be present in the App Service and all the custom roles must have all 'publishxml' operations added as the Non Actions, e.g. 'microsoft.web/sites/publishxml/read'. Refer https://docs.microsoft.com/en-us/azure/app-service/faq-deployment#i-am-just-getting-started-with-app-service-web-apps-how-do-i-publish-my-code for exploring ways to securely deploy app service.","No","No","SDL, TCP, Manual, Deploy, AppService, FunctionApp"
"AppService","Azure_AppService_AuthZ_Trigger_Url_AuthN","Trigger URL for the App Service Web Job must require authentication","Important","No","No","Scheduled WebJobs can be triggered by specific scheduled time or by triggered URL. WebJob triggered URL can be authenticated by AAD authentication (bearer token) or by App Services deployment credentials. Since its not recommended to use publish profiles, WebJob triggered URL must be authenticated by AAD authentication.","Use bearer tokens and AAD-based authentication to in the trigger.","No","No","SDL, Information, Manual, AuthZ, AppService, FunctionApp"
"AppService","Azure_AppService_DP_Encrypt_In_Transit_Webhook","The webhook used for a Web Job must encrypt sensitive data in transit","Important","No","No","Use of HTTPS ensures server/service authentication and protects data in transit from network layer man-in-the-middle, eavesdropping, session-hijacking attacks.","Encryption in transit in the context of webhooks can be achieved by using HTTPS URLs.","No","No","SDL, Information, Manual, DP, AppService, FunctionApp"
"AppService","Azure_AppService_DP_Store_Secrets_in_Key_Vault","All App Service secrets should be stored in Key Vault","Moderate","No","No","Keeping secrets such as DB connection strings, passwords, keys, etc. in clear text can lead to easy compromise at various avenues during an application's lifecycle. Storing them in a key vault ensures that they are protected at rest.","Refer https://azure.microsoft.com/en-in/documentation/articles/key-vault-get-started/ for configuring Key Vault and storing secrets.","No","No","SDL, Best Practice, Manual, DP, AppService, FunctionApp"
"AppService","Azure_AppService_Deploy_Use_Notification_Hub","App Service should use Notification Hub for push notification (instead of directly using Push Notification Service)","Moderate","No","No","Notification Hub provides a better mechanism to manage the keys related Push Notification Systems (PNS).","Refer https://docs.microsoft.com/en-us/azure/notification-hubs/ for details on configuring Notification Hub for push notifications.","No","No","SDL, Best Practice, Manual, Deploy, AppService, FunctionApp"
"AppService","Azure_AppService_Config_Disable_Remote_Debugging","Remote debugging must be turned off for App Service","Important","Yes","No","Remote debugging requires inbound ports to be opened on App Service. These ports become easy targets for compromise from various internet based attacks.","Go to Azure Portal --> your App Service --> Settings --> Application Settings --> Remote Debugging --> Click on 'OFF'.","Yes","No","SDL, TCP, Automated, Config, AppService, FunctionApp"
"AppService","Azure_AppService_Config_Disable_Web_Sockets","Web Sockets should be disabled for App Service","Important","No","Yes","WebSockets protocol (WS) is vulnerable to different types of security attacks. Usage of Web Sockets with in web applications has to be carefully reviewed.","Run command 'Set-AzWebApp -Name '<WebAppName>' -ResourceGroupName '<RGName>' -WebSocketsEnabled $false'. Run 'Get-Help Set-AzWebApp -full' for more help. Refer: https://github.com/OWASP/CheatSheetSeries/blob/master/cheatsheets/HTML5_Security_Cheat_Sheet.md#websockets","Yes","Yes","SDL, Best Practice, Automated, Config, AppService, FunctionApp"
"AppService","Azure_AppService_BCDR_Use_AlwaysOn","'Always On' should be configured for App Service","Moderate","No","No","By default, websites are unloaded if they have been idle for some period of time. However, this may not be ideal for 'high availability' requirements. Configuring 'Always On' can help prevent app services from getting timed out.","Go to Azure Portal --> your App Service --> Settings --> Application Settings --> Always On --> Click on 'ON'.","Yes","No","SDL, Best Practice, Automated, BCDR, AppService"
"AppService","Azure_AppService_Deploy_Use_Latest_Version","The latest version of .NET framework version should be used for App Service","Low","No","No","Running on older .Net versions could mean you are not using latest security classes. Usage of such old classes and types can make your application vulnerable.","Run command 'Set-AzWebApp -Name '<WebAppName>' -ResourceGroupName '<RGName>' -NetFrameworkVersion 'v4.7''. Run 'Get-Help Set-AzWebApp -full' for more help.","Yes","Yes","SDL, Best Practice, Automated, Deploy, AppService, FunctionApp"
"AppService","Azure_AppService_Deploy_Use_ARM_Template","Deployment of App Service should be done using ARM template","Moderate","No","No","Deployment using ARM template is more secure than using publish profiles. This is because the former uses user/SPN credentials which can be protected better than publish profiles and provide a better audit trail of deployment activity.","Use an ARM Template to ensure fully repeatable and secured configuration of a deployment. Refer https://azure.microsoft.com/en-gb/resources/templates/ to get sample quickstart templates.","No","No","SDL, Best Practice, Manual, Deploy, AppService, FunctionApp"
"AppService","Azure_AppService_BCDR_Use_Multiple_Instances","App Service must be deployed on a minimum of two instances to ensure availability","Moderate","No","No","App Service deployed on multiple instances ensures that the App Service remains available even if an instance is down.","Run command 'Set-AzAppServicePlan -Name '<AppServicePlanName>' -ResourceGroupName '<RGName>' -NumberofWorkers '<NumberofInstances>''. Run 'Get-Help Set-AzAppServicePlan -full' for more help.","Yes","Yes","SDL, TCP, Automated, BCDR, AppService"
"AppService","Azure_AppService_BCDR_Use_App_Backup","Backup feature must be configured to backup data for App Service","Moderate","No","No","Enabling backup on App Service ensures that there is always a previous snapshot of App Service data that can be leveraged towards recovery scenarios.","Run command 'Edit-AzWebAppBackupConfiguration -FrequencyInterval '1' -FrequencyUnit 'Day' -RetentionPeriodInDays '<0 or 365>' -StartTime '<TimeLessThanOrEqualToCurrentTime>' -Name '<WebAppName>' -ResourceGroupName '<RGName>' -StorageAccountUrl '<StorageAccountUrl>' -KeepAtLeastOneBackup'. Run 'Get-Help Edit-AzWebAppBackupConfiguration -full' for more help.","Yes","No","SDL, Best Practice, Automated, BCDR, OwnerAccess, AppService"
"AppService","Azure_AppService_Audit_Enable_Logging_and_Monitoring","Auditing and Monitoring must be enabled for App Service","Moderate","No","No","Auditing enables log collection of important system events pertinent to security. Regular monitoring of audit logs can help to detect any suspicious and malicious activity early and respond in a timely manner.","Run command 'Set-AzWebApp -Name '<WebAppName>' -ResourceGroupName '<RGName>' -DetailedErrorLoggingEnabled $true -HttpLoggingEnabled $true -RequestTracingEnabled $true'. Run 'Get-Help Set-AzWebApp -full' for more help.","Yes","Yes","SDL, TCP, Automated, Audit, AppService, FunctionApp"
"AppService","Azure_AppService_BCDR_Configure_Auto_Healing","Auto healing should be configured for App Service","Moderate","No","No","With the use of Auto-Healing, a website can automatically recover from long running/blocked states. Auto-Healing enables automatic recycling of the worker process hosting your web application based on certain events. E.g. 1. When request count breaches a certain limit 2. When requests are running slower that expected 3. When an unexpected http status code is received X number of times 4. When the process consumes more than expected memory","Refer https://azure.microsoft.com/en-in/blog/auto-healing-windows-azure-web-sites/ for details on configuring auto healing.","No","No","SDL, Best Practice, Manual, BCDR, AppService"
"AppService","Azure_AppService_DP_Dont_Allow_HTTP_Access","App Service must only be accessible over HTTPS","Important","Yes","No","Use of HTTPS ensures server/service authentication and protects data in transit from network layer eavesdropping attacks.","Run command 'Set-AzWebApp -Name '<WebAppName>' -ResourceGroupName '<RGName>' -HttpsOnly $true. Run 'Get-Help Set-AzWebApp -full' for more help.","Yes","Yes","SDL, TCP, Automated, DP, AppService, FunctionApp"
"AppService","Azure_AppService_DP_Website_Load_Certificates_Not_All","WEBSITE_LOAD_CERTIFICATES parameter must not be set to '*' (i.e. all) for App Service","Important","No","No","Using '*' for this parameter means that all certificates will get uploaded to the VM running the website. This will most likely lead to abuse of the principle of least privilege as it is unlikely that the site needs access to all certificates at runtime.","Go to Azure Portal --> your App Service --> Settings --> Application Settings --> App Settings --> Check for 'WEBSITE_LOAD_CERTIFICATES' key and make sure that value is not set to '*'. Instead choose the specific certificate that is required by the App Service. Refer https://msftplayground.com/2016/11/using-certificates-azure-app-services/ for more details.","Yes","No","SDL, TCP, Automated, DP, AppService, FunctionApp, OwnerAccess"
"AppService","Azure_AppService_DP_Configure_Rotate_Keys_Fn","Keys should be renewed after a regular interval","Moderate","No","No","Periodic key/password rotation is a good security hygiene practice as, over time, it minimizes the likelihood of data loss/compromise which can arise from key theft/brute forcing/recovery attacks.","Refer https://docs.microsoft.com/en-us/azure/azure-functions/functions-bindings-http-webhook#authorization-keys for details on Host keys in Functions app.","No","No","SDL, TCP, Manual, DP, FunctionApp"
"AppService","Azure_AppService_DP_Dont_Share_HostKeys_Fn","Host key access should not be shared with individual clients","Moderate","No","No","Host Keys grant full access to all the functions within a function app. Not sharing this key with individual clients ensures that clients are granted just enough permissions to invoke a particular function","Refer https://docs.microsoft.com/en-us/azure/azure-functions/functions-bindings-http-webhook#authorization-keys for details on Host keys in Functions app.","No","No","SDL, TCP, Manual, DP, FunctionApp"
"AppService","Azure_AppService_Authz_Use_Function_Authorization_level_Fn","Authorization level for HTTP Trigger function in a function app should be set to 'Function'","Moderate","No","No","Use 'Function' authorization level to ensure that users with minimum of function keys should only be able to invoke the function. This is in accordance with the principle of least privilege.","Go to Azure Portal --> your Functions App --> your HTTP Trigger Function --> Integrate --> Change Authorization level.","Yes","No","SDL, TCP, Automated, Config, AuthZ, OwnerAccess, FunctionApp"
"AppService","Azure_AppService_Configure_EditMode_ReadOnly_Fn","Functions app edit mode should be set to Read Only","Moderate","No","No","Using 'Read Only' mode ensures that source code is changes come in via a CICD pipeline and not directly through portal. This ensures that code changes are properly audited.","Go to Azure Portal --> your Functions App --> Functions app settings --> Function app edit mode --> Click on 'Read Only'.","Yes","No","SDL, TCP, Automated, Config, FunctionApp"
"AppService","Azure_AppService_DP_Use_Individual_FunctionKeys_Fn","Different functions keys must be generated and shared with individual clients.","Moderate","No","No","Different function keys for individual clients promotes separation of concerns. It also makes revocation easier to manage in the event of a compromise of one client.","Go to Azure Portal --> your Functions App --> your Function --> Manage --> Add New Function Key.","No","No","SDL, TCP, Manual, DP, FunctionApp"
"AppService","Azure_AppService_DP_Restrict_CORS_Access","Ensure that CORS access is granted to a limited set of trusted origins.","Moderate","No","No","CORS enables applications running under one domain to access a resource under another domain. Using '*' (allow all) for CORS setting means that an application running under any domain can have access to your application's resources and data. Restricting allowed origins to the specific set that needs access aligns with the principle of least privilege.","Go to Azure Portal --> your App Service --> API --> CORS --> Provide the specific domain names that should be allowed to make cross-origin calls. Note: No action is needed if you are not using CORS for your app.","Yes","No","SDL, TCP, Automated, DP, AppService, FunctionApp, OwnerAccess"
"AppService","Azure_AppService_Configure_Important_Alerts","Alerts should be configured to track unauthorized access attempts for the AppService.","Moderate","No","No","Alert rules for unauthorized requests enable you to detect any suspicious and malicious activity early enough.","Go to Azure Portal --> your App Service --> Monitoring --> Alerts --> Add Alert. Set alert on metrics with name 'Http 403'(unauthorized response) and 'Http 401'(forbidden response).","No","No","SDL, TCP, Config, AppService, Manual"
"AppService","Azure_AppService_AuthN_Use_Managed_Service_Identity","Use Managed Service Identity (MSI) for accessing other AAD-protected resources from the app service.","Moderate","No","No","Managed Service Identity (MSI) allows your app to easily access other AAD-protected resources such as Azure Key Vault. The identity is managed by the Azure platform and eliminates the need to provision/manage/rotate any secrets thus reducing the overall risk. ","Go to Azure Portal --> your App Service --> Settings --> Identity --> System assigned --> ON","Yes","No","SDL, TCP, Automated, Config, AppService, FunctionApp, OwnerAccess"
"AppService","Azure_AppService_DP_Dont_Allow_HTTP_Access_Fn","Function App must only be accessible over HTTPS","Important","No","Yes","Use of HTTPS ensures server/service authentication and protects data in transit from network layer eavesdropping attacks.","Run command 'Set-AzResource -ResourceName '<WebAppName>' -ResourceGroupName '<RGName>' -ResourceType 'Microsoft.Web/sites' -Properties @{httpsOnly='true'} -Force '. Run 'Get-Help Set-AzResource -full' for more help. Note:'HttpsOnly' is required only for 'Http Trigger' functions.","Yes","No","SDL, TCP, Automated, DP, OwnerAccess, FunctionApp"
"Automation","Azure_Automation_AuthZ_Grant_Min_RBAC_Access","All users/identities must be granted minimum required permissions using Role Based Access Control (RBAC)","Moderate","No","No","Granting minimum access by leveraging RBAC feature ensures that users are granted just enough permissions to perform their tasks. This minimizes exposure of the resources in case of user/service account compromise.","Remove any excessive privileges granted on the Automation account. Run command Remove-AzRoleAssignment -SignInName '{signInName}' -Scope '{scope}' -RoleDefinitionName '{role definition name}'. Run 'Get-Help Remove-AzRoleAssignment -full' for more help. Assign 'Automation Operator' RBAC role to members who need to start/stop/suspend/resume jobs. Refer: https://docs.microsoft.com/en-us/azure/automation/automation-role-based-access-control, https://docs.microsoft.com/en-us/azure/active-directory/role-based-access-control-manage-access-powershell","Yes","No","SDL, TCP, Automated, AuthZ, RBAC, Automation"
"Automation","Azure_Automation_DP_Review_Webhook_Usage","Webhooks should not be used for runbooks that perform highly sensitive functions","Moderate","No","No","If webhook URL is inadequately protected or gets compromised, the runbook can be triggered by unauthorized users.","Remove webhook(s) if not required. Run command Remove-AzAutomationWebhook -AutomationAccountName '{AutomationAccountName}' -Name '{WebhookName}' -ResourceGroupName '{ResourceGroupName}'","Yes","No","SDL, TCP, Automated, DP, Automation"
"Automation","Azure_Automation_DP_Minimal_Webhook_Validity","Webhook URL must have a shorter validity period (<= 60 days) to prevent malicious access","Moderate","No","No","If webhook URL gets compromised, runbook can be triggered by unauthorized users. Minimizing the validity period of the trigger URL ensures that the window of time available to an attacker in the event of compromise is minimized.","Change the webhook expiry date by navigating to Azure Portal --> Your Automation account --> Your runbook --> Webhooks --> Your webhook --> Edit 'Expiration' field --> Save","Yes","No","SDL, TCP, Automated, DP, Automation"
"Automation","Azure_Automation_DP_Use_Encrypted_Variables","Encryption of Automation account variable assets must be enabled when storing sensitive data","Important","No","Yes","Encrypted variables are stored securely by the Azure platform. Moreover, their values cannot be retrieved from the Get-AzAutomationVariable cmdlet that ships as part of the Azure PowerShell module.","Encrypt variable if it stores sensitive data. Create a new encrypted copy of each unencrypted variable in the automation account and delete the unencrypted variables later. Run command 'New-AzAutomationVariable -AutomationAccountName '{AutomationAccountName}' -Name '{VariableName}' -Encrypted $true -Value '{Value} -ResourceGroupName '{ResourceGroupName}' and 'Remove-AzAutomationVariable -AutomationAccountName '{AutomationAccountName}' -Name '{VariableName}' -ResourceGroupName '{ResourceGroupName}'","Yes","No","SDL, TCP, Automated, DP, Automation"
"Automation","Azure_Automation_DP_Use_Secure_Assets","Never hard-code secure information in your runbook, instead use Automation account assets (Credentials, encrypted variables etc.)","Important","No","No","Automation account assets are encrypted and stored in the Azure Automation using a unique key that is generated for each automation account.","For detailed information about assets refer: https://docs.microsoft.com/en-us/azure/automation/automation-certificates, https://docs.microsoft.com/en-us/azure/automation/automation-connections, https://docs.microsoft.com/en-us/azure/automation/automation-credentials, https://docs.microsoft.com/en-us/azure/automation/automation-variables","No","No","SDL, TCP, DP, Manual, Automation"
"Automation","Azure_Automation_DP_Rotate_Account_Keys","Automation account keys should be rotated periodically as per the company standards","Moderate","No","No","Periodic key/password rotation is a good security hygiene practice as, over time, it minimizes the likelihood of data loss/compromise which can arise from key theft/brute forcing/recovery attacks.","Run command New-AzAutomationKey -AutomationAccountName '{AutomationAccountName}' -KeyType '{Primary/Secondary}' -ResourceGroupName '{ResourceGroupName}' to rotate keys","No","No","SDL, TCP, DP, Best Practice, Manual, Automation"
"Automation","Azure_Automation_DP_Rotate_RunAsAccount_Credentials","Credentials for Run As Account should be deleted and recreated at regular intervals to make sure that Service Principal connection credentials are not compromised","Moderate","No","No","Periodic key/password rotation is a good security hygiene practice as, over time, it minimizes the likelihood of data loss/compromise which can arise from key theft/brute forcing/recovery attacks.","Remove existing certificate and connection using command Remove-AzAutomationCertificate and Remove-AzAutomationConnection. Create new certificate and connection using commands New-AzAutomationCertificate and New-AzAutomationConnection. Refer : https://docs.microsoft.com/en-us/azure/automation/automation-create-runas-account","No","No","SDL, Best Practice, Manual, DP, Automation"
"Automation","Azure_Automation_DP_Automation_Asset_Protection","Automation accounts for which Hybrid Runbook Worker feature is enabled must only include assets required for the hybrid runbook functioning.","Moderate","No","No","Hybrid worker machines running the MMA (Microsoft Monitoring Agent) have unrestricted access to all assets in the Automation. Limiting these assets to only those required for the hybrid worker functioning eliminates the likelihood of compromise of a broader set of assets.","Create dedicated Automation account for Hybrid Worker Groups","No","No","SDL, TCP, Manual, DP, Automation"
"Automation","Azure_Automation_AuthN_Dedicated_SP_For_Runbook","Runbook authentication must be done using dedicated service principal instead of AD User account ","Moderate","No","No","Using a 'user' account should be avoided because, in general, a user account will likely have broader set of privileges to enterprise assets. Using a dedicated SPN ensures that the SPN does not have permissions beyond the ones specifically granted for the automation job to function.","Refer : https://docs.microsoft.com/en-us/azure/automation/automation-create-runas-account","No","No","SDL, Manual, TCP, AuthN, Automation"
"Automation","Azure_Automation_Audit_Configure_Log_Analytics","Configure Log Analytics to get greater operational visibility of your Automation jobs","Moderate","No","No","Using Log Analytics, one can ensure high availability of important/critical services by monitoring jobs and getting alerts for job failures.","You can change the diagnostic settings from the Azure Portal by following the steps given here: https://docs.microsoft.com/en-us/azure/monitoring-and-diagnostics/monitoring-archive-diagnostic-logs#archive-diagnostic-logs-using-the-portal","Yes","No","SDL, Best Practice, Audit, Manual, Automation"
"APIConnection","Azure_APIConnection_AuthN_Connectors_Use_AAD","Logic App connectors must use AAD-based authentication wherever possible","Important","No","No","Using the native enterprise directory for authentication ensures that there is a built-in high level of assurance in the user identity established for subsequent access control. All Enterprise subscriptions are automatically associated with their enterprise directory (xxx.onmicrosoft.com) and users in the native directory are trusted for authentication to enterprise subscriptions.","For HTTP based connectors, refer: https://docs.microsoft.com/en-us/azure/connectors/connectors-native-http#azure-active-directory-oauth-authentication. For other connectors you must manually verify that AAD authentication is used for connectors that support it.","Yes","No","SDL, TCP, Automated, AuthN"
"APIConnection","Azure_APIConnection_DP_Encrypt_Data_In_Transit","Data transit across connectors must use encrypted channel","Important","No","No","Use of HTTPS ensures server/service authentication and protects data in transit from network layer man-in-the-middle, eavesdropping, session-hijacking attacks.","Use HTTPS URI in HTTP-based connectors. For connectors which are HTTP-based, use HTTPS URLs. For other connectors you must manually verify that encrypted connections are used by the connector protocol.","Yes","No","SDL, TCP, Automated, DP"
"APIManagement","Azure_APIManagement_AuthZ_Grant_Min_RBAC_Access","All users/identities must be granted minimum required permissions using Role Based Access Control (RBAC)","Moderate","No","No","Granting minimum access by leveraging RBAC feature ensures that users are granted just enough permissions to perform their tasks. This minimizes exposure of the resources in case of user/service account compromise.","Remove any excessive privileges granted on the API Management Service. Run command: Remove-AzRoleAssignment -SignInName '<SignInName>' -Scope '<Scope>' -RoleDefinitionName '<RoleDefinitionName>'. Run 'Get-Help Remove-AzRoleAssignment -full' for more help.","Yes","No","SDL, TCP, Automated, AuthZ, RBAC, DeveloperSku, BasicSku, StandardSku, PremiumSku, APIManagement"
"APIManagement","Azure_APIManagement_Audit_Enable_Alerts","Metric alert rules must be configured for critical actions on API Management service","Moderate","No","No","Metric alert for occurrence of unauthorized gateway requests help the admin to identify security breach attempts.","To setup an alert rule: (1) Go to API management instance -> 'Alerts' -> 'New alert rule' -> 'Add condition' (2) Select Signal type as 'Metrics' -> Select 'Unauthorized Gateway Request' -> Select a. Operator = 'Greater Than' b. Aggregation type = 'Total' c. Threshold value = '0' and d. Aggregation granularity = '1 hour' (3) Select an existing Action Group or create a new one of type 'Email/SMS/Push/Voice'. Select 'Email' option and specify the email id. Please refer: https://docs.microsoft.com/en-us/azure/api-management/api-management-howto-use-azure-monitor#set-up-an-alert-rule-for-unauthorized-request.","Yes","No","SDL, TCP, Automated, Audit, DeveloperSku, BasicSku, StandardSku, PremiumSku, APIManagement"
"APIManagement","Azure_APIManagement_Audit_Enable_Diagnostics_Log","Diagnostics logs must be enabled with a retention period of at least 365 days","Moderate","No","No","Logs should be retained for a long enough period so that activity trail can be recreated when investigations are required in the event of an incident or a compromise. A period of 1 year is typical for several compliance requirements as well.","Run command: Set-AzDiagnosticSetting -ResourceId {'ResourceId'} -Enabled $true -StorageAccountId '{StorageAccountId}' -RetentionInDays 365 -RetentionEnabled $true. Alternatively, you can also change the diagnostic settings from the Azure Portal by following the steps given here: https://docs.microsoft.com/en-us/azure/monitoring-and-diagnostics/monitoring-archive-diagnostic-logs#archive-diagnostic-logs-using-the-portal.","Yes","No","SDL, TCP, Diagnostics, Automated, Audit, DeveloperSku, BasicSku, StandardSku, PremiumSku, APIManagement"
"APIManagement","Azure_APIManagement_DP_Use_HTTPS_URL_Scheme","Backend API(s) must be accessible only over HTTPS via API Management service","Important","No","Yes","Use of HTTPS ensures server/service authentication and protects data in transit from network layer eavesdropping attacks.","Run command: Set-AzApiManagementApi -Context {APIContextObject} -Protocols 'Https' -Name '{APIName}' -ApiId '{APIId}' -ServiceUrl '{ServiceURL}'. Run command : Get-AzApiManagementApi -Context '{APIContextObject}' to get the details of existing APIs. Refer https://docs.microsoft.com/en-us/powershell/module/az.apimanagement/set-azapimanagementapi","Yes","No","SDL, TCP, Automated, DP, DeveloperSku, BasicSku, StandardSku, PremiumSku, APIManagement, APIMAPIs"
"APIManagement","Azure_APIManagement_BCDR_Backup_Periodically","API Management service instance should be backed up periodically","Moderate","No","No","The service 'backup and restore' feature provides facility to recover from availability problems affecting the region where your API Management service is hosted.","Use REST APIs for 'backup and restore' operations. Refer https://docs.microsoft.com/en-us/azure/api-management/api-management-howto-disaster-recovery-backup-restore.","No","No","SDL, TCP, BCDR, DeveloperSku, BasicSku, StandardSku, PremiumSku, APIManagement"
"APIManagement","Azure_APIManagement_DP_Encrypt_Named_Values","'Named Values' that contain sensitive data must be encrypted by marking as 'secret'","Important","No","No","Encrypted 'Named Values' are stored securely by the Azure platform.","Run command: Set-AzApiManagementProperty -Secret $true -Context {APIContextObject} -Name '{PropertyDisplayName}' -PropertyId '{PropertyId}'. Refer https://docs.microsoft.com/en-us/azure/api-management/api-management-howto-properties. Example: https://docs.microsoft.com/en-us/azure/api-management/api-management-advanced-policies#example-11","Yes","No","SDL, TCP, Automated, DP, DeveloperSku, BasicSku, StandardSku, PremiumSku, APIManagement"
"APIManagement","Azure_APIManagement_DP_Use_Secure_TLS_Version","Ensure that only the most secure and up to date version of TLS is enabled on the API gateway","Important","No","No","TLS 1.2 is the latest and most secure protocol. Using 3DES Ciphers, TLS protocols (1.1 and 1.0) and SSL 3.0 exposes the API to meet-in-the-middle attack, chosen-plaintext or known-plaintext attacks.","Ensure that secure protocol versions are used between the client and the gateway *and* between the gateway and the backend APIs. Go to Azure Portal --> your API management instance --> Settings --> Protocol settings --> Turn OFF 3DES Ciphers, TLS protocols (1.1 and 1.0) and SSL 3.0 Protocols.","No","No","SDL, TCP, Manual, DP, DeveloperSku, BasicSku, StandardSku, PremiumSku, APIManagement"
"APIManagement","Azure_APIManagement_DP_Remove_Default_Products","Delete the two sample products 'Starter' and 'Unlimited' to avoid accidental exposure of APIs","Moderate","No","No","By default, each API Management instance comes with two sample products: Starter and Unlimited. Unless the access control of these sample products is being strictly regulated, associating APIs to these products stands the chance of exposing APIs to unauthenticated users.","To delete sample products go to Azure Portal --> your API management instance --> Products --> Select 'Starter'/'Unlimited' Product --> Delete.","Yes","No","SDL, TCP, Automated, DP, DeveloperSku, BasicSku, StandardSku, PremiumSku, APIManagement, APIMProducts"
"APIManagement","Azure_APIManagement_DP_Dont_Log_Sensitive_Header_Data","Any header containing sensitive data such as authorization token should not be logged in Application Insights","Moderate","No","No","APIM provides an option to log request and response headers in Application Insights. Any header containing sensitive data such as authorization token should not be logged. This minimizes the risk of data loss from physical theft and also helps meet regulatory compliance requirements.","Do not explicitly add header containing sensitive data while integrating Azure API Management with Azure Application Insights. Note: By default headers data is not logged. Please refer https://docs.microsoft.com/en-us/azure/api-management/api-management-howto-app-insights.","Yes","No","SDL, TCP, Automated, DP, DeveloperSku, BasicSku, StandardSku, PremiumSku, APIManagement, APIMAPIs"
"APIManagement","Azure_APIManagement_DP_Restrict_CORS_Access","Ensure that CORS access is granted to a minimal set of trusted origins and only required verbs are supported","Moderate","No","No","CORS enables an operation or an API to allow cross-domain calls from browser-based clients. Using '*' (allow all) for CORS setting means that all cross-origin requests are allowed. Restricting allowed origins to the specific set that needs access aligns with the principle of least privilege.","For steps to add CORS policy to API's inbound policies please refer https://docs.microsoft.com/en-us/azure/api-management/api-management-cross-domain-policies#CORS. Note: No action is needed if you are not using CORS for your service.","Yes","No","SDL, TCP, Automated, DP, DeveloperSku, BasicSku, StandardSku, PremiumSku, APIManagement, APIMAPIs"
"APIManagement","Azure_APIManagement_AuthN_Verify_Delegated_Authentication","If delegated authentication is enabled, ensure that it is implemented securely","Important","No","Yes","Delegation allows you to use your existing website for handling developer sign-in/sign-up and subscription to products as opposed to using the built-in functionality in the developer portal. It is the API publisher's responsibility to ensure protection of user data.","If Delegation is enabled, APIM Publisher must take the responsibility of secure sign-in/sign-up, subscription to products and management of user data.","Yes","No","SDL, TCP, Automated, AuthN, DeveloperSku, BasicSku, StandardSku, PremiumSku, APIManagement"
"APIManagement","Azure_APIManagement_NetSec_Configure_Virtual_Network_For_APIM","Consider hosting APIM within a virtual network for improved isolation","Moderate","No","No","Azure Virtual Network (VNet) deployment provides enhanced security and isolation for API management instance, as well as backend service, access control policies, and other features to further restrict access.","Where feasible/practical, host the APIM and APIs within an isolated network. For steps to deploy Azure API Management inside a Virtual Network, refer: https://docs.microsoft.com/en-us/azure/api-management/api-management-using-with-vnet.","Yes","No","SDL, TCP, Automated, NetSec, PremiumSku, DeveloperSku, APIManagement"
"APIManagement","Azure_APIManagement_DP_Use_Custom_Domain_With_SSL","Custom domain with SSL binding must be configured for Proxy and Portal endpoints of Azure API Management instance","Moderate","No","No","Use of custom domain protects a backend service from common attacks such as phishing, session hijacking and other DNS-related attacks.","Go to Azure Portal --> your API management instance --> Settings --> Custom Domains and configure a custom domain for Proxy and Portal endpoint. Please refer: https://docs.microsoft.com/en-us/azure/api-management/configure-custom-domain. To configure custom domain using PowerShell please refer : https://docs.microsoft.com/en-us/azure/api-management/scripts/powershell-setup-custom-domain","No","No","SDL, TCP, Manual, DP, DeveloperSku, BasicSku, StandardSku, PremiumSku, APIManagement"
"APIManagement","Azure_APIManagement_AuthZ_Validate_JWT","Ensure that JWT validation is enabled if using OAuth 2.0 or OpenID connect","Important","No","No","If 'validate-jwt' policy is not configured, client can call the API without the OAuth/OpenID connect authorization token. This policy enforces existence and validity of a JWT extracted from either a specified HTTP Header or a specified query parameter.","For steps to add JWT Validate Token policy please refer: https://docs.microsoft.com/en-us/azure/api-management/api-management-access-restriction-policies#ValidateJWT and https://docs.microsoft.com/en-us/azure/api-management/api-management-howto-protect-backend-with-aad#configure-a-jwt-validation-policy-to-pre-authorize-requests","Yes","No","SDL, TCP, Automated, AuthZ, DeveloperSku, BasicSku, StandardSku, PremiumSku, APIManagement, APIMAPIs"
"APIManagement","Azure_APIManagement_AuthZ_Restrict_Caller_IPs","Use Restrict caller IPs policies for additional protection","Moderate","No","No","Using the IP filter policy feature ensures that access to the backend service is restricted to a specific set/group of clients. NOTE: While this control does provide an extra layer of access control protection, it may not always be feasible to implement in all scenarios.","Use 'ip-filter' policy filters to allow and deny calls from specific IP addresses and/or address ranges. Do not add IP range 0.0.0.0-255.255.255.255 as that allows access to all possible IPs. Please refer: https://docs.microsoft.com/en-us/azure/api-management/api-management-access-restriction-policies#RestrictCallerIPs","Yes","No","SDL, TCP, Automated, AuthZ, DeveloperSku, BasicSku, StandardSku, PremiumSku, APIManagement"
"APIManagement","Azure_APIManagement_AuthN_Disable_Management_API","Do not use API Management REST API","Important","No","Yes","The credentials used to access API Management REST API provide admin-level access without support for role-based access control and without recording audit logs. For better security it is recommended to make calls through the ARM-based REST API","Disable API Management REST API and use the ARM-based REST API instead. Run command: Set-AzApiManagementTenantAccess -Context {APIContextObject} -Enabled $false. To disable 'Enable API Management REST API' manually go to Azure Portal --> your API management instance --> Management API --> Uncheck 'Enable API Management REST API'. Use ARM based REST API mentioned in https://docs.microsoft.com/en-us/rest/api/apimanagement.","Yes","No","SDL, TCP, Automated, AuthN, DeveloperSku, BasicSku, StandardSku, PremiumSku, APIManagement"
"APIManagement","Azure_APIManagement_AuthZ_Enable_User_Authorization_For_API","Ensure that either OAuth 2.0 or OpenID Connect are used to authorize developer accounts in API Management","Important","No","No","Enabling OAuth/OpenID connect user authorization ensure that only valid users have access, and they can only access resources to which they are entitled.","To enable user authorization for an API go to Azure Portal --> your API management instance --> APIs --> Select API --> Settings -> User Authorization -> Enable 'OAuth 2.0' or 'OpenID connect'. Please refer https://docs.microsoft.com/en-us/azure/api-management/api-management-howto-oauth2.","Yes","No","SDL, TCP, Automated, AuthZ, APIManagement, DeveloperSku, BasicSku, StandardSku, PremiumSku, APIMAPIs"
"APIManagement","Azure_APIManagement_AuthN_Use_AAD_for_Client_AuthN","Enterprise applications using APIM must authenticate developers/applications using Azure Active Directory backed credentials","Important","No","Yes","Using the native enterprise directory for authentication ensures that there is a built-in high level of assurance in the user identity established for subsequent access control. All Enterprise subscriptions are automatically associated with their enterprise directory (xxx.onmicrosoft.com) and users in the native directory are trusted for authentication to enterprise subscriptions.","Authorize developer accounts by using Azure Active Directory in Azure API Management. For step please refer https://docs.microsoft.com/en-us/azure/api-management/api-management-howto-aad.","Yes","No","SDL, TCP, Automated, AuthN, DeveloperSku, StandardSku, PremiumSku, APIManagement"
"APIManagement","Azure_APIManagement_DP_Dont_Reveal_Backend_Info","Use transform policies to hide backend/implentation details in API responses","Moderate","No","No","Information such as technology stack that is running on the backend and the original URLs that appear in the body of API's HTTP response are private backend info and should be hidden from external customers.","Verify that your API's response does not reveal private backend information. To hide private information from client refer: https://docs.microsoft.com/en-us/azure/api-management/transform-api.","No","No","SDL, TCP, Manual, DP, DeveloperSku, BasicSku, StandardSku, PremiumSku, APIManagement"
"APIManagement","Azure_APIManagement_DP_Dont_Checkin_Secrets_In_Source","Do not include secrets directly in API configuration and policies","Important","No","Yes","When using Git to save and configure your API Management service configuration, any secrets that are not defined as properties will be stored in the repository and will remain in its history until you disable and re-enable Git access. Properties (Named values) provide a secure place to manage constant string values, including secrets, across all API configuration and policies, so you don't have to store them directly in your policy statements.","Refer: https://docs.microsoft.com/en-us/azure/api-management/api-management-configuration-repository-git.","Yes","No","SDL, TCP, Automated, DP, DeveloperSku, BasicSku, StandardSku, PremiumSku, APIManagement"
"APIManagement","Azure_APIManagement_AuthN_Secure_API_Using_Client_Certificates","Use client certificates for authentication between gateway and backend APIs","Important","No","No","Use client certificates to secure access to the back-end service of an API and protects data in transit from network layer man-in-the-middle, eavesdropping, session-hijacking attacks.","To enable client certificate authentication from Azure portal please refer https://docs.microsoft.com/en-us/azure/api-management/api-management-howto-mutual-certificates and https://docs.microsoft.com/en-us/azure/api-management/api-management-authentication-policies.","Yes","No","SDL, TCP, Automated, AuthN, APIManagement, DeveloperSku, BasicSku, StandardSku, PremiumSku, APIMAPIs"
"APIManagement","Azure_APIManagement_AuthZ_Enable_Requires_Subscription","'Requires Subscription' option must be turned on for all products in an API Management instance","Important","No","No","When publishing APIs through Azure API Management (APIM), the easiest and most common way to secure access to the APIs is by using Subscription Keys. To obtain a Subscription Key for accessing APIs, a Subscription is required. This ensures that a Client applications that need to consume the published APIs must subscribe before making calls to those APIs.","To enable 'Requires Subscription' go to Azure Portal --> your API management instance --> Products --> Settings --> 'Requires Subscription'. Refer: https://docs.microsoft.com/en-us/azure/api-management/api-management-subscriptions. To create subscription for a user directly from Azure portal refer https://docs.microsoft.com/en-us/azure/api-management/api-management-howto-create-subscriptions","Yes","No","SDL, TCP, Automated, AuthZ, DeveloperSku, BasicSku, StandardSku, PremiumSku, APIManagement, APIMProducts"
"APIManagement","Azure_APIManagement_DP_Restrict_Critical_APIs_Access","Critical APIs must not be exposed to Guest users","Moderate","No","No","Guest users or unauthenticated developer portal users, such as prospective customers visiting the developer portal of an API Management instance can be granted certain read-only access, such as the ability to view APIs but not call them.","Do not associate Guest groups with products containing critical APIs. To verify access go to Azure Portal --> your API management instance --> Products --> Access Control","Yes","No","SDL, TCP, Automated, DP, DeveloperSku, BasicSku, StandardSku, PremiumSku, APIManagement, APIMProducts"
"APIManagement","Azure_APIManagement_AuthN_Use_Managed_Service_Identity","Use Managed Service Identity (MSI) for accessing other AAD-protected resources from the API management instance","Moderate","No","No","Managed Service Identity (MSI) allows your API Management instance to easily access other AAD-protected resources, such as Azure Key Vault. The identity is managed by the Azure platform and eliminates the need to provision/manage/rotate any secrets thus reducing the overall risk.","Go to Azure Portal --> your API management instance --> Settings --> Managed Service Identity --> Register with AAD --> ON","Yes","No","SDL, TCP, Automated, AuthN, DeveloperSku, BasicSku, StandardSku, PremiumSku, APIManagement"
"APIManagement","Azure_APIManagement_AuthZ_Enable_Requires_Approval","Use the 'Requires Approval' option for APIs where additional checks/manual review is necessary","Important","No","No","Enabling 'Requires Approval' ensures that only users approved by API publisher can subscribe to a product.","To enable 'Requires Approval' go to Azure Portal --> your API management instance --> Products --> Settings --> Select 'Requires Approval'. Refer: https://docs.microsoft.com/en-us/azure/api-management/api-management-subscriptions.","No","No","SDL, TCP, Manual, AuthZ, DeveloperSku, BasicSku, StandardSku, PremiumSku, APIManagement, APIMProducts"
"HDInsight","Azure_HDInsight_Deploy_Supported_Cluster_Version","HDInsight must have supported HDI cluster version","Important","No","Yes","Being on the latest/supported HDInsight version significantly reduces risks from security bugs or updates that may be present in older or retired cluster versions.","Refer: https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-component-versioning?#supported-hdinsight-versions https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-upgrade-cluster","Yes","No","SDL, TCP, Manual, SI, HDInsight"
"HDInsight","Azure_HDInsight_AuthN_Use_SSH_Keys_For_Login","Use Public-Private key pair together with a passcode for SSH login","Important","No","No","Public-Private key pair help to protect against password guessing and brute force attacks","Refer: https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-hadoop-linux-use-ssh-unix","No","No","SDL, TCP, Manual, SI, HDInsight"
"HDInsight","Azure_HDInsight_AuthZ_Restrict_Cluster_Network_Access","HDInsight cluster access must be restricted using virtual network or Azure VPN gateway service with NSG traffic rules","Important","No","No","Restricting cluster access with inbound and outbound traffic via NSGs limits the network exposure for cluster and reduces the attack surface.","You should restrict IP range and port as per application needs. Refer: https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-extend-hadoop-virtual-network. Note: In case the IP range is indeterminate (for instance, if the client is a PaaS endpoint), you may need to attest this control.","Yes","No","SDL, TCP, Manual, AuthZ, HDInsight"
"HDInsight","Azure_HDInsight_DP_Storage_Encrypt_In_Transit","Secure transfer protocol must be used for accessing storage account resources","Important","No","No","Use of secure transfer ensures server/service authentication and protects data in transit from network layer man-in-the-middle, eavesdropping, session-hijacking attacks. When enabling HTTPS one must remember to simultaneously disable access over plain HTTP else data can still be subject to compromise over clear text connections.","https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-hadoop-create-linux-clusters-with-secure-transfer-storage?toc=%2Fen-us%2Fazure%2Fhdinsight%2Fstorm%2FTOC.json&bc=%2Fen-us%2Fazure%2Fbread%2Ftoc.json","No","No","SDL, TCP, Manual, DP, HDInsight"
"HDInsight","Azure_HDInsight_DP_Storage_Encrypt_At_Rest","Storage used for cluster must have encryption at rest enabled","Important","No","No","Using this feature ensures that sensitive data is stored encrypted at rest. This minimizes the risk of data loss from physical theft and also helps meet regulatory compliance requirements.","https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-hadoop-create-linux-clusters-with-secure-transfer-storage?toc=%2Fen-us%2Fazure%2Fhdinsight%2Fstorm%2FTOC.json&bc=%2Fen-us%2Fazure%2Fbread%2Ftoc.json","No","No","SDL, TCP, Manual, DP, HDInsight"
"HDInsight","Azure_HDInsight_DP_Dont_Store_Data_On_Cluster_Nodes","Sensitive data must be stored on storage linked to cluster and not on cluster node disks","Important","No","No","Cluster node restart may cause loss of data present on cluster nodes. Also currently HDInsight does not support encryption at rest for cluster node disk.","All data must be stored on storage linked with HDInsight cluster","No","No","SDL, TCP, Manual, DP, HDInsight"
"HDInsight","Azure_HDInsight_AuthZ_Restrict_Network_Access_To_Cluster_Storage","Access to cluster's storage must be restricted to virtual network of the cluster","Moderate","No","No","Restricting storage access within cluster network boundary reduces the attack surface.","Refer: https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-hadoop-linux-use-ssh-unix","No","No","SDL, TCP, Manual, AuthZ, HDInsight"
"HDInsight","Azure_HDInsight_AuthZ_Grant_Min_RBAC_Access_For_Cluster_Operations","All users/identities must be granted minimum required cluster operation permissions using Ambari Role Based Access Control (RBAC)","Moderate","No","No","Granting minimum access by leveraging RBAC feature ensures that users are granted just enough permissions to perform their tasks. This minimizes exposure of the resources in case of user/service account compromise.","Refer: https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-authorize-users-to-Ambari#assign-users-to-roles","No","No","SDL, TCP, Manual, AuthZ, RBAC, HDInsight"
"HDInsight","Azure_HDInsight_AuthZ_Restrict_Access_To_Ambari_Views","Only required users/identities must be granted access to Ambari views","Moderate","No","No","Granting access to only required users to Ambari views ensures minimum exposure of underline data resources.","Refer: https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-authorize-users-to-Ambari#grant-permissions-to-hive-views","No","No","SDL, TCP, Manual, AuthZ, RBAC, HDinsight"
"HDInsight","Azure_HDInsight_DP_Rotate_Admin_Password","Ambari admin password must be renewed after a regular interval","Moderate","No","No","Periodic key/password rotation is a good security hygiene practice as, over time, it minimizes the likelihood of data loss/compromise which can arise from key theft/brute forcing/recovery attacks.","Refer: https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-administer-use-portal-linux#change-passwords","No","No","SDL, TCP, Manual, DP, HDinsight"
"HDInsight","Azure_HDInsight_Audit_Use_Diagnostics_Log","Diagnostics must be enabled for cluster operations","Moderate","No","No","Diagnostics logs are needed for creating activity trail while investigating an incident or a compromise.","Refer: https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-hadoop-linux-use-ssh-unix","No","No","SDL, TCP, Manual, Audit, HDInsight"
"HDInsight","Azure_HDInsight_DP_No_PlainText_Secrets_In_Notebooks","Secrets and keys must not be in plain text in notebooks and jobs","Moderate","No","No","Keeping secrets such as connection strings, passwords, keys, etc. in clear text can lead to easy compromise. Storing them in a secure place (like KeyVault) ensures that they are protected at rest.","Use a key vault backed secret scopes to store any secrets and keys and read them from the respective secret scopes in notebooks and jobs.","No","No","SDL, TCP, Manual, Audit, HDInsight"
"AnalysisServices","Azure_AnalysisServices_AuthZ_Grant_Min_RBAC_Access","All users/identities must be granted minimum required permissions using Role Based Access Control (RBAC)","Moderate","No","No","Granting minimum access by leveraging RBAC feature ensures that users are granted just enough permissions to perform their tasks. This minimizes exposure of the resources in case of user/service account compromise.","Remove any excessive privileges granted on the Analysis Service. Run command Remove-AzRoleAssignment -SignInName '{signInName}' -Scope '{scope}' -RoleDefinitionName '{role definition name}'. Run 'Get-Help Remove-AzRoleAssignment -full' for more help. Refer: https://docs.microsoft.com/en-us/sql/analysis-services/multidimensional-models/roles-and-permissions-analysis-services, https://docs.microsoft.com/en-us/azure/analysis-services/analysis-services-manage-users, https://docs.microsoft.com/en-us/azure/active-directory/role-based-access-control-manage-access-powershell","Yes","No","SDL, TCP, Automated, AuthZ, RBAC, AnalysisServices"
"AnalysisServices","Azure_AnalysisServices_AuthZ_Min_Admin","Minimize the number of Analysis Service admins","Moderate","No","No","Analysis Service admins have full access on the server to perform any operation. Each additional person in the admin role increases the attack surface for the server. The number of members in these roles should be kept to as low as possible.","Minimize the number of Analysis Service admins. Run command Set-AzAnalysisServicesServer -Name '{AnalysisServicesServerName}' -ResourceGroupName '{ResourceGroupName}' -Administrator '{Administrator}'. Refer: https://docs.microsoft.com/en-us/powershell/module/az.analysisservices/Set-AzAnalysisServicesServer","Yes","No","SDL, Best Practice, Automated, AuthZ, AnalysisServices"
"AnalysisServices","Azure_AnalysisServices_AuthZ_Users_Min_DB_Permission","Database users must be added to database roles with minimum required permission","Moderate","No","No","Granting minimum access ensures that users are granted just enough permissions to perform their tasks. This minimizes permission of operations at the Analysis Server in case of user account compromise.","Make sure that users are granted the least required privileges to databases and tabular models. Refer: https://docs.microsoft.com/en-us/azure/analysis-services/analysis-services-manage-users, https://docs.microsoft.com/en-us/sql/analysis-services/tabular-models/create-and-manage-roles-ssas-tabular","No","No","SDL, TCP, Manual, AuthZ, AnalysisServices"
"AnalysisServices","Azure_AnalysisServices_AuthN_Analysis_Service_Clients","Analysis Service clients should authenticate users using Azure Active Directory backed credentials","Important","No","No","Using the native enterprise directory for authentication ensures that there is a built-in high level of assurance in the user identity established for subsequent access control.All Enterprise subscriptions are automatically associated with their enterprise directory (xxx.onmicrosoft.com) and users in the native directory are trusted for authentication to enterprise subscriptions.","Analysis Services clients such as 'Power BI', 'Excel' or any BI Tools should authenticate users using Azure Active Directory backed credentials. Refer: (Power BI) https://docs.microsoft.com/en-us/azure/power-bi-embedded/power-bi-embedded-app-token-flow and (Excel) https://docs.microsoft.com/en-us/azure/analysis-services/analysis-services-connect-excel","No","No","SDL, Best Practice, Manual, AuthN, AnalysisServices"
"AnalysisServices","Azure_AnalysisServices_DP_Encrypt_In_Transit","Sensitive data must be encrypted in transit","Important","No","No","Use of HTTPS ensures server/service authentication and protects data in transit from network layer man-in-the-middle, eavesdropping, session-hijacking attacks.","Ensure that sensitive data is transmitted only on an encrypted channel through out the Analysis Service. Refer: https://blogs.msdn.microsoft.com/jason_howell/2013/02/26/how-do-i-ensure-analysis-services-client-tcp-connectivity-is-encrypted/","No","No","SDL, Information, Manual, DP, AnalysisServices"
"AnalysisServices","Azure_AnalysisServices_DP_Encrypt_At_Rest","Sensitive data must be encrypted at rest","Important","No","No","Using this feature ensures that sensitive data is stored encrypted at rest. This minimizes the risk of data loss from physical theft and also helps meet regulatory compliance requirements.","Default behavior. No action required.","No","No","SDL, Information, Manual, DP, AnalysisServices"
"AnalysisServices","Azure_AnalysisServices_BCDR_Plan","Backup and Disaster Recovery must be planned for Analysis Services","Moderate","No","No","Azure Analysis Service does not offer features to cover backup/disaster recovery out-of-the-box. As a result, when processing critical workloads, a team must have adequate backups of the data.","Go To Azure Portal => Analysis Services => Select Analysis Service => Go To Settings => Select Backups => Select Storage account details and enable backups, Refer: https://docs.microsoft.com/en-us/azure/analysis-services/analysis-services-backup","Yes","No","SDL, Best Practice, Automated, BCDR, AnalysisServices"
"DataFactory","Azure_DataFactory_DP_LinkSvc_Encrypt_In_Transit","Linked Service must use encryption in transit","Important","No","No","Use of HTTPS ensures server/service authentication and protects data in transit from network layer man-in-the-middle, eavesdropping, session-hijacking attacks.","Linked Services used to transfer data between a data source and Azure Data Factory must use encrypted channels to transmit the data. (e.g., for an Azure Storage account the HTTPS endpoint must be specified in the service JSON and, similarly, for SQL Server the JSON must have Encrypt=True in the connection string, etc.). ","Yes","No","SDL, TCP, Automated, DataFactory, DP"
"DataFactory","Azure_DataFactory_AuthZ_Grant_Min_Access","User accounts/roles connecting to data source must have minimum required permissions","Moderate","No","No","Granting minimum access ensures that users are granted just enough permissions to perform their tasks. This minimizes exposure of the resources in case of user/service account compromise.","All user accounts/roles which are involved in Azure Data Factory must have minimum required access rights to data sources. (e.g. If the Data Factory is just reading data from the data source then the account employed must use just read-only access.)","No","No","SDL, TCP, Manual, DataFactory, AuthZ"
"DataFactory","Azure_DataFactory_Config_Lockdown_DMG_Server","Data Management Gateway (DMG), if used, must be installed on a locked down machine","Moderate","No","No","The DMG machine is serving as a 'gateway' into the corporate environment allowing endpoint in the cloud access to enteprise data. Using a locked-down, secure baseline configuration ensures that this machine does not get leveraged as an entry point to the downstream data server/service.","Use Windows Server lockdown templates to minimize the attack surface available. For the most critical scenarios, consider using Code Integrity feature as well.","No","No","SDL, TCP, Manual, DataFactory, Config"
"DataFactory","Azure_DataFactory_Deploy_Register_DMG_Securely","Data Management Gateway (DMG), if used, must be registered in secure way","Moderate","No","No","Data Management Gateway(DMG) tool is required to connect data sources which are hidden behind corpnet/firewall. DMG tool needs to be installed and registered on a machine which has access to data source.The gateway key needs to be exchanged between Azure Portal and DMG tool for registration. Manual handling of this key may impose an operational risk and thus registration of DMG tool must be done via PowerShell.","Use a PowerShell-based approach to register the tool instead of manually handling the key to minimize operational risk. Refer:  https://docs.microsoft.com/en-us/azure/data-factory/data-factory-data-management-gateway#powershell-cmdlets","No","No","SDL, TCP, Manual, DataFactory, Deploy"
"DataFactory","Azure_DataFactory_DP_Rotate_Gateway_Key","Data Gateway key (on Azure Portal) must be rotated periodically","Moderate","No","No","Periodic key/password rotation is a good security hygiene practice as, over time, it minimizes the likelihood of data loss/compromise which can arise from key theft/brute forcing/recovery attacks.","Rotate the Data Gateway key every six months or whenever the DMG service account password is renewed in order to reduce risk from brute force key-guessing attacks.","No","No","SDL, TCP, Manual, DataFactory, DP"
"DataFactory","Azure_DataFactory_AuthZ_Use_Svc_Acct_for_DMG","Linked Service must be setup using a service account when Data Management Gateway is used ","Moderate","No","No","Using a service account with access to the data tier eliminates the need to manage a separate account/connection string that DMG would otherwise need to use to access the backend data.","Configuration of Linked Service involves credentials (username, password etc.) for the target data source. The service account used to run the DMG may be granted access to the target data source. This can let us leverage integrated authentication and do away with the need to store credentials.","No","No","SDL, TCP, Manual, DataFactory, AuthZ"
"DataFactory","Azure_DataFactory_Audit_Enable_Logging_and_Monitoring","Monitoring must be enabled for Azure Data Factory","Moderate","No","No","Auditing enables log collection of important system events pertinent to security. Regular monitoring of audit logs can help to detect any suspicious and malicious activity early and respond in a timely manner.","Refer: https://docs.microsoft.com/en-us/azure/data-factory/data-factory-monitor-manage-app","No","No","SDL, TCP, Manual, DataFactory, Audit"
"DataFactory","Azure_DataFatory_AuthN_DataLakeStore_LinkedService","Data lake store linked service in Data Factory must be configured with service-to-service authentication","Important","No","No","If user credentials are employed, there may be downtime due to token expiration.","Use service principal based authentication in the data lake store linked service. Refer: https://docs.microsoft.com/en-us/azure/data-factory/data-factory-azure-datalake-connector#linked-service-properties","No","No","SDL, TCP, Manual, DataFactory, AuthN"
"DataFactory","Azure_DataFatory_BCDR_Multiple_Node_DMG","To ensure high availability multiple nodes should be configured on DMG","Important","No","No","DMG configured on multiple node ensures that another node is available for moving data even if one of the nodes goes down.","Refer: https://docs.microsoft.com/en-us/azure/data-factory/data-factory-data-management-gateway-high-availability-scalability#set-up-a-multi-node-gateway","No","No","SDL, TCP, Manual, DataFactory, BCDR"
"DataFactory","Azure_DataFactory_DP_Encrypt_Node_To_Node_Communication","For multi-node gateway, node to node communication must be encrypted with valid TLS/SSL certificate","Important","No","No","Use of HTTPS ensures server/service authentication and protects data in transit from network layer man-in-the-middle, eavesdropping, session-hijacking attacks.","For each DMG node following: Go to Data Management Gateway Application --> After Registration --> Settings Tab --> Node-Node Communication Encryption Mode --> Change. Upload a valid certificate which fulfils https://docs.microsoft.com/en-us/azure/data-factory/data-factory-data-management-gateway-high-availability-scalability#tlsssl-certificate-requirements requirements.","No","No","SDL, TCP, Manual, DataFactory, DP"
"DataFactory","Azure_DataFactory_BCDR_DMG_Configuration_Backup","Use backup feature to keep a snapshot of DMG configurations","Moderate","No","No","Keeping backup of DMG config ensures that there is always a previous snapshot that can be leveraged to restore configurations quickly during a recovery scenario.","Go to Data Management Gateway Application --> After Registration --> Home Tab --> Generate Backup --> Provide strong password.","No","No","SDL, Best Practice, Manual, DataFactory, BCDR"
"DataFactory","Azure_DataFactory_DP_Encrypt_Credentials_LinkedService","Encrypt credentials in Linked Service while configuring Data Factory (Applicable only for Linked Services which require Gateway)","Important","No","No","By using this configuration, credentials will be transmitted in encrypted format to the DMG which connects to the data source. This ensures that on-premise data source is accessible only through DMG as only DMG can decrypt the credential.","Refer: https://docs.microsoft.com/en-us/azure/data-factory/data-factory-data-management-gateway#encrypting-credentials","No","No","SDL, TCP, Manual, DataFactory, DP"
"DataFactory","Azure_DataFactory_BCDR_Config_Fault_Tolerance","Configure fault tolerance in copy activity to handle incompatible data","Moderate","No","No","In case of incompatible data flowing through the ADF channel, the default behavior will abort the copy activity. A fault tolerant configuration is helpful to continue copy activity by skipping and logging incorrect data.","Refer: https://docs.microsoft.com/en-us/azure/data-factory/data-factory-copy-activity-fault-tolerance#configuration","No","No","SDL, Best Practice, Manual, DataFactory, BCDR"
"EventHub","Azure_EventHub_AuthZ_Dont_Use_Policies_At_Event_Hub_Namespace","Event Hub clients (event senders or receivers) must not use 'namespace' level access policies","Moderate","No","No","A 'namespace' level access policy provides access to all Event Hub in a namespace. However, using an access policy at entity (Event Hub) level provides access only to the specific entity. Thus using the latter is inline with the principle of least privilege.","Remove all the authorization rules from Event Hub namespace except RootManageSharedAccessKey using Remove-AzEventHubAuthorizationRule command. Run 'Get-Help Remove-AzEventHubAuthorizationRule -full' for more help. Use the Azure portal to configure shared access policies with appropriate claims at the specific Event Hub scope.","Yes","No","SDL, TCP, Automated, AuthZ, EventHub"
"EventHub","Azure_EventHub_AuthZ_Use_Min_Permissions_Access_Policies","Access policies must be defined with minimum required permissions to the Event Hub","Moderate","No","No","Granting minimum access ensures that users are granted just enough permissions to perform their tasks. This minimizes the set of operations that can be preformed on the resource by an attacker in case of access policy key compromise.","Ensure that client apps use shared access policies with the least required privilege and at the Event Hub scope. For instance, if the client app is only reading events from the event hub (as opposed to sending), then the policy used must only include the 'Listen' claim. Refer: https://docs.microsoft.com/en-us/azure/event-hubs/event-hubs-authentication-and-security-model-overview","Yes","No","SDL, TCP, Automated, AuthZ, EventHub"
"EventHub","Azure_EventHub_DP_Protect_Keys_At_Rest","Access policy keys must be protected at rest","Important","No","No","Using this feature ensures that sensitive data is stored encrypted at rest. This minimizes the risk of data loss from physical theft and also helps meet regulatory compliance requirements.","Access policy keys must be handled in a secure manner. E.g., Access policy keys can be stored in the application settings on the Azure portal for a Web App, or can be stored in a Key Vault. The approach to protect the key may vary based on the Azure feature and scenario from where Event Hubs are consumed.","No","No","SDL, TCP, Manual, DP, EventHub"
"EventHub","Azure_EventHub_DP_Rotate_Keys","Access policy keys must be rotated periodically","Moderate","No","No","Periodic key/password rotation is a good security hygiene practice as, over time, it minimizes the likelihood of data loss/compromise which can arise from key theft/brute forcing/recovery attacks.","Use New-AzEventHubKey -ResourceGroupName <ResourceGroupName> -Namespace <NamespaceName> -EventHub <EventHubName> -Name <AuthorizationRuleName> -RegenerateKey PrimaryKey/SecondaryKey to regenerate Event Hub key. Use New-AzEventHubKey -ResourceGroupName <ResourceGroupName> -Namespace <NamespaceName> -Name <AuthorizationRuleName> -RegenerateKey PrimaryKey/SecondaryKey to regenerate namespace key. Caution: Make sure that the newly generated keys are seamlessly deployed to clients to avoid disruption of functionality.","No","No","SDL, TCP, Manual, DP, EventHub"
"EventHub","Azure_EventHub_Audit_Review_Logs","Audit logs for Event Hub entities should be reviewed periodically","Moderate","No","No","Periodic reviews of diagnostics, activity and audit logs ensures that anomalous activity can be identified early enough instead of after a major compromise.","Audit log can be reviewed at Portal -> Event Hub -> <Your Event Hub Name> -> Diagnostics Logs","No","No","SDL, Best Practice, Manual, Audit, EventHub"
"EventHub","Azure_EventHub_DP_Encrypt_In_Transit","Sensitive data must be encrypted in transit","Important","No","No","Use of HTTPS ensures server/service authentication and protects data in transit from network layer man-in-the-middle, eavesdropping, session-hijacking attacks.","Default behavior. No action required.","No","No","SDL, Information, Manual, DP, EventHub"
"EventHub","Azure_EventHub_AuthZ_Use_Min_Token_Lifetime","Expiry time of SAS token should be minimum required","Moderate","No","No","If SAS token gets compromised, unauthorized users can access Event Hub entities. Minimizing the validity period of the SAS token ensures that the window of time available to an attacker in the event of compromise is minimized.","Set expiry time of SAS tokens to the minimum required in context of the scenario. Refer: https://docs.microsoft.com/en-us/azure/service-bus-messaging/service-bus-sas#generate-a-shared-access-signature-token","No","No","SDL, Best Practice, Manual, AuthZ, EventHub"
"EventHub","Azure_EventHub_AuthN_Use_Publisher_Token","Use 'Publisher' tokens to authenticate senders instead of 'Access Policy' tokens","Moderate","No","No","Publisher tokens offer a scalable option when there are a large number of senders involved. Individual time-bound SAS tokens can be created via inheritance from a shared policy so the damage from compromise of any single token is contained. Also, all publisher tokens generated by same policy can be decommisioned by simply decommisioning the corresponding access policy.","Generate 'Publisher' tokens by combining an access policy that has 'Send' claim with an event publisher ID for each publisher. Using this mechanism each publisher will be able to send to only its own virtual endpoint. Refer: https://blogs.msdn.microsoft.com/servicebus/2015/02/02/event-hub-publisher-policy-in-action/","No","No","SDL, Best Practice, Manual, AuthN, EventHub"
"EventHub","Azure_EventHub_AuthZ_Grant_Min_RBAC_Access","All users/identities must be granted minimum required permissions using Role Based Access Control (RBAC)","Moderate","No","No","Granting minimum access by leveraging RBAC feature ensures that users are granted just enough permissions to perform their tasks. This minimizes exposure of the resources in case of user/service account compromise.","Administrator should assign 'Owner' role to Event Hub at the 'resource' scope. Application developers should not have direct access to the Event Hub resource (they should just be provided the required shared access policy for a non-production event hub). Auditors should have 'Monitor Contributor Service Role' or 'Monitor Reader Service Role' based on their role.","Yes","No","SDL, TCP, Automated, AuthZ, RBAC, EventHub"
"EventHub","Azure_EventHub_Audit_Enable_Diagnostics_Log","Diagnostics logs must be enabled with a retention period of at least 365 days","Moderate","No","No","Logs should be retained for a long enough period so that activity trail can be recreated when investigations are required in the event of an incident or a compromise. A period of 1 year is typical for several compliance requirements as well.","You can change the diagnostic settings from the Azure Portal by following the steps given here: https://docs.microsoft.com/en-us/azure/monitoring-and-diagnostics/monitoring-archive-diagnostic-logs#archive-diagnostic-logs-using-the-portal","Yes","No","SDL, TCP, Automated, Audit, Diagnostics, EventHub"
"SQLDatabase","Azure_SQLDatabase_AuthZ_Use_AAD_Admin","Enable Azure AD admin for the SQL Database","Important","Yes","No","Using the native enterprise directory for authentication ensures that there is a built-in high level of assurance in the user identity established for subsequent access control. All Enterprise subscriptions are automatically associated with their enterprise directory (xxx.onmicrosoft.com) and users in the native directory are trusted for authentication to enterprise subscriptions.","Run command Set-AzSqlServerActiveDirectoryAdministrator -ResourceGroupName '{ResourceGroupName}' -ServerName '{ServerName}' -DisplayName '{AzureAdAdmin Display Name}' Refer: https://docs.microsoft.com/en-us/powershell/module/az.sql/set-azsqlserveractivedirectoryadministrator","Yes","Yes","SDL, TCP, Automated, AuthZ"
"SQLDatabase","Azure_SQLDatabase_DP_Enable_TDE","Transparent data encryption (TDE) must be enabled","Important","Yes","No","Using this feature ensures that sensitive data is stored encrypted at rest. This minimizes the risk of data loss from physical theft and also helps meet regulatory compliance requirements.","Run command Set-AzSqlDatabaseTransparentDataEncryption -ResourceGroupName '{ResourceGroupName}' -ServerName '{ServerName}' -DatabaseName '{DatabaseName}' -State 'Enabled'. Refer: https://docs.microsoft.com/en-us/powershell/module/az.sql/set-azsqldatabasetransparentdataencryption *Note:If Blob Auditing or Threat Detection are enabled on the server, they will always apply to the database, regardless of the database level settings.","Yes","Yes","SDL, TCP, Automated, DP, SOX, SqlDatabase"
"SQLDatabase","Azure_SQLDatabase_Audit_Enable_Threat_Detection_Server","Enable SQL Server threat detection with email admins option. Do not exclude any detection types","Important","Yes","No","Enabling threat detection helps generate alerts about suspicious activity that might indicate attacks such as SQL Injection, login from a new location, unusual usage patterns and related attacks in a timely manner.","First run command 'Set-AzSqlServerAuditing -ResourceGroupName '{ResourceGroupName}' -ServerName '{ServerName}' -StorageAccountName '{StorageAccountName}' -State 'Enabled' -RetentionInDays 365'.Refer: https://docs.microsoft.com/en-us/powershell/module/az.sql/set-azsqlserverauditing. Then run command 'Set-AzSqlServerThreatDetectionPolicy -ResourceGroupName '{ResourceGroupName}' -ServerName '{ServerName}' -StorageAccountName '{StorageAccountName}' -EmailAdmins $true -ExcludedDetectionType 'None''.","Yes","Yes","SDL, TCP, Automated, Audit, SOX"
"SQLDatabase","Azure_SQLDatabase_AuthZ_Use_IP_Firewall_Rules_DB","In a SQL Server with multiple databases, setup firewall rules also at the database level","Important","No","No","Using the IP firewall rules ensures that access to the data or the service is restricted to a specific set of IPs. NOTE: While this control does provide an extra layer of access control protection, it may not always be feasible to implement in all scenarios.","Wherever feasible, restrict each SQL Database to a limited set of IP addresses/ranges that require access to that database. Refer: https://docs.microsoft.com/en-us/azure/sql-database/sql-database-firewall-configure. Note: In case the IP range is indeterminate (for instance, if the client is a PaaS endpoint), you may need to attest this control.","No","No","SDL, TCP, Manual, AuthZ, SqlDatabase"
"SQLDatabase","Azure_SQLDatabase_AuthN_Dont_Use_SQL_AuthN","Do not use SQL Authentication. Use AAD-authentication instead","Important","No","No","Using the native enterprise directory for authentication ensures that there is a built-in high level of assurance in the user identity established for subsequent access control. All Enterprise subscriptions are automatically associated with their enterprise directory (xxx.onmicrosoft.com) and users in the native directory are trusted for authentication to enterprise subscriptions.","Disable SQL Authentication on the DB and use AAD authentication instead. Refer: https://docs.microsoft.com/en-us/azure/sql-database/sql-database-aad-authentication","No","No","SDL, TCP, Manual, AuthN"
"SQLDatabase","Azure_SQLDatabase_DP_Use_Client_Side_Encryption","Client-side encryption should be used where appropriate","Moderate","No","No","Using client-side encryption in 'Always Encrypted' mode helps protect sensitive data at rest on the server, during movement between client and server and ensures that only client applications or app servers that have access to the encryption keys can access plaintext data.","The recommended client side encryption solution is 'Always Encrypted'. Refer: https://docs.microsoft.com/en-us/azure/sql-database/sql-database-always-encrypted","No","No","SDL, TCP, Manual, DP"
"SQLDatabase","Azure_SQLDatabase_AuthZ_Grant_Min_Access","Access to SQL Servers and DBs must be granted in accordance with the principle of least privilege","Moderate","No","No","Granting minimum access ensures that users are granted just enough permissions to perform their tasks. This minimizes exposure of the resources in case of user/service account compromise.","Using SSMS Object Explorer and T-SQL to assign database roles, e.g. db_datareader, db_datawriter, db_securityadmin: Alter Role db_datareader ADD MEMBER ApplicationUser; to allow ApplicationUser to read data, Alter Role db_datawriter ADD MEMBER ApplicationUser; to allow ApplicationUser to write data. Refer: https://azure.microsoft.com/en-us/documentation/articles/sql-database-security/#authorization, http://blogs.technet.com/b/scotts-it-blog/archive/2014/09/03/adding-accounts-to-database-roles-in-sql-server-2012.aspx","No","No","SDL, TCP, Manual, AuthZ"
"SQLDatabase","Azure_SQLDatabase_AuthZ_Configure_IP_Range","Configure only the required IP addresses on SQL firewall. Do not use Any-to-Any IP range 0.0.0.0-255.255.255.255","Important","No","No","Using the firewall feature ensures that access to the data or the service is restricted to a specific set/group of clients. NOTE: While this control does provide an extra layer of access control protection, it may not always be feasible to implement in all scenarios.","Do not configure Any to Any firewall IP address. Run command Remove-AzSqlServerFirewallRule -FirewallRuleName '{AnyToAny FirewallRule Name}' -ResourceGroupName '{ResourceGroupName}' -ServerName '{ServerName}'. Refer: https://docs.microsoft.com/en-us/powershell/module/az.sql/Remove-AzSqlServerFirewallRule","Yes","No","SDL, Best Practice, Automated, AuthZ, SOX"
"SQLDatabase","Azure_SQLDatabase_Audit_Enable_Logging_and_Monitoring_Server","Enable SQL Server audit with selected event types and retention period of minimum 365 days","Moderate","No","No","Auditing enables log collection of important system events pertinent to security. Regular monitoring of audit logs can help to detect any suspicious and malicious activity early and respond in a timely manner.","Run command Set-AzSqlServerAuditing -ResourceGroupName '{ResourceGroupName}' -ServerName '{ServerName}' -StorageAccountName '{StorageAccountName}' -State 'Enabled' -RetentionInDays 365. Refer: https://docs.microsoft.com/en-us/powershell/module/az.sql/set-azsqlserverauditing","Yes","Yes","SDL, TCP, Automated, Audit, SOX"
"SQLDatabase","Azure_SQLDatabase_Audit_Review_Logs_Periodically","Logs should be reviewed routinely","Moderate","No","No","Periodic reviews of diagnostics, activity and audit logs ensures that anomalous activity can be identified early enough instead of after a major compromise.","Use Azure SQL Audit Logs Excel template to review logs. Refer: https://docs.microsoft.com/en-us/azure/sql-database/sql-database-auditing#subheading-3","No","No","SDL, TCP, Manual, Audit"
"SQLDatabase","Azure_SQLDatabase_DP_Review_Data_Masking_Policy","Review the Data Masking policy for SQL Database sensitive data columns if in use.","Moderate","No","No","Database dynamic data masking limits sensitive data exposure by masking it to non-privileged users and hides the sensitive data in the result set of a query over designated database fields. When used dynamic data masking should cover all sensitive columns.","(As applicable) Set Data Masking Rules using the following steps: (1) Run command Set-AzSqlDatabaseDataMaskingRule -ResourceGroupName '{ResourceGroupName}' -ServerName '{ServerName}' -DatabaseName '{DataBaseName}' -SchemaName '{SchemaName}' -TableName  '{TableName}' -ColumnName '{ColumnName}'. Refer: https://docs.microsoft.com/en-us/powershell/module/az.sql/set-azsqldatabasedatamaskingrule (2) Verify the privileged users to whom access is granted to view Unmasked data columns.","Yes","No","SDL, TCP, Automated, Deploy"
"SQLDatabase","Azure_SQLDatabase_AuthZ_Firewall_Deny_Access_AzureServices","Use the 'Allow access to Azure services' flag only if required.","Moderate","No","No","The 'Allow access to Azure services' setting configures a very broad range of IP addresses from Azure as permitted to access the SQL Server. Please make sure your scenario really requires this setting before enabling it. Turning it ON exposes your SQL Server to risk of attacks from resources (IPs) owned by others in the Azure region.","Turn off the allow access to Azure services flag. Run command Remove-AzSqlServerFirewallRule -FirewallRuleName 'AllowAllWindowsAzureIps' -ResourceGroupName '{ResourceGroupName}' -ServerName '{ServerName}'. Refer: https://docs.microsoft.com/en-us/powershell/module/az.sql/remove-azsqlserverfirewallrule","Yes","No","SDL, Best Practice, Automated, AuthZ, SOX"
"ServiceFabric","Azure_ServiceFabric_AuthN_Publicly_Exposed_MicroSvc","Publicly exposed microservice endpoints must have authentication and authorization enforced","Important","No","No","If authentication and authorization are not correctly implemented, microservice endpoints may be easily accessed by anyone on the internet leading to compromise of sensitive data.","Authentication and access control must be implemented on publicly exposed microservices using standard mechanisms for user/client authentication.","No","No","SDL, TCP, Manual, AuthN, ServiceFabric, Windows, Linux"
"ServiceFabric","Azure_ServiceFabric_DP_Exposed_Endpoint_SSL_Secured","Publicly exposed endpoints must be secured using SSL","Important","No","No","Use of SSL ensures server/service authentication and protects data in transit from network layer man-in-the-middle, eavesdropping, session-hijacking attacks.","Azure Service Fabric supports configuration of endpoints for microservices. To provide end to end encryption and data integrity, all publicly exposed endpoints must be secured using SSL. Steps to configure SSL: (1) Specify HTTPS endpoint in ServiceManifest.xml at ServiceManifest --> Resources --> Endpoints, (2) Specify certificate details in ApplicationManifest.xml <i> Add an EndpointBindingPolicy at ApplicationManifest --> ServiceManifestImport --> Policies <ii> Add an EndpointCertificate at ApplicationManifest --> Certificates (3) Upload certificate to cluster (Refer: https://azure.microsoft.com/en-in/documentation/articles/service-fabric-service-manifest-resources/#example-specifying-an-https-endpoint-for-your-service)","Yes","No","SDL, TCP, Manual, DP, ServiceFabric, Windows, Linux"
"ServiceFabric","Azure_ServiceFabric_DP_App_Secrets_Cert_Encrypted","Application secrets must be encrypted with a certificate","Important","No","No","Protecting the connection string, storage account keys, password, etc., (stored in Settings.xml file in ConfigPackage of microservice, ServiceManifest.xml and ApplicationManifest.xml) ensures that these secrets do not get compromised through copies of the settings/manifest files that might be left unprotected on various systems.","An application typically contains secrets, such as connection string, storage account keys, password etc., which are required at runtime. Application secrets can be stored in Settings.xml file in ConfigPackage of microservice, ServiceManifest.xml and ApplicationManifest.xml. These secrets must be encrypted with a certificate. Steps to encrypt a secret: (1) Obtain a data encipherment certificate. (2) Install the certificate on cluster. (3) Encrypt secret values when deploying an application with the certificate and inject them into Settings.xml/ServiceManifest.xml/ApplicationManifest.xml file. (4) Read encrypted values out of Settings.xml and decrypt them with the same encipherment certificate. Refer:  https://azure.microsoft.com/en-us/documentation/articles/service-fabric-application-secret-management/","No","No","SDL, TCP, Manual, DP, ServiceFabric, Windows, Linux"
"ServiceFabric","Azure_ServiceFabric_DP_Data_Replication_Cert_Secured","Data replication must be secured with certificate","Moderate","No","No","The replication traffic of microservices must be protected using a certificate so that microservices are not be able to see each others' replication traffic.","Service Fabric Replicator Service is responsible for making the state of Stateful service highly reliable. Replicator security configurations must be used to secure the communication channel that is used during replication. Doing this ensures that services within the same cluster will not be able to see each other's replication traffic, ensuring that the data that is made highly available is also secure. Note that by default an empty security configuration section implies no replication security. Refer 'Sample configuration file' at:  https://azure.microsoft.com/en-in/documentation/articles/service-fabric-reliable-services-configuration/#_replicator-security-configuration","No","No","SDL, TCP, Manual, DP, ServiceFabric, Windows, Linux"
"ServiceFabric","Azure_ServiceFabric_DP_Sensitive_Data_Dont_Store_In_DataPackage","Sensitive data must not be stored inside DataPackage","Important","No","No","DataPackage files can be accessed from other microservices running on same node (VM). DataPackage files get distributed along with the application package while publishing/deployment. This can lead to compromise of any sensitive data as copies of these deployment packages are often left unprotected.","DataPackage is intended to store static files which are required by microservices at runtime. Files inside DataPackage are NOT intended to be modified at runtime. DataPackage must not contain any file containing sensitive data, because: (1) DataPackage files can be accessed from other microservices running on same node (VM) and (2) DataPackage files gets distributed along with the application package when the application is published.","No","No","SDL, TCP, Manual, DP, ServiceFabric, Windows, Linux"
"ServiceFabric","Azure_ServiceFabric_Availability_Replica_Stateful_Size_Set_Min_3","Replica set size for stateful services must be set to a minimum of 3","Moderate","No","No","A replica set size of 3 or more in the case of stateful services ensures that data is not lost in the event of a single node failure.","The replica set size of a Stateful service indicates the number of copies of reliable service data maintained by Service Fabric. The data in reliable service must not be lost even if a node (VM) goes down. However, if the replica set size is 1, data loss is possible. To achieve high availability, each stateful service must have a target and minimum replica set size of at least 3. Set the values for all Stateful services in ApplicationManifest.xml file as below: (1) ApplicationManifest --> DefaultServices --> Service --> StatefulService --> MinReplicaSetSize, (2) ApplicationManifest --> DefaultServices --> Service --> StatefulService --> TargetReplicaSetSize. Refer: https://azure.microsoft.com/en-in/documentation/articles/service-fabric-concepts-partitioning/","Yes","No","SDL, TCP, Manual, Availability, ServiceFabric, Windows, Linux"
"ServiceFabric","Azure_ServiceFabric_Availability_Instance_Stateless_Size_Set_Min_3","Instance count for stateless service must be set to a minimum of 3","Moderate","No","No","An instance count of 3 or more guarantees high availability for stateless services in the event of a single node failure.","The instance count reflects the number of instances of a stateless service that should be running in the cluster. To achieve high availability, each stateless service must have an instance count of at least 3. Set this value to 3 for all stateless services in ApplicationManifest.xml file at ApplicationManifest --> DefaultServices --> Service --> StatelessService --> InstanceCount","Yes","No","SDL, TCP, Manual, Availability, ServiceFabric, Windows, Linux"
"ServiceFabric","Azure_ServiceFabric_AuthZ_Security_Mode_Enabled","Service Fabric cluster security must be enabled using security mode option","Important","No","No","A secure cluster prevents unauthorized access to management operations, which includes deployment, upgrade, and deletion of microservices. Also provides encryption for node-to-node communication, client-to-node communication etc. In oppose to unsecure cluster which can be connected by any anonymous user.","A secure cluster must be created to prevent unauthorized access to management operations (e.g., deployment, upgrade or deletion of microservices). A secure cluster also provides encryption for node-to-node communication, client-to-node communication, etc. An insecure cluster is open to be connected by any anonymous user. An insecure cluster cannot be secured at a later time. For creating a secure cluster using (1) Azure Portal, refer: https://azure.microsoft.com/en-in/documentation/articles/service-fabric-cluster-creation-via-portal/#_3-security or using (2) ARM template refer:https://azure.microsoft.com/en-in/documentation/articles/service-fabric-cluster-creation-via-arm/","Yes","No","SDL, TCP, Automated, AuthZ, Information, ServiceFabric, Windows, Linux"
"ServiceFabric","Azure_ServiceFabric_AuthZ_Microservice_Trust","Service Fabric cluster must contain only microservices which trust each other","Important","No","No","Microservice hosted on same Service Fabric cluster can monitor traffic of other microservices and access the files hosted on cluster. Hence the same Service Fabric cluster must not host microservices which do not trust each other.","Microservices hosted on same Service Fabric cluster can monitor traffic of other microservices and access the files hosted on cluster. Hence a Service Fabric cluster must contain only those microservices which trust each other.","No","No","SDL, TCP, Manual, AuthZ, ServiceFabric, Windows, Linux"
"ServiceFabric","Azure_ServiceFabric_AuthN_Self_Signed_Cert","Self-signed certs must not be used for Service Fabric cluster primary certificate","Important","No","No","The primary certificate of Service Fabric must be obtained from a trusted certification authority. This ensures that client applications/endpoints can validate the identities of microservices in the cluster in a secure manner.","Service Fabric uses an X.509 certificate for cluster security in a couple of ways: (1) Cluster authentication: For authentication of node-to-node communication and (2) Server authentication: For authentication of cluster management endpoints to management clients. The primary certificate is also for the HTTPS access to the management API and the Service Fabric Explorer. This certificate must be obtained from an approved Certificate Authority for a custom domain name for your cluster.","Yes","No","SDL, TCP, Automated, AuthN, ServiceFabric, Windows, Linux"
"ServiceFabric","Azure_ServiceFabric_AuthN_Client_AuthN_AAD_Only","Client authentication must be performed only via Azure Active Directory","Important","Yes","No","Using the native enterprise directory for authentication ensures that there is a built-in high level of assurance in the user identity established for subsequent access control. All Enterprise subscriptions are automatically associated with their enterprise directory (xxx.onmicrosoft.com) and users in the native directory are trusted for authentication to enterprise subscriptions.","A Service Fabric cluster offers several entry points to its management functionality, including the web-based Service Fabric Explorer, Visual Studio and PowerShell. Access to the cluster must be controlled using AAD. Refer: https://docs.microsoft.com/en-in/azure/service-fabric/service-fabric-cluster-creation-setup-aad","Yes","No","SDL, TCP, Automated, AuthN, ServiceFabric, Windows"
"ServiceFabric","Azure_ServiceFabric_DP_Set_Property_ClusterProtectionLevel","The ClusterProtectionLevel property must be set to EncryptAndSign","Important","No","Yes","With cluster protection level set to 'EncryptAndSign', all the node-to-node messages are encrypted and digitally signed. This protects the intra-cluster communication from eavesdropping/tampering/man-in-the-middle attacks on the network.","Service Fabric provides three levels of protection (None, Sign and EncryptAndSign) for node to node communication using cluster primary certificate. The protection level can be specified using property 'ClusterProtectionLevel' inside Service Fabric ARM template. The value of 'ClusterProtectionLevel' must be set to 'EncryptAndSign' to ensure that all the node-to-node messages are encrypted and digitally signed. Configure 'ClusterProtectionLevel' using ARM template as follows: ARM Template --> Resources --> Select resource type 'Microsoft.ServiceFabric/clusters' --> 'fabricSettings' --> Add 'ClusterProtectionLevel' property with value 'EncryptAndSign'.","Yes","No","SDL, TCP, Automated, DP, ServiceFabric, Windows, Linux"
"ServiceFabric","Azure_ServiceFabric_AuthN_NSG_Enabled","Network security group (NSG) must be enabled on subnets of Service Fabric cluster","Moderate","No","No","Use of appropriate NSG rules can limit exposure of Service Fabric cluster in multiple scenarios. For example, RDP connections can be restricted only for specific admin machines. Incoming requests to microservices may be restricted to specific clients. Also, deployments can be restricted to happen only from an allowed range of IP addresses.","NSG contains a list of Access Control List (ACL) rules that allow or deny network traffic to Service Fabric node instances in a Virtual Network. NSGs can be associated with either subnets or individual node/VM instances within a subnet. NSG must be used in following scenarios: (1) Restrict RDP connection only from admin machine IP,  (2) Restrict microservice incoming request from trusted source IP, (3) Lock down the remote address ranges allowed for microservice deployments. Refer: https://azure.microsoft.com/en-in/documentation/articles/virtual-networks-create-nsg-arm-pportal/","Yes","No","SDL, TCP, Automated, AuthN, ServiceFabric, Windows, Linux"
"ServiceFabric","Azure_ServiceFabric_DP_Enable_Encryption_Stg_Acc_Store_VHD","Encryption must be enabled on all storage accounts which store VHDs of Service Fabric cluster VMs","Important","No","No","Using this feature ensures that sensitive data is stored encrypted at rest. This minimizes the risk of data loss from physical theft and also helps meet regulatory compliance requirements.","Default behavior. No action required.","No","No","SDL, TCP, Manual, Information, DP, ServiceFabric, Windows, Linux"
"ServiceFabric","Azure_ServiceFabric_Audit_Use_Diagnostics_Log","Diagnostics must be enabled for Service Fabric cluster","Moderate","No","No","Diagnostics logs are needed for creating activity trail while investigating an incident or a compromise.","Diagnostics must be enabled to get logs of these events: (1) Service Fabric events: Emitted by the platform to standard ETW and event source channels. E.g., Node Down/Up etc. (2) Application events: Events emitted from the microservice code. E.g., Application Created, Service Created/Deleted, etc. Diagnostics extension must be deployed on all VMs in the Service Fabric cluster. It collect logs from all the VMs and uploads them to the Azure Storage Account. Enable Diagnostics while creating Service Fabric using either the Azure Portal or an ARM template. (1) For Azure Portal refer: https://azure.microsoft.com/en-in/documentation/articles/service-fabric-diagnostics-how-to-setup-wad/#_deploy-the-diagnostics-extension-as-part-of-cluster-creation-through-the-portal (2) For ARM Template, refer: https://azure.microsoft.com/en-in/documentation/articles/service-fabric-diagnostics-how-to-setup-wad/#_deploy-the-diagnostics-extension-as-part-of-cluster-creation-by-using-azure-resource-manager","Yes","No","SDL, TCP, Automated, Audit, ServiceFabric, Windows, Linux"
"ServiceFabric","Azure_ServiceFabric_Audit_Publicly_Exposed_Load_Balancer_Ports","Monitor publicly exposed ports on load balancers used by Service Fabric cluster","Moderate","No","No","Publically exposed ports must be monitored to detect suspicious and malicious activities early and respond in a timely manner.","Azure load balancer maps the public IP address and port number of incoming traffic to the private IP address and port number of the Service Fabric nodes (ports number opened by microservices). Intranet microservice ports must not be exposed to the internet. Moreover, publicly exposed IP address/port numbers must be monitored using Azure load balancer rules as follows: Azure Portal --> Load Balancers --> <Load Balancer Name> --> Load Balancing Rules --> Validate mapping of public end port with backend port.","No","No","SDL, TCP, Manual, Audit, ServiceFabric, Windows, Linux"
"ServiceFabric","Azure_ServiceFabric_DP_Reverse_Proxy_Use_SSL","Reverse proxy service should be secured using SSL","Moderate","No","No","Use of SSL ensures server/service authentication and protects data in transit from network layer man-in-the-middle, eavesdropping, session-hijacking attacks.","To configure the reverse proxy with a SSL certificate, please refer: https://docs.microsoft.com/en-us/azure/service-fabric/service-fabric-reverseproxy-setup","No","No","SDL, TCP, Manual, DP, ServiceFabric, Windows"
"ServiceFabric","Azure_ServiceFabric_DP_Dont_Expose_Reverse_Proxy_Port","Reverse proxy port must not be exposed publicly","Important","No","Yes","Configuring the reverse proxy's port in Load Balancer with public IP will expose all microservices with HTTP endpoint. Microservices meant to be internal may be discoverable by a determined malicious user.","Check that reverse proxy port is not be exposed through Azure Load Balancer rules as follows: Azure Portal --> Load Balancers --> <Load Balancer Name> --> Load Balancing Rules --> Validate reverse proxy port is not exposed.","Yes","No","SDL, TCP, Automated, DP, ServiceFabric, Windows"
"ServiceFabric","Azure_ServiceFabric_SI_Set_Auto_Update_Cluster","Upgrade mode should be set to automatic for cluster","Moderate","No","No","Clusters with unsupported fabric version can become targets for compromise from various malware/trojan attacks that exploit known vulnerabilities in software.","You can set your cluster to receive automatic fabric upgrades as they are released by Microsoft, for details please refer: https://docs.microsoft.com/en-us/azure/service-fabric/service-fabric-cluster-upgrade","Yes","No","SDL, TCP, Automated, SI, ServiceFabric, Windows, Linux"
"LoadBalancer","Azure_LoadBalancer_AuthZ_Grant_Min_RBAC_Access","All users/identities must be granted minimum required permissions using Role Based Access Control (RBAC)","Moderate","No","No","Granting minimum access by leveraging RBAC feature ensures that users are granted just enough permissions to perform their tasks. This minimizes exposure of the resources in case of user/service account compromise.","Remove any excessive privileges granted on the Load Balancer. Assign 'Log Analytics Contributor, Network Contributor, Virtual Machine Contributor' RBAC role to developers who manages Load Balancer configurations. Run command: Remove-AzRoleAssignment -SignInName '{signInName}' -Scope '{scope}' -RoleDefinitionName '{role definition name}'. Run 'Get-Help Remove-AzRoleAssignment -full' for more help. Refer: https://docs.microsoft.com/en-us/azure/active-directory/role-based-access-control-manage-access-powershell","Yes","No","SDL, TCP, Automated, AuthZ, RBAC, LoadBalancer"
"LoadBalancer","Azure_LoadBalancer_Audit_Enable_Diagnostics_Log","Diagnostics logs must be enabled with a retention period of at least 365 days.","Moderate","No","No","Logs should be retained for a long enough period so that activity trail can be recreated when investigations are required in the event of an incident or a compromise. A period of 1 year is typical for several compliance requirements as well.","You can change the diagnostic settings from the Azure Portal by following the steps given here: https://docs.microsoft.com/en-us/azure/monitoring-and-diagnostics/monitoring-archive-diagnostic-logs#archive-diagnostic-logs-using-the-portal","Yes","No","SDL, TCP, Automated, Audit, Diagnostics, LoadBalancer"
"LoadBalancer","Azure_LoadBalancer_NetSec_Justify_PublicIPs","Public IPs on a internet facing Load Balancer should be carefully reviewed","Important","No","Yes","Public IPs provide direct access over the internet exposing the infrastructure behind the load balancer to all type of attacks over the public network.","Use steps on portal :LoadBalancer Properties -> Frontend IP configuration -> Click on Context menu of desired Frontend IP configuration -> Delete","Yes","No","SDL, TCP, Automated, NetSec, LoadBalancer"
"Databricks","Azure_Databricks_DP_No_PlainText_Secrets_In_Notebooks","Secrets and keys must not be in plain text in notebooks and jobs","Important","No","No","Keeping secrets such as connection strings, passwords, keys, etc. in clear text can lead to easy compromise. Storing them in a secert scope ensures that they are protected at rest.","Use a key vault backed Databricks secret scopes to store any secrets and keys and read them from the respective secret scopes in notebooks and jobs. Refer: https://docs.azuredatabricks.net/user-guide/secrets/index.html","Yes","No","SDL, TCP, PAT, DP, Automated, Admin, Databricks, Preview"
"Databricks","Azure_Databricks_DP_Use_KeyVault_Backed_Secret_Scope","Use Azure Key Vault backed secret scope to hold secrets","Moderate","No","No","Using Key Vault backed secret scopes leads to imroved protection and segregation of stored secrets.","To use Azure Key Vault backed secret scopes, refer: https://docs.azuredatabricks.net/user-guide/secrets/secret-scopes.html#create-an-azure-key-vault-backed-secret-scope","Yes","No","SDL, TCP, DP, Automated, PAT, Admin, Databricks, Preview"
"Databricks","Azure_Databricks_DP_Independent_KeyVault_Per_Scope","Each secret scope should use an independent key vault","Moderate","No","No","Using a separate key vault for each secret scope leads to better segregation of access to secrets via use of scope level ACLs. If the same key vault is used for two different scopes then any person with access to either of them will be able to see keys and secrets in both. ","Analyze the separation of access needed in your solution and use different scopes backed by independent key vaults as necessary.","Yes","No","SDL, TCP, DP, Best Practice, Automated, PAT, Admin, Databricks, Preview"
"Databricks","Azure_Databricks_DP_Minimal_Token_Validity","Personal access tokens (PAT) must have a shortest possible validity period","Important","No","No","If a personal access token (PAT) gets compromised, the Databricks assets accessible to the user can be accessed/manipulated by unauthorized users. Minimizing the validity period of the PAT ensures that the window of time available to an attacker in the event of compromise is small.","While creating a PAT, provide the minimum practical expiration period. You can see all tokens genearted by you and their expiration periods by navigating to Databricks Workspace --> Profile --> User Settings --> Access Tokens","Yes","No","SDL, TCP, PAT, Automated, DP, Databricks, Preview"
"Databricks","Azure_Databricks_AuthZ_Grant_Min_RBAC_Access","All users/identities must be granted minimum required permissions using Role Based Access Control (RBAC)","Moderate","No","No","Granting minimum access by leveraging RBAC feature ensures that users are granted just enough permissions to perform their tasks. This minimizes exposure of the resources in case of user account compromise.","Remove any excessive privileges granted on the Databricks. Run command: Remove-AzRoleAssignment -SignInName '<SignInName>' -Scope '<Scope>' RoleDefinitionName '<RoleDefinitionName>'. Run 'Get-Help Remove-AzRoleAssignment -full' for more help.","Yes","No","SDL, TCP, AuthZ, RBAC, Automated, Databricks, Preview"
"Databricks","Azure_Databricks_AuthZ_Limit_Admin_Count","Minimize the number of workspace admins","Moderate","No","No","Databricks workspace admins have full access on the workspace to perform any operation. Each additional person in the admin role increases the attack surface for the workspace. The number of members in these roles should be kept to as low as possible.","Minimize the number of workspace admins. Navigate to Databricks workspace --> Account --> Admin Console --> Users --> Revoke admin access for users(who no longer requires admin access)","Yes","No","SDL, TCP, AuthZ, Automated, Admin, PAT, Databricks, Preview"
"Databricks","Azure_Databricks_AuthZ_Cluster_Grant_Min_RBAC_Access","All users must be granted minimum required permissions on clusters","Moderate","No","No","Granting minimum access by leveraging RBAC feature ensures that users are granted just enough permissions to perform their tasks. This minimizes exposure of the resources in case of user account compromise.","Remove any excessive privileges granted to any user on clusters. Navigate to workspace --> clusters --> select cluster --> Edit --> Permissions, for details refer: https://docs.azuredatabricks.net/administration-guide/admin-settings/cluster-acl.html","No","No","SDL, TCP, AuthZ, RBAC, Manual, Databricks, Preview"
"Databricks","Azure_Databricks_AuthZ_Enable_Workspace_Access_Control","Workspace access control should be enabled","Moderate","No","No","Enabling workspace access control allows an admin to manage fine-grained user permissions and ensures that users can perform only intended operations. This minimizes exposure of data in case of user account compromise.","To enable and configure workspace access control, refer: https://docs.azuredatabricks.net/administration-guide/admin-settings/workspace-acl.html","Yes","No","SDL, TCP, AuthZ, RBAC, Automated, Databricks, Preview"
"Databricks","Azure_Databricks_AuthZ_Enable_Cluster_Access_Control","Cluster access control should be enabled","Moderate","No","No","Enabling cluster access control allows admin to provide restricted access to user over cluster so that users can perform only intended operations. This minimizes exposure of data in case of user/service account compromise.","To enable and configure cluster access control, refer: https://docs.azuredatabricks.net/administration-guide/admin-settings/cluster-acl.html","Yes","No","SDL, TCP, AuthZ, RBAC, Automated, Databricks, Preview"
"Databricks","Azure_Databricks_AuthZ_Enable_Job_Access_Control","Job access control should be enabled","Moderate","No","No","Enabling job access control ensures that users are granted just enough permissions to perform their tasks. This minimizes exposure of data in case of user/service account compromise.","To enable and configure job access control, refer: https://docs.azuredatabricks.net/administration-guide/admin-settings/jobs-acl.html","Yes","No","SDL, TCP, AuthZ, RBAC, Automated, Databricks, Preview"
"Databricks","Azure_Databricks_DP_Review_Mounted_DataSources","Do not mount any data sources that may not be required for all users in the workspace.","Moderate","No","No","Mouting a data source gives all users within the workspace access to the data from the mount point. Thus, mounting sources with sensitive data onto DBFS can lead to unauthorized access.","Create a mount point only if all users in workspace need to have access to all data in the mounted data source. Use tables with ACLs if you want to impose segregation of access on imported data.","No","No","SDL, TCP, DP, Manual, Databricks, Preview"
"Databricks","Azure_Databricks_AuthZ_Prohibit_Guest_Account_Admin_Access","Guest accounts within the AAD tenant should not be granted admin access","Important","No","No","Databricks workspace admins have full access on the workspace to perform any operation. Each guest account in an admin role increases the attack surface for the workspace. Adding guest accounts as admin on workspace should be avoided.","Avoid granting access to guest accounts from the AAD tentant. Remove any such accounts that may have been granted access in the past. Navigate to Databricks workspace --> Account --> Admin Console --> Users --> Revoke admin access of guest users(who no longer requires admin access)","Yes","No","SDL, TCP, AuthZ, Admin, Databricks, PAT, Preview"
"Databricks","Azure_Databricks_NetSec_Justify_VNet_Peering","Use of any virtual network peerings should be justified","Important","No","Yes","Resources??in the peered virtual networks can communicate with each other directly. If the two peered networks are on different sides of a security boundary (e.g., corpnet v. private vNet), this can lead to exposure of corporate data. Hence any vNet peerings should be closely scrutinized and approved by the network security team","You can remove any virtual network peering by navigating to Azure portal --> Databricks --> Virtual Network Peerings --> select vNET peering --> Delete (unless their presence has been approved by network security team).","Yes","No","SDL, Best Practice, Automated, NetSec, Databricks, Preview"
"ServiceBus","Azure_ServiceBus_AuthZ_Dont_Use_Policies_At_SB_Namespace","Service bus clients (senders/receivers) must not use 'namespace' level access policies","Important","No","No","A 'namespace' level access policy provides access to all Queues/Topics in a namespace. However, using an access policy at entity (Queue/Topic) level provides access only to the specific entity. Thus using the latter is inline with the principle of least privilege.","Remove all the authorization rules from Service Bus namespace except RootManageSharedAccessKey using Remove-AzServiceBusAuthorizationRule command. Run 'Get-Help Remove-AzServiceBusAuthorizationRule -full' for more help. Use the Azure portal to configure shared access policies with appropriate claims at the specific entity (Topic/Queue) scope.","Yes","No","SDL, TCP, Automated, AuthZ, ServiceBus"
"ServiceBus","Azure_ServiceBus_AuthZ_Use_Minimum_Access_Policies","Access policies must be defined with minimum required permissions","Moderate","No","No","Granting minimum access ensures that users are granted just enough permissions to perform their tasks. This minimizes operation preformed on the resource in case of access policy key compromise.","Access policies must have the minimum required permissions. For instance, if the client app is only reading a Topic or a Queue (as opposed to sending), then the policy used must only include the 'Listen' claim. Refer: https://docs.microsoft.com/en-us/azure/service-bus-messaging/service-bus-sas","Yes","No","SDL, TCP, AuthZ, Automated, ServiceBus"
"ServiceBus","Azure_ServiceBus_DP_Protect_Keys_at_Rest","Access policy keys must be protected at rest","Important","No","No","Using this feature ensures that sensitive data is stored encrypted at rest. This minimizes the risk of data loss from physical theft and also helps meet regulatory compliance requirements.","Access policy keys must be handled in a secure manner. E.g., Access policy keys can be stored in the application settings on the Azure portal for a Web App, or can be stored in a Key Vault. The approach to protect the key may vary based on the Azure feature and scenario from where Event Hubs are consumed.","No","No","SDL, TCP, Manual, DP, ServiceBus"
"ServiceBus","Azure_ServiceBus_DP_Rotate_Keys","Access policy keys must be rotated periodically","Moderate","No","No","Periodic key/password rotation is a good security hygiene practice as, over time, it minimizes the likelihood of data loss/compromise which can arise from key theft/brute forcing/recovery attacks.","Use New-AzServiceBusKey -ResourceGroupName <ResourceGroupName> -Namespace <NamespaceName> -Queue <QueueName> -RegenerateKey PrimaryKey/SecondaryKey to regenerate Queue key. Use New-AzServiceBusKey -ResourceGroupName <ResourceGroupName> -Namespace <NamespaceName> -Topic <TopicName> -RegenerateKey PrimaryKey/SecondaryKey to regenerate Topic key. Use New-AzServiceBusKey -ResourceGroupName <ResourceGroupName> -Namespace <NamespaceName> -RegenerateKey PrimaryKey/SecondaryKey to regenerate namespace key. Caution: Make sure that the newly generated keys are seamlessly deployed to clients to avoid disruption of functionality.","No","No","SDL, TCP, Manual, DP, ServiceBus"
"ServiceBus","Azure_ServiceBus_Audit_Review_logs","Audit logs for Service Bus entities should be reviewed routinely","Moderate","No","No","Auditing enables log collection of important system events pertinent to security. Regular monitoring of audit logs can help to detect any suspicious and malicious activity early and respond in a timely manner.","Audit log can be reviewed at Portal -> Service Bus -> <Your Service Bus Name> -> Diagnostics logs. Reference: https://docs.microsoft.com/en-us/azure/service-bus-messaging/service-bus-diagnostic-logs","No","No","SDL, Best Practice, Manual, Audit, ServiceBus"
"ServiceBus","Azure_ServiceBus_DP_Encrypt_in_Transit","Sensitive data must be encrypted in transit ","Important","No","No","Use of HTTPS ensures server/service authentication and protects data in transit from network layer man-in-the-middle, eavesdropping, session-hijacking attacks.","Default behavior. No action required.","No","No","SDL, Information, Manual, DP, ServiceBus"
"ServiceBus","Azure_ServiceBus_AuthZ_Use_Min_Token_Lifetime","Expiry time of SAS token should be minimum required","Moderate","No","No","If SAS token gets compromised, unauthorized users can access Service Bus entities. Minimizing the validity period of the SAS token ensures that the window of time available to an attacker in the event of compromise is minimized.","Set expiry time of SAS tokens to the minimum required in context of the scenario. Refer: https://docs.microsoft.com/en-us/azure/service-bus-messaging/service-bus-sas#generate-a-shared-access-signature-token","No","No","SDL, Best Practice, Manual, AuthZ, ServiceBus"
"ServiceBus","Azure_ServiceBus_BCDR_Paired_Namespace_In_Diff_Center","Paired Namespace should be used for disaster recovery","Moderate","No","No","Paired namespace helpful to maintain consistent availability of ServiceBus in case of ServiceBus outage (e.g. throttling, storage issue, subsystem failure) in primary region.","In case of Service Bus outage (e.g. throttling, storage issue, single subsystem failure, Azure data center failure), messages sent by sender application will not be received by Service Bus. To maintain consistent availability of application, Service Bus users should use a paired namespace in a different data center. Paired namespace  will send the messages to secondary queue(s) while primary queue is down. (Messages from secondary queue will be transferred to primary queue when primary queue becomes available again). Refer: https://azure.microsoft.com/en-in/documentation/articles/service-bus-paired-namespaces/","No","No","SDL, Best Practice, Manual, BCDR, ServiceBus"
"ServiceBus","Azure_ServiceBus_AuthZ_Grant_Min_RBAC_Access","All users/identities must be granted minimum required permissions using Role Based Access Control (RBAC)","Moderate","No","No","Granting minimum access by leveraging RBAC feature ensures that users are granted just enough permissions to perform their tasks. This minimizes exposure of the resources in case of user/service account compromise.","Administrator should assign 'Owner' role to Service Bus at the 'resource' scope. Application developers should not have direct access to the Service Bus resource (they should just be provided the required shared access policy for a non-production Topic/Queue entity). Auditors should have 'Monitor Contributor Service Role' or 'Monitor Reader Service Role' based on their role.","Yes","No","SDL, TCP, Automated, AuthZ, RBAC, ServiceBus"
"ServiceBus","Azure_ServiceBus_Audit_Enable_Diagnostics_Log","Diagnostics logs must be enabled with a retention period of at least 365 days.","Moderate","No","No","Logs should be retained for a long enough period so that activity trail can be recreated when investigations are required in the event of an incident or a compromise. A period of 1 year is typical for several compliance requirements as well.","You can change the diagnostic settings from the Azure Portal by following the steps given here: https://docs.microsoft.com/en-us/azure/monitoring-and-diagnostics/monitoring-archive-diagnostic-logs#archive-diagnostic-logs-using-the-portal","Yes","No","SDL, TCP, Automated, Audit, Diagnostics, ServiceBus"
"KeyVault","Azure_KeyVault_AuthN_Use_Cert_Auth_for_Apps","Azure Active Directory applications, which have access to Key Vault, must use certificate to authenticate to Key Vault","Important","No","No","Password/shared secret credentials can be easily shared and hence can be easily compromised. Certificate credentials offer better security.","Remove any password credentials from Azure AD Applications and use certificate credentials instead. Run command Remove-AzureADApplicationPasswordCredential -InformationAction '{ActionPreference}' -InformationVariable '{InformationVariable}' -KeyId '{KeyId}' -ObjectId '{ObjectId}'. Refer: https://docs.microsoft.com/en-us/powershell/module/azuread/remove-azureadapplicationpasswordcredential?view=azureadps-2.0, https://docs.microsoft.com/en-us/azure/active-directory/develop/active-directory-certificate-credentials#register-your-certificate-with-azure-ad","Yes","No","SDL, TCP, Automated, AuthN, OwnerAccess, KeyVault"
"KeyVault","Azure_KeyVault_AuthN_Dont_Share_KeyVault_Unless_Trust","Applications must not share a Key Vault unless they trust each other and they need access to the same secrets at runtime","Important","No","Yes","Key Vault contains critical information like credentials/secrets etc. All applications can access all secrets from a given Key Vault. This can violate trust boundaries between applications.","Ensure that there is a clear need for apps to share secrets if they are sharing a Key Vault. Else setup independent Key Vaults for each application.","Yes","No","SDL, TCP, Automated, AuthN, KeyVault, OwnerAccess, GraphRead"
"KeyVault","Azure_KeyVault_AuthZ_Grant_Min_RBAC_Access","All users/identities must be granted minimum required permissions using Role Based Access Control (RBAC)","Important","No","No","Granting minimum access by leveraging RBAC feature ensures that users are granted just enough permissions to perform their tasks. This minimizes exposure of the resources in case of user/service account compromise.","Remove any excessive privileges granted on the Key Vault. Run command Remove-AzRoleAssignment -SignInName '{signInName}' -Scope '{scope}' -RoleDefinitionName '{role definition name}'. Run 'Get-Help Remove-AzRoleAssignment -full' for more help. Assign 'Key Vault Contributor' RBAC role to developers who need to manage Key Vault configurations. Refer: https://docs.microsoft.com/en-us/azure/key-vault/key-vault-secure-your-key-vault, https://docs.microsoft.com/en-us/azure/active-directory/role-based-access-control-manage-access-powershell","Yes","No","SDL, TCP, Automated, AuthZ, RBAC, KeyVault"
"KeyVault","Azure_KeyVault_AuthZ_Grant_Min_Access_policies","All Key Vault access policies must be defined with minimum required permissions to keys and secrets","Important","No","No","Granting minimum access by defining Key Vault access policies ensures that applications/users are granted just enough permissions to perform their tasks. This minimizes exposure of the resources in case of user/service account compromise.","Use command Set-AzKeyVaultAccessPolicy -VaultName '{VaultName}' -ResourceGroupName '{ResourceGroupName}' ??-PermissionsToKeys '{PermissionsToKeys}' -PermissionsToSecrets '{PermissionsToSecrets}' ??-PermissionsToCertificates '{PermissionsToCertificates}' -ObjectId '{ObjectId}'. Refer: ??https://docs.microsoft.com/en-us/powershell/module/az.keyvault/Set-AzKeyVaultAccessPolicy","Yes","No","SDL, TCP, Automated, AuthZ, RBAC, KeyVault"
"KeyVault","Azure_KeyVault_AuthZ_Configure_Advanced_Access_Policies","Advanced access policies must be configured on a need basis","Moderate","No","No","Advanced access policy allows Azure services (Azure Resource Manager, Virtual Machine, Disk Encryption etc.) to seamlessly access Key Vault. To avoid unintentional access to Key Vault from Azure services, advanced access policies must be configured only as required.","Remove any advanced policies that are not required using the command: Remove-AzKeyVaultAccessPolicy -VaultName '{VaultName}' -ResourceGroupName '{ResourceGroupName}' -EnabledForDeployment -EnabledForTemplateDeployment -EnabledForDiskEncryption. Refer: https://docs.microsoft.com/en-us/powershell/module/az.keyvault/Remove-AzKeyVaultAccessPolicy","Yes","No","SDL, TCP, Automated, AuthZ, KeyVault"
"KeyVault","Azure_KeyVault_DP_Keys_Protect_By_HSM","All Keys in Key Vault must be protected by HSM [Key Type = HSM Protected Key]","Moderate","No","No","A hardware security module (HSM) is a physical device that provides extra security for sensitive data like Keys. HSMs make sure that the keys never leave the HSM boundary throughout their lifecycle. Using HSMs for key protection is required for keys that encrypt highly sensitive data (often in regulated environments).","Remove the non-HSM keys and recreate the removed ones within a destination Key Vault of type HSM. Run command Remove-AzKeyVaultKey -VaultName '{KeyVaultName}' -Name '{KeyName}' to remove non-HSM key. Use command Add-AzKeyVaultKey -VaultName ??'{VaultName}' -Name '{KeyName}' -Expires '{ExpiryDate}' -Destination 'HSM' -KeyOps '{KeyOps}'. Refer: https://docs.microsoft.com/en-us/powershell/module/az.keyvault/remove-azkeyvaultkey, https://docs.microsoft.com/en-us/powershell/module/az.keyvault/add-azkeyvaultkey","Yes","No","SDL, TCP, Automated, DP, KeyVault, KeySecretPermissions"
"KeyVault","Azure_KeyVault_DP_Keys_Secrets_Check_Expiry_Date","All Keys and Secrets in Key Vault must have expiration dates","Moderate","No","No","Expiration dates on keys ensure that keys are rotated on a periodic basis. Key rotation is an important security hygiene activity.","To add an expiry date to keys, run command: Update-AzKeyVaultKey -VaultName '{KeyVaultName}' -Name '{KeyName}' -Expires '{ExpiryDate}'. Expiry date should not be more than 365 days for keys. To add an expiry date to secrets, run command: Update-AzKeyVaultSecret -VaultName '{KeyVaultName}' -Name '{SecretName}' -Expires '{ExpiryDate}', Expiry date should not be more than 180 days for secrets.","Yes","No","SDL, TCP, Automated, DP, KeyRotation, OwnerAccess, KeyVaultAccess, KeyVault, KeySecretPermissions"
"KeyVault","Azure_KeyVault_Audit_Enable_Diagnostics_Log","Diagnostics logs must be enabled with a retention period of at least 365 days.","Moderate","No","No","Logs should be retained for a long enough period so that activity trail can be recreated when investigations are required in the event of an incident or a compromise. A period of 1 year is typical for several compliance requirements as well.","You can change the diagnostic settings from the Azure Portal by following the steps given here: https://docs.microsoft.com/en-us/azure/monitoring-and-diagnostics/monitoring-archive-diagnostic-logs#archive-diagnostic-logs-using-the-portal","Yes","No","SDL, TCP, Automated, Audit, Diagnostics, KeyVault"
"KeyVault","Azure_KeyVault_AuthN_Key_Min_Operation","Restrict the cryptographic operations permitted using keys to the ones actually required","Important","No","No","Restricting the operations to be performed on Keys ensures that applications/users can perform only intended operations. This minimizes exposure of the Keys in case of user/service account compromise.","Run command Update-AzKeyVaultKey -VaultName '{KeyVaultName}' -Name '{KeyName}' -KeyOps '{KeyOps}'. Refer: https://docs.microsoft.com/en-us/powershell/module/az.keyvault/update-azkeyvaultkey","Yes","No","SDL, TCP, Automated, AuthN, KeyVault, KeySecretPermissions"
"KeyVault","Azure_KeyVault_DP_Identify_Roles","Key Vault owner must grant minimum required access to keys/secrets based on individual roles (Developer/Operator/Auditor/Security Team)","Important","No","No","Identifying and assigning various roles ensures proper separation of duties.","Key Vault owner must identify different roles that need various levels of access on keyvault keys/secrets and configure them using a least privilege model. Refer: https://docs.microsoft.com/en-us/azure/key-vault/key-vault-secure-your-key-vault","No","No","SDL, TCP, Manual, DP, KeyVault"
"KeyVault","Azure_KeyVault_DP_Rotate_Key_Periodocally","Keys/secrets must be rotated periodically","Moderate","No","No","Periodic key/password rotation is a good security hygiene practice as, over time, it minimizes the likelihood of data loss/compromise which can arise from key theft/brute forcing/recovery attacks.","Rotate the keys and secrets at regular intervals. Run command: Update-AzKeyVaultKey -VaultName '{KeyVaultName}' -Name '{KeyName}' -Expires '{ExpiryDate}' -Version '{Version}' to generate new version for key. Run command: Update-AzKeyVaultSecret -VaultName '{KeyVaultName}' -Name '{KeyName}' -Expires '{ExpiryDate}' ??-Version ??'{Version}' ??to generate new version for secret.","No","No","SDL, TCP, Manual, DP, KeyVault"
"KeyVault","Azure_KeyVault_Audit_Review_Logs","Diagnostic logs for Key Vault must be reviewed periodically","Moderate","No","No","Periodic reviews of diagnostics, activity and audit logs ensures that anomalous activity can be identified early enough instead of after a major compromise.","Review diagnostic logs at regular intervals for different operations carried out on keys and secrets. Refer: https://docs.microsoft.com/en-us/azure/log-analytics/log-analytics-azure-key-vault","No","No","SDL, TCP, Manual, Audit, KeyVault"
"KeyVault","Azure_KeyVault_SI_Enable_SoftDelete","Soft delete must be enabled to allow recovery of deleted Key Vault and any objects (keys, secrets, etc.) contained in it.","Moderate","No","No","Enabling soft delete feature on Key Vault acts as a safety measure to recover inadvertently or maliciously deleted Key Vault and any objects (keys, secrets, etc.) contained in it.","Refer: https://docs.microsoft.com/en-us/azure/key-vault/key-vault-soft-delete-powershell to enable soft delete feature on Key Vault.","Yes","No","SDL, TCP, Automated, KeyVault"
"KeyVault","Azure_KeyVault_Avoid_Excessive_Versions_Keys_Secrets","Too many versions of keys or secrets should not be in use.","Moderate","No","No","Having too many active versions can lead to increased complexity of solutions due to difficulty of tracking what is in use where, indirectly leading to security vulnerability due to oversight. Additionally, it can also adversely affect performance and availability.","Disable older versions of keys and secrets that are no longer required. Go to the Azure Portal > Key Vault > Settings > Keys or Secrets. Select the key or secret that has too many versions, and choose the version that needs to be disabled. Set 'Enabled' attribute as 'No'. For more on the Azure Key Vault service limits, refer: https://docs.microsoft.com/en-us/azure/key-vault/key-vault-service-limits","Yes","No","SDL, TCP, Automated, KeySecretPermissions, KeyVault"
"Batch","Azure_Batch_AuthZ_Grant_Min_RBAC_Access","All users/identities must be granted minimum required permissions using Role Based Access Control (RBAC)","Moderate","No","No","Granting minimum access by leveraging RBAC feature ensures that users are granted just enough permissions to perform their tasks. This minimizes exposure of the resources in case of user/service account compromise.","Remove any excessive privileges granted on the Batch service. Run command Remove-AzRoleAssignment -SignInName '{signInName}' -Scope '{scope}' -RoleDefinitionName '{role definition name}'. Run 'Get-Help Remove-AzRoleAssignment -full' for more help. Refer: https://docs.microsoft.com/en-us/azure/active-directory/role-based-access-control-manage-access-powershell","Yes","No","SDL, TCP, Automated, AuthZ, RBAC, Batch"
"Batch","Azure_Batch_DP_Encrypt_Linked_Storage","Storage Account, linked with Batch account, must be protected using Storage Service Encryption (SSE)","Important","No","No","Using this feature ensures that sensitive data is stored encrypted at rest. This minimizes the risk of data loss from physical theft and also helps meet regulatory compliance requirements.","Default behavior. No action required.","No","No","SDL, TCP, Manual, Information, DP, Batch"
"Batch","Azure_Batch_DP_Protect_Secrets_On_Compute_Nodes","Secrets associated with tasks must be protected on Batch service compute nodes","Important","No","No","Encrypting the sensitive data like secrets/keys minimizes the exposure until runtime. Using the uploaded certificates, compute nodes can decrypt the secrets as needed at runtime.","Certificates need to be installed on the compute nodes used by Batch in order to protect sensitive information. Run command New-AzBatchCertificate  -FilePath '{FilePath}'  -BatchContext '{BatchContext}' -Password '{Password}'. Note: Password value should be a secure string variable. Please refer https://docs.microsoft.com/en-us/azure/batch/batch-api-basics#security-with-certificates","No","No","SDL, TCP, Manual, DP, Batch"
"Batch","Azure_Batch_DP_Rotate_Access_Keys","Batch account access keys must be rotated periodically","Moderate","No","No","Periodic key/password rotation is a good security hygiene practice as, over time, it minimizes the likelihood of data loss/compromise which can arise from key theft/brute forcing/recovery attacks.","Rotate Batch account access keys at regular intervals as per business requirement. Run command New-AzBatchAccountKey -AccountName '{AccountName}'  -KeyType '{KeyType}' -ResourceGroupName '{ResourceGroupName}' Refer: https://docs.microsoft.com/en-us/powershell/module/az.batch/New-AzBatchAccountKey","No","No","SDL, TCP, Manual, DP, Batch"
"Batch","Azure_Batch_NetSec_Disable_RDP_Connection","Remote desktop connection should be disabled on Batch account compute nodes","Important","No","No","Open RDP/remote management connections expose a VM/compute node to a high level of risk from internet-based attacks that attempt to brute force credentials to gain access to the machine.","Remote desktop connection should be disabled. Refer: https://docs.microsoft.com/en-us/azure/cloud-services/cloud-services-role-enable-remote-desktop-powershell","No","No","SDL, Best Practice, Manual, NetSec, Batch"
"Batch","Azure_Batch_BCDR_Persist_Output_To_Storage","Batch account tasks and jobs should be configured to persist output to Azure Blob Storage","Moderate","No","No","Batch service works on the compute nodes. It is good to persist the data into SSE enabled storage account. Otherwise, on the crash of compute node, would result in the data loss.","Use Azure blob storage to persist Batch account tasks and jobs. Refer: https://docs.microsoft.com/en-us/azure/batch/batch-task-output","No","No","SDL, Best Practice, Manual, BCDR, Batch"
"Batch","Azure_Batch_Audit_Enable_Diagnostics_Log","Diagnostics logs must be enabled with a retention period of at least 365 days","Moderate","No","No","Logs should be retained for a long enough period so that activity trail can be recreated when investigations are required in the event of an incident or a compromise. A period of 1 year is typical for several compliance requirements as well.","You can change the diagnostic settings from the Azure Portal by following the steps given here: https://docs.microsoft.com/en-us/azure/monitoring-and-diagnostics/monitoring-archive-diagnostic-logs#archive-diagnostic-logs-using-the-portal","Yes","No","SDL, TCP, Automated, Audit, Diagnostics, Batch"
"Batch","Azure_Batch_Audit_Enable_Metric_Alert","Metric alert rules must be configured on Batch account","Low","No","No","Metric alerts should be enabled to get alerts for issues that impacts the performance of batch resource when a metric crosses a certain threshold.","To setup alert rule for 'Pool Delete Complete Events' and 'Pool Delete Start Events' events (1) Go to Batch service -> 'Alerts' -> 'New alert rule' -> 'Add condition' (2) Select Signal type as 'Metrics' -> Select 'Pool Delete Complete Events'/'Pool Delete Start Events' -> Select a. Operator = 'Greater Than' b. Aggregation type = 'Total' c. Threshold value = '0' and d. Aggregation granularity = '1 hour' (3) Select an existing Action Group or create a new one of type 'Email/SMS/Push/Voice'. Select 'Email' option and specify the email id.","Yes","No","SDL, Best Practice, Automated, Audit, Batch"
"CloudService","Azure_CloudService_AuthN_Use_AAD_for_Client_AuthN","Cloud Service must authenticate users using Azure Active Directory backed credentials","Important","Yes","No","Using the native enterprise directory for authentication ensures that there is a built-in high level of assurance in the user identity established for subsequent access control.All Enterprise subscriptions are automatically associated with their enterprise directory (xxx.onmicrosoft.com) and users in the native directory are trusted for authentication to enterprise subscriptions.","Create an AAD App. Configure the App with your cloud service URLs to enforce AAD auth for every request. Refer: https://blogs.msdn.microsoft.com/visualstudio/2014/11/19/connecting-to-cloud-services/","No","No","SDL, AuthN, Classic, Manual"
"CloudService","Azure_CloudService_DP_DontAllow_HTTP_Access_InputEndpoints","Cloud Service must only be accessible over HTTPS. Enable https for InputEndpoints.","Important","Yes","No","Use of HTTPS ensures server/service authentication and protects data in transit from network layer man-in-the-middle, eavesdropping, session-hijacking attacks.","Get an SSL certificate from a trusted certificate provider. Upload that certificate to cloud service. Update input endpoints by renaming HTTP to HTTPS in .csdef. Refer: https://docs.microsoft.com/en-us/azure/cloud-services/cloud-services-configure-ssl-certificate","Yes","No","SDL, Automated, DP, Classic"
"CloudService","Azure_CloudService_SI_Validate_InternalEndpoints","Remove unused internal endpoints","Moderate","No","No","Internal endpoints are available for instance-to-instance communication with in cloud service. Exploitation of one such internal instance can put all the other internal instances at risk with which it has open communication channels.","Remove unused internal endpoints from .csdef and redeploy your cloud service to reflect the new changes. Refer: https://azure.microsoft.com/en-us/documentation/articles/cloud-services-enable-communication-role-instances","Yes","No","SDL, Automated, Classic, OwnerAccess, SI"
"CloudService","Azure_CloudService_SI_Validate_InputEndpoints","Remove unused input endpoints","Moderate","No","No","The input endpoint is used when you want to expose a port to the outside from a cloud service. Such unintended open connections expose cloud service instances to a high level of risk from internet-based attacks that attempt to brute force credentials to gain access to the machine.","Remove unused input endpoints from .csdef and redeploy your cloud service to reflect the new changes. Refer: https://azure.microsoft.com/en-us/documentation/articles/cloud-services-enable-communication-role-instances","Yes","No","SDL, Automated, SI, Classic"
"CloudService","Azure_CloudService_SI_Disable_RemoteDebugging","Remote debugging must be turned off","Important","No","Yes","Remote debugging requires inbound ports to be opened. These ports become easy targets for compromise from various internet based attacks.","Remove [Microsoft.WindowsAzure.Plugins.RemoteDebugger*] endpoints from .csdef and redeploy your cloud service to reflect the new changes. Refer: https://docs.microsoft.com/en-us/azure/vs-azure-tools-debug-cloud-services-virtual-machines","Yes","No","SDL, Automated, Classic, OwnerAccess, SI"
"CloudService","Azure_CloudService_DP_CNAME_with_SSL","A CNAME should be configured for the cloud service.","Moderate","No","No","Use of custom domain protects a web application from common attacks such as phishing, session hijacking and other DNS-related attacks.","Get an SSL certificate for your CNAME from a trusted certificate provider and upload the same to your cloud service. Map the VIP of your cloud service at your DNS registrar's website. Refer: https://docs.microsoft.com/en-us/azure/cloud-services/cloud-services-custom-domain-name","No","No","SDL, Classic, OwnerAccess, Manual, DP"
"CloudService","Azure_CloudService_SI_Auto_OSUpdate","OS version should be set to automatic.","Important","Yes","No","Cloud services where automatic updates are disabled are likely to miss important security patches (human error, forgetfulness). This may lead to compromise from various malware/trojan attacks that exploit known vulnerabilities in operating systems and related software.","To enable automatic updates: Go to manage Azure portal --> your cloud service --> under configure tab --> set operating system version to automatic.","Yes","No","SDL, Automated, SI, Classic"
"CloudService","Azure_CloudService_SI_Enable_AntiMalware","Enable the Antimalware extension for the cloud service roles","Important","Yes","No","Antimalware provides real-time protection, scheduled scanning, malware remediation, signature updates, engine updates, samples reporting, exclusion event collection etc.","To enable Antimalware: Go to Azure portal --> your cloud service --> Antimalware under Settings section--> select role and enable Antimalware.","Yes","No","SDL, Automated, Classic, OwnerAccess, SI"
"CloudService","Azure_CloudService_SI_Disable_RemoteDesktop_Access","Remote Desktop (RDP) access must be disabled on cloud service roles","Important","Yes","No","Remote desktop access requires inbound ports to be opened. These ports become easy targets for compromise from various internet based attacks.","Go to Azure portal --> your cloud service --> Remote Desktop under Settings section --> disable Remote Desktop","Yes","No","SDL, Automated, Classic, OwnerAccess, SI"
"LogicApps","Azure_LogicApps_Deploy_Dont_Use_Apps_In_Same_RG_Unless_Trust","Multiple Logic Apps should not be deployed in the same resource group unless they trust each other","Important","No","No","API Connections contain critical information like credentials/secrets, etc., provided as part of configuration. Logic App can use all API Connections present in the same Resource Group. Thus, Resource Group should be considered as security boundary when threat modeling.","Separate Logic Apps into different resource groups unless the apps trust each other and need to use API Connections present in the resource group.","Yes","No","SDL, Best Practice, Automated, Deploy"
"LogicApps","Azure_LogicApps_AuthZ_Connector_Use_Min_Permissions","Logic App connectors must have minimum required permissions on data source","Moderate","No","No","This ensures that connectors can be used only towards intended actions in the Logic App","Connectors must be configured with minimum permissions. E.g., 'SQL Server-Get Row' must use an account with only Read permission on the required table.","No","No","SDL, TCP, Manual, AuthZ"
"LogicApps","Azure_LogicApps_AuthZ_Grant_Min_RBAC_Access","All users/identities must be granted minimum required permissions using Role Based Access Control (RBAC)","Moderate","No","No","Granting minimum access by leveraging RBAC feature ensures that users are granted just enough permissions to perform their tasks. This minimizes exposure of the resources in case of user/service account compromise.","Assign 'Logic App Contributor' role to developers and 'Logic App Operator' role to operators. Refer: https://docs.microsoft.com/en-us/azure/logic-apps/logic-apps-securing-a-logic-app#secure-access-to-manage-or-edit-logic-apps","Yes","No","SDL, TCP, Automated, AuthZ, RBAC"
"LogicApps","Azure_LogicApps_AuthZ_Provide_Triggers_Access_Control","If Logic App fires on an HTTP Request (e.g. Request or Webhook) then provide IP ranges for triggers to prevent unauthorized access","Important","No","No","Specifying the IP range ensures that the triggers can be invoked only from a restricted set of endpoints.","Provide access control by navigating to Portal --> Logic App --> Workflow settings --> Access Control Configuration and setting the IP addresses/ranges. Do not add IP range 0.0.0.0-255.255.255.255 as this means access to all IPs. Note: In case the IP range is indeterminate (for instance, if the client is a PaaS endpoint), you may need to attest this control.","Yes","No","SDL, TCP, Automated, AuthZ"
"LogicApps","Azure_LogicApps_AuthZ_Provide_Contents_Access_Control","Must provide IP ranges for contents to prevent unauthorized access to inputs/outputs data of Logic App run history","Important","No","No","Using the firewall feature ensures that access to the data or the service is restricted to a specific set/group of clients. While this may not be feasible in all scenarios, when it can be used, it provides an extra layer of access control protection for critical assets.","Provide access control by navigating to Portal --> Logic App --> Workflow settings --> Access Control Configuration and setting the IP addresses/ranges. Do not add IP range 0.0.0.0-255.255.255.255 as this means access to all IPs. Note: In case the IP range is indeterminate (for instance, if the client is a PaaS endpoint), you may need to attest this control.","Yes","No","SDL, TCP, Automated, AuthZ"
"LogicApps","Azure_LogicApps_DP_Dont_Allow_PlainText_Secrets_In_Codeview","Application secrets and credentials must not be in plain text in source code (code view) of a Logic App","Important","No","No","Keeping secrets such as DB connection strings, passwords, keys, etc. in clear text can lead to easy compromise at various avenues during an application's lifecycle. Storing them in a key vault ensures that they are protected at rest.","Use 'secureString' type parameter in Logic App code view for secret parameters. Refer: https://docs.microsoft.com/en-us/azure/logic-apps/logic-apps-securing-a-logic-app#secure-parameters-and-inputs-within-a-workflow","Yes","No","SDL, TCP, Automated, DP"
"LogicApps","Azure_LogicApps_DP_Rotate_Keys","Logic App access keys must be rotated periodically","Moderate","No","No","Periodic key/password rotation is a good security hygiene practice as, over time, it minimizes the likelihood of data loss/compromise which can arise from key theft/brute forcing/recovery attacks.","Rotate access keys at regular intervals. Naviagte to Logic App --> Access Keys --> Regenerate Access Key to generate a new access key.","No","No","SDL, TCP, Manual, DP"
"LogicApps","Azure_LogicApps_Audit_Enable_Diagnostics_Log","Diagnostics logs must be enabled with a retention period of at least 365 days.","Moderate","No","No","Logs should be retained for a long enough period so that activity trail can be recreated when investigations are required in the event of an incident or a compromise. A period of 1 year is typical for several compliance requirements as well.","You can change the diagnostic settings from the Azure Portal by following the steps given here: https://docs.microsoft.com/en-us/azure/monitoring-and-diagnostics/monitoring-archive-diagnostic-logs#archive-diagnostic-logs-using-the-portal","Yes","No","SDL, TCP, Automated, Audit, Diagnostics"
"LogicApps","Azure_LogicApps_BCDR_Backup_Periodically","Logic App Code View code should be backed up periodically","Moderate","No","No","Logic App code view contains application's workflow logic and API connections detail which could be lost if there is no backup. No backup/disaster recovery feature is available out of the box in Logic Apps.","Navigate to Logic App --> Logic App Code View and save content to a backup location.","No","No","SDL, Best Practice, Manual, BCDR"
"AzSKCfg","Azure_AzSKCfg_Check_Presence_of_CA","Continuous Assurance automation account must be present in the subscription","Important","Yes","No","Presence of CA ensures that regular scan is happening for your cloud subscription and resources.","To install Continuous Assurance automation account, run command: Install-AzSKContinuousAssurance.For more details, please refer https://github.com/azsk/DevOpsKit-docs/blob/master/04-Continous-Assurance/Readme.md#setting-up-continuous-assurance---step-by-step","Yes","No","SDL, TCP, Automated, AzSKCfgControl"
"AzSKCfg","Azure_AzSKCfg_Check_Health_of_CA","Continuous Assurance automation account must be in a healthy state","Important","Yes","No","Presence of CA ensures that regular scan is happening for your cloud subscription and resources.","Run command: 'Get-AzSKContinuousAssurance -SubscriptionId <subId>'.Follow the recommendation given to bring CA in healthy state","Yes","No","SDL, TCP, Automated, GraphRead, AzSKCfgControl"
"AzSKCfg","Azure_AzSKCfg_Check_Presence_of_Latest_AzSK_Module","AzSK scans must use latest version of the AzSK Module","Important","Yes","No","With each release new security updates are being added. Using the latest AzSK module ensures that your cloud subscription and resources are scanned with the latest controls.","Re-run install command to get latest AzSK module","Yes","No","SDL, TCP, Automated, AzSKCfgControl"
"DataFactoryV2","Azure_DataFactoryV2_AuthZ_Grant_Min_Access","User accounts/roles connecting to data source must have minimum required permissions","Moderate","No","No","Granting minimum access ensures that users are granted just enough permissions to perform their tasks. This minimizes exposure of the resources in case of user/service account compromise.","All user accounts/roles which are involved in Azure Data Factory must have minimum required access rights to data sources. (e.g. If the Data Factory is just reading data from the data source then the account employed must use just read-only access.)","No","No","SDL, TCP, Manual, DataFactoryV2, AuthZ"
"DataFactoryV2","Azure_DataFactoryV2_DP_KeyVault_for_LinkedSvc_Credentials","All linked service credentials should be stored in Key Vault.","Moderate","No","No","Keeping secrets such as DB connection strings, passwords, keys, etc., in clear text can lead to easy compromise at various avenues during an application's lifecycle. Storing them in a key vault ensures that they are protected at rest.","Refer: https://docs.microsoft.com/en-us/azure/data-factory/store-credentials-in-key-vault","No","No","SDL, TCP, DP, DataFactoryV2, Manual"
"DataFactoryV2","Azure_DataFactoryV2_AuthN_Use_Service_Identity","Data factory must use a service identity for authenticating to supported linked services.","Moderate","No","No","Using a service identity for authentication ensures that there is a built-in high level of assurance for subsequent access control.","If the data factory was created through Azure SDK or REST API and does not have a service identity then run command: Set-AzDataFactoryV2 -ResourceGroupName <resourceGroupName> -Name <dataFactoryName> -Location <region>","No","No","SDL, Best Practice, DP, DataFactoryV2, Manual"
"DataFactoryV2","Azure_DataFactoryV2_DP_Configure_Secure_Output","Configure activity output as 'Secure Output' if the activity emits sensitive data.","Moderate","No","No","Configuring activity output as 'Secure Output' prevents it from getting logged to monitoring.","To enable secure output, please follow these steps - (a) Logon to https://portal.azure.com/ (b) Navigate to 'Data factories' (c) Navigate to the data factory you want to modify (d) Click on the 'Author and Monitor'. This will launch the data factory portal (e) Select the appropriate activity under the pipeline you want to modify (f) Go to 'General' tab and select the checkbox 'Secure Output' (g) Publish the pipeline.","No","No","SDL, Best Practice, DP, DataFactoryV2, Manual"
"Storage","Azure_Storage_AuthN_Dont_Allow_Anonymous","The Access Type for containers must not be set to 'Anonymous'","Important","Yes","No","Data in containers that have anonymous access can be downloaded by anyone on the internet without authentication. This can lead to a compromise of corporate data.","Run command 'Set-AzStorageContainerAcl -Name '<ContainerName>' -Permission 'Off' -Context (New-AzStorageContext -StorageAccountName '<StorageAccountName>' -StorageAccountKey '<StorageAccountKey>')'. Run 'Get-Help Set-AzStorageContainerAcl -full' for more help.","Yes","Yes","SDL, TCP, Automated, AuthN, StandardSku, PremiumSku, GeneralPurposeStorage, BlobStorage, HNSDisabled, ResourceLocked"
"Storage","Azure_Storage_Audit_AuthN_Requests","Storage Account must be configured to log and monitor authentication request data","Moderate","No","No","Logging and monitoring of authentication request data can help to detect suspicious and malicious activities early and respond in a timely manner.","Run command 'Set-AzStorageServiceLoggingProperty -ServiceType '<Blob/Queue/Table>' -LoggingOperations 'All' -Context '<StorageContext>' -RetentionDays '365' -PassThru'. Run 'Get-Help Set-AzStorageServiceLoggingProperty -full' for more help. Set-AzStorageServiceMetricsProperty -MetricsType 'Hour' -ServiceType '<Blob/Queue/Table/File>' -Context '<StorageContext>' -MetricsLevel 'ServiceAndApi' -RetentionDays '365' -PassThru. Run 'Get-Help Set-AzStorageServiceMetricsProperty -full' for more help.","Yes","Yes","SDL, TCP, Automated, Audit, OwnerAccess, StandardSku, GeneralPurposeStorage, BlobStorage, ResourceLocked"
"Storage","Azure_Storage_DP_Encrypt_In_Transit","HTTPS protocol must be used for accessing Storage Account resources","Important","Yes","No","Use of HTTPS ensures server/service authentication and protects data in transit from network layer man-in-the-middle, eavesdropping, session-hijacking attacks. When enabling HTTPS one must remember to simultaneously disable access over plain HTTP else data can still be subject to compromise over clear text connections.","Run command 'Set-AzStorageAccount -ResourceGroupName <RGName> -Name <StorageAccountName> -EnableHttpsTrafficOnly $true'. Run 'Get-Help Set-AzStorageAccount -full' for more help.","Yes","Yes","SDL, TCP, Automated, DP, StandardSku, PremiumSku, GeneralPurposeStorage, BlobStorage, PremiumFileShareStorage"
"Storage","Azure_Storage_AuthZ_Use_IP_ACL","Use IP-restrictions in SAS tokens to only permit access from intended IP addresses","Moderate","No","No","Using appropriate IP-based ACLs ensures that data in storage is protected and accessible only to entities from an expected set of endpoints.","Restrict storage SAS tokens to specific IP addresses/ranges where possible. Refer: https://docs.microsoft.com/en-us/azure/storage/storage-dotnet-shared-access-signature-part-1. Note: In case the IP range is indeterminate (for instance, if the client is a PaaS endpoint), you may need to attest this control.","No","No","SDL, TCP, Manual, AuthZ, StandardSku, PremiumSku, GeneralPurposeStorage, BlobStorage"
"Storage","Azure_Storage_AuthZ_Clients_Use_SAS","End user/client apps should access Storage Account through SAS token only (and not via Storage Account Key)","Important","No","No","A shared access signature (SAS) provides you with a way to grant limited access to objects in your Storage Account to other clients, without exposing your account key. This is in accordance with the principle of least privilege access.","Do not use Storage Account key directly in apps. Use a SAS token to limit the access based on scope, duration, IPs, etc. Refer: https://docs.microsoft.com/en-us/azure/storage/storage-dotnet-shared-access-signature-part-1.","No","No","SDL, Best Practice, Manual, AuthZ, StandardSku, PremiumSku, GeneralPurposeStorage, BlobStorage"
"Storage","Azure_Storage_DP_Rotate_Keys","Storage Account keys must be rotated periodically","Moderate","No","No","Periodic key/password rotation is a good security hygiene practice as, over time, it minimizes the likelihood of data loss/compromise which can arise from key theft/brute forcing/recovery attacks.","Rotate Storage Account keys on a periodic basis. To generated a new key, run command 'New-AzStorageAccountKey -KeyName '<key1/key2>' -Name '<StorageAccountName>' -ResourceGroupName '<RGName>'. Deploy the new key or derived SAS tokens to various clients as appropriate. Run 'Get-Help New-AzStorageAccountKey -full' for more help.","No","No","SDL, TCP, Manual, DP, StandardSku, PremiumSku, GeneralPurposeStorage, BlobStorage"
"Storage","Azure_Storage_AuthZ_Allow_Limited_Access_to_Services","Use Stored Access Policies with least privileges needed to access services in the Storage Account.","Important","No","No","Granting minimum access ensures that users are granted just enough permissions to perform their tasks. This minimizes operations that can be performed on the resource in case of access policy key compromise.","Create a SAS token with Stored Access Policy for service access using the minimal required privileges. Refer: https://docs.microsoft.com/en-us/azure/storage/storage-dotnet-shared-access-signature-part-1#controlling-a-sas-with-a-stored-access-policy.","No","No","SDL, TCP, Manual, AuthZ, StandardSku, PremiumSku, GeneralPurposeStorage, BlobStorage"
"Storage","Azure_Storage_DP_Restrict_CORS_Access","Ensure that CORS access is granted to a minimal set of trusted origins and only required verbs are supported.","Moderate","No","No","CORS enables applications running under one domain to access a resource under another domain. Using '*' (allow all) for CORS setting means that an application running under any domain can have access to your application's resources and data. Restricting allowed origins to the specific set that needs access aligns with the principle of least privilege.","Go to Azure Portal --> your Storage service --> Settings --> CORS --> for each of the Storage services  i.e. Blob/File/Table/Queue --> Add --> Provide the specific domain names and other CORS details that should be allowed to make cross-origin calls. Note: No action is needed if you are not using CORS for your service.","Yes","No","SDL, TCP, Automated, DP, StandardSku, GeneralPurposeStorage, BlobStorage, OwnerAccess, ResourceLocked"
"TrafficManager","Azure_TrafficManager_AuthZ_Grant_Min_RBAC_Access","All Users/Identities must be granted minimum required permissions using Role Based Access Control (RBAC)","Moderate","No","No","Granting minimum access by leveraging RBAC feature ensures that users are granted just enough permissions to perform their tasks. This minimizes exposure of the resources in case of user/service account compromise.","Clean up any unauthorized users on the Traffic Manager Profile. Run command Remove-AzRoleAssignment -SignInName '{signInName}' -Scope '{scope}}' -RoleDefinitionName {role definition name}'. Run 'Get-Help Remove-AzRoleAssignment -full' to get the complete details about this command.","Yes","No","SDL, TCP, Automated, AuthZ, RBAC, TrafficManager"
"TrafficManager","Azure_TrafficManager_DP_Enable_HTTPS","Traffic Manager profile should use HTTPS protocol for endpoint monitoring","Moderate","Yes","No","Use of HTTPS ensures server/service authentication and protects data in transit from network layer man-in-the-middle, eavesdropping, session-hijacking attacks.","To enable HTTPS protocol for endpoint monitoring, go to Azure Portal --> your Traffic Manager Profile --> Configuration -->  Select HTTPS --> Save.","Yes","No","SDL, Best Practice, Automated, DP, TrafficManager"
"Search","Azure_Search_AuthZ_Grant_Min_RBAC_Access","All users/identities must be granted minimum required permissions using Role Based Access Control (RBAC)","Moderate","No","No","Granting minimum access by leveraging RBAC feature ensures that users are granted just enough permissions to perform their tasks. This minimizes exposure of the resources in case of user/service account compromise.","Remove any excessive privileges granted on the Search service. Run command: Remove-AzRoleAssignment -SignInName '<SignInName>' -Scope '<Scope>' RoleDefinitionName '<RoleDefinitionName>'. Run 'Get-Help Remove-AzRoleAssignment -full' for more help.","Yes","No","SDL, TCP, Automated, AuthZ, RBAC, Search"
"Search","Azure_Search_AuthZ_Least_Privilege_For_Monitoring","Users monitoring/supporting the Search service should be provided with minimum required permissions","Moderate","No","No","Granting minimum access to monitoring and support team ensures that they are granted just enough permissions to perform their tasks. This minimizes exposure of the resources in case of data compromise.","Remove any excessive privileges granted on the Search service to monitoring/support teams. Run command: Remove-AzRoleAssignment -SignInName '<SignInName>' -Scope '<Scope>' RoleDefinitionName '<RoleDefinitionName>'. Run 'Get-Help Remove-AzRoleAssignment -full' for more help.","No","No","SDL, Best Practice, Manual, AuthZ, Search"
"Search","Azure_Search_DP_Encrypt_At_Rest","Sensitive data at data source must be encrypted at rest","Important","No","No","Using this feature ensures that sensitive data is stored encrypted at rest. This minimizes the risk of data loss from physical theft and also helps meet regulatory compliance requirements.","To enable encryption for a SQL DB, run command 'Set-AzSqlDatabaseTransparentDataEncryption -DatabaseName '<DBName>' -ResourceGroupName '<RGName>' -ServerName '<SQLServerName>' -State 'Enabled''. Run 'Get-Help Set-AzSqlDatabaseTransparentDataEncryption -full' for more help.","No","No","SDL, TCP, Manual, DP, Search"
"Search","Azure_Search_DP_Encrypt_In_Transit","Sensitive data must be encrypted in transit","Important","No","No","Use of HTTPS ensures server/service authentication and protects data in transit from network layer man-in-the-middle, eavesdropping, session-hijacking attacks.","For SQL DB, specify 'Encrypt=True, TrustServerCertificate=False' parameters in your application's connection string. For Azure Storage, use HTTPS protocol for data access.","No","No","SDL, TCP, Manual, DP, Search, Information"
"Search","Azure_Search_AuthZ_Grant_Admin_Keys_For_Manage_Access_Only","Admin keys must be furnished only for clients who need to manage the search catalog of Search service","Important","No","No","Granting Admin keys to clients means giving access to all operations, including the ability to manage the service, create and delete indexes, indexers, and data sources. So they should be maintained and owned only by the users administering the service.","Admin keys should be maintained and owned only by Search service administrators and must be rotated periodically as per the company standards. To get the Admin keys, go to Azure Portal --> your Search service --> Settings --> Keys.","No","No","SDL, TCP, Manual, AuthZ, Search"
"Search","Azure_Search_AuthZ_Grant_Only_QueryKey_Access_to_Readers","Consumers who require read access on Search service must only be granted 'query' keys","Important","No","No","Query keys grant read-only access to indexes and documents. So to avoid giving excessive permissions like creating and deleting indexes, only QueryKey access should be given to readers","Ensure that Search clients are granted access to 'query' keys only (and not 'admin' keys). To get 'query' keys, go to Azure Portal --> your Search service --> Settings --> Keys --> Manage query keys.","No","No","SDL, TCP, Manual, AuthZ, Search"
"Search","Azure_Search_Availability_Configure_Three_Replicas","Search service must have at least three replicas for high availability","Moderate","No","No","High availability can be achieved by adding replicas. Each replica has one copy of an index, so adding one more replica translates to one more index that can be used to service query requests. Minimum of three replicas are required since the azure team has specified three to be the borderline value for the same","Go to Azure Portal --> your Search service --> Settings --> Scale --> Replicas. Ensure that at least 3 replicas are setup.","Yes","No","SDL, TCP, Automated, Availability, Search"
"Search","Azure_Search_Audit_Enable_Diagnostics_Log","Diagnostics logs must be enabled with a retention period of at least 365 days","Moderate","No","No","Logs should be retained for a long enough period so that activity trail can be recreated when investigations are required in the event of an incident or a compromise. A period of 1 year is typical for several compliance requirements as well.","You can change the diagnostic settings from the Azure Portal by following the steps given here: https://docs.microsoft.com/en-us/azure/monitoring-and-diagnostics/monitoring-archive-diagnostic-logs#archive-diagnostic-logs-using-the-portal","Yes","No","SDL, TCP, Automated, Audit, Diagnostics, Search"
"ContainerRegistry","Azure_ContainerRegistry_AuthZ_Disable_Admin_Account","The Admin account in Container Registry should be disabled","Important","No","Yes","The Admin user account is designed for a single user to access the registry. Multiple users authenticating with the admin account appear as just one user to the registry. This leads to loss of auditability. Using AAD-based identity ensures that there is a built-in high level of assurance in the user identity established for subsequent access control.","Run command 'Update-AzContainerRegistry -DisableAdminUser -Name '<ContainerRegistryName>' -ResourceGroupName '<RGName>'. Run 'Get-Help Update-AzContainerRegistry -full' for more help. You can add AAD-based SPNs or user accounts to the appropriate RBAC role instead.","Yes","Yes","SDL, TCP, Automated, AuthZ, ContainerRegistry"
"ContainerRegistry","Azure_ContainerRegistry_AuthZ_Use_SPN_For_Registry_Access","A service principal should be used to access container images in Container Registry","Moderate","No","No","Using a 'user' account should be avoided because, in general, a user account will likely have broader set of privileges to enterprise assets. Using a dedicated SPN ensures that the SPN does not have permissions beyond the ones specifically granted for the given scenario.","Grant access to an SPN using the guidance here: https://docs.microsoft.com/en-us/azure/container-registry/container-registry-auth-service-principal","Yes","No","SDL, TCP, Automated, AuthZ, OwnerAccess, GraphRead, ContainerRegistry"
"ContainerRegistry","Azure_ContainerRegistry_DP_Store_SPN_Cred_In_KeyVault","Credentials of service principal used for Container Registry must be stored in Key Vault","Important","No","No","Keeping/sharing password in clear text can lead to easy compromise at various avenues during an application's life cycle. Storing them in a key vault ensures that they are protected at rest.","To create an SPN and add the credential to a key vault refer: https://docs.microsoft.com/en-us/azure/container-registry/container-registry-tutorial-quick-build#create-service-principal-and-store-credentials.","No","No","SDL, TCP, Manual, SI, ContainerRegistry"
"ContainerRegistry","Azure_ContainerRegistry_AuthZ_Grant_Min_RBAC_Access","All users/identities must be granted minimum required permissions using Role Based Access Control (RBAC)","Moderate","No","No","Granting minimum access by leveraging RBAC feature ensures that users are granted just enough permissions to perform their tasks. This minimizes exposure of the resources in case of user/service account compromise.","Remove any excessive privileges granted on the Container Registry. Run command Remove-AzRoleAssignment -SignInName '{signInName}' -Scope '{scope}' -RoleDefinitionName '{role definition name}'. Run 'Get-Help Remove-AzRoleAssignment -full' for more help. Assign 'Reader' RBAC role to the members/SPs who only required to pull images from the Registry. Refer: https://docs.microsoft.com/en-us/azure/container-registry/container-registry-authentication#service-principal, https://docs.microsoft.com/en-us/azure/active-directory/role-based-access-control-manage-access-powershell","Yes","No","SDL, TCP, Automated, AuthZ, RBAC, ContainerRegistry"
"ContainerRegistry","Azure_ContainerRegistry_Configure_Latest_Images","Container Registry must have latest/patched image(s) all the time","Moderate","No","No","Unpatched images are easy targets for compromise from various malware/trojan attacks that exploit known vulnerabilities in operating systems and related software. Automated-patching ensures that the window for attacks on container images in minimized.","Setup automate build using the guidance here: https://docs.microsoft.com/en-us/azure/container-registry/container-registry-tutorial-base-image-update","No","No","SDL, Best Practice, Manual, Config, ContainerRegistry"
"ContainerRegistry","Azure_ContainerRegistry_DP_Enable_Content_Trust","Content trust must be enabled for the Container Registry","Moderate","No","No","Content trust gives the ability to verify both the integrity and the publisher of all the image content received from a registry over any channel. If a container image is served from an untrusted registry, the image itself may not be trustworthy/stable. Running such a compromised image can lead to loss of sensitive enterprise data.","Go to Azure Portal --> your Container Registry --> Content Trust --> Enabled. This feature is currently available only in Premium SKU. After enabling Content Trust, push only trusted images in the repositories. Refer: https://aka.ms/acr/content-trust.","Yes","No","SDL, Best Practice, Automated, DP, ContainerRegistry"
"ContainerRegistry","Azure_ContainerRegistry_Audit_Review_Logs","Activity logs for Data Container Registry should be reviewed periodically","Moderate","No","No","Periodic reviews of activity and audit logs ensures that anomalous activity can be identified early enough instead of after a major compromise.","Review activity logs to check critical activities (e.g. List Container Registry Login Credentials) on the resource. Refer: https://docs.microsoft.com/en-us/azure/monitoring-and-diagnostics/monitoring-overview-activity-logs","No","No","SDL, Best Practice, Manual, Audit, ContainerRegistry"
"ContainerRegistry","Azure_ContainerRegistry_DP_Push_Only_Signed_Images","Only signed images must be pushed to Container Registry","Moderate","No","No","A container image that is not signed can be exposed malicious changes. Signing and signature verification ensures that only trusted images are able to run.","Run command 'az acr repository show -n <RegistryName> --image <IamgeName>:<Tag>' from Azure cli to get signature details of the images. Refer: https://docs.docker.com/engine/security/trust/content_trust/#push-trusted-content","No","No","SDL, Best Practice, Manual, DP"
"VirtualNetwork","Azure_VNet_NetSec_Justify_PublicIPs","Minimize the number of Public IPs (i.e. NICs with PublicIP) on a virtual network","Important","No","No","Public IPs provide direct access over the internet exposing the resource(s) to all type of attacks over the public network.","Unutilized Public IP address must be removed from virtual network. For more information visit: https://docs.microsoft.com/en-us/powershell/module/az.network/remove-azpublicipaddress","Yes","No","SDL, TCP, Automated, NetSec"
"VirtualNetwork","Azure_VNet_NetSec_Justify_IPForwarding_for_NICs","Use of IP Forwarding on any NIC in a virtual network should be scrutinized","Important","No","No","Enabling IP Forwarding on a VM NIC allows the VM to receive traffic addressed to other destinations. IP forwarding is required only in rare scenarios (e.g., using the VM as a network virtual appliance) and those should be reviewed with the network security team.","Disable IP Forwarding unless it has been reviewed and approved by network security team. Go to Azure Portal --> Navigate to VM NIC (where IP Forwarding is enabled) --> IP Configurations --> IP Forwarding settings --> Click on 'Disabled'.","Yes","No","SDL, Best Practice, Automated, NetSec"
"VirtualNetwork","Azure_VNet_NetSec_Configure_NSG","NSG should be used for subnets in a virtual network to permit traffic only on required inbound/outbound ports. NSGs should not have a rule to allow any-to-any traffic","Moderate","No","No","Restricting inbound and outbound traffic via NSGs limits the network exposure of the subnets within a virtual network and limits the attack surface.","Configure NSG rules to be as restrictive as possible via: (a) Azure Portal -> Network security groups -> <Your NSG> -> Inbound security rules -> Edit 'Allow' action rules. (b) Azure Portal -> Network security groups. -> <Your NSG> -> Outbound security rules -> Edit 'Allow' action rules.","Yes","No","SDL, Best Practice, Automated, NetSec"
"VirtualNetwork","Azure_VNet_AuthZ_Grant_Min_RBAC_Access","All users/identities must be granted minimum required permissions using Role Based Access Control (RBAC)","Moderate","No","No","Granting minimum access by leveraging RBAC feature ensures that users are granted just enough permissions to perform their tasks. This minimizes exposure of the resources in case of user/service account compromise.","Remove any excessive privileges granted on the Virtual Network. Run command: Remove-AzRoleAssignment -SignInName '<SignInName>' -Scope '<Scope>' RoleDefinitionName '<RoleDefinitionName>'. Run 'Get-Help Remove-AzRoleAssignment -full' for more help.","Yes","No","SDL, TCP, Automated, AuthZ, RBAC"
"VirtualNetwork","Azure_VNet_NetSec_Justify_Gateways","Presence of any virtual network gateways (GatewayType = VPN/ExpressRoute) in the virtual network must be justified","Important","No","No","Virtual network gateways enable network traffic between a virtual network and other networks. All such connectivity must be carefully scrutinized to ensure that corporate data is not subject to exposure on untrusted networks.","You can remove virtual network gateways using the Remove-AzVirtualNetworkGateway command (unless their presence has been approved by network security team). Run 'Get-Help Remove-AzVirtualNetworkGateway -full' for more help.","Yes","No","SDL, Best Practice, Automated, NetSec"
"VirtualNetwork","Azure_VNet_NetSec_Justify_Peering","Use of any virtual network peerings should be justified","Important","No","No","Resources in the peered virtual networks can communicate with each other directly. If the two peered networks are on different sides of a security boundary (e.g., corpnet v. private vNet), this can lead to exposure of corporate data. Hence any VNet peerings should be closely scrutinized and approved by the network security team","You can remove any virtual network peerings using the Remove-AzVirtualNetworkPeering command (unless their presence has been approved by network security team). Run 'Get-Help Remove-AzVirtualNetworkPeering -full' for more help.","Yes","No","SDL, Best Practice, Automated, NetSec"
"CosmosDB","Azure_CosmosDB_AuthZ_Enable_Firewall","Cosmos DB firewall should be enabled","Important","No","No","Using the firewall feature ensures that access to the data or the service is restricted to a specific set/group of clients. While this may not be feasible in all scenarios, when it can be used, it provides an extra layer of access control protection for critical assets.","Azure Portal --> Resource --> Firewall. Turn 'ON' - 'Selected Networks' and provide required IP addresses and/or ranges in the IP tab and save. Note: In case the IP range is indeterminate (for instance, if the client is a PaaS endpoint), you may need to attest this control.","Yes","No","SDL, TCP, Automated, AuthZ, CosmosDB, Firewall"
"CosmosDB","Azure_CosmosDB_AuthZ_Verify_IP_Range","Configure only the required IP addresses on Cosmos DB firewall","Important","No","No","Using the firewall feature ensures that access to the data or the service is restricted to a specific set/group of clients. For effective usage, whitelist only the required IPs. Whitelisting larger ranges like 0.0.0.0/0, 0.0.0.0/1, 128.0.0.0/1, etc. will defeat the purpose.","Do not use high ranges like 0.0.0.0/0, 0.0.0.0/1, 128.0.0.0/1, etc. Maximum IPs in a range should be less that 256 and total IPs including all ranges should be less than 2048. To modify - Azure Portal --> Resource --> Firewall and Virtual networks. Turn 'ON' - 'Enable IP Access Control' and add/or remove IP addresses and/or ranges and save. Note: In case the IP range is indeterminate (for instance, if the client is a PaaS endpoint), you may need to attest this control.","Yes","No","SDL, Best Practice, Automated, StateManagement, AuthZ, CosmosDB, Firewall"
"CosmosDB","Azure_CosmosDB_Config_Default_Consistency","Do not use 'Eventual' consistency","Important","No","Yes","Using Eventual consistency might cause undesired effects due to its ordering guarantees. This consistency is the weakest of all and the values returned in reads are always not guaranteed to be latest write.","Using Eventual consistency might cause undesired effects due to its ordering guarantees. To modify - Azure Portal --> Resource --> Default consistency. Select 'Session' and save. Refer: https://docs.microsoft.com/en-in/azure/cosmos-db/consistency-levels","Yes","No","SDL, Best Practice, Automated, Config, CosmosDB"
"CosmosDB","Azure_CosmosDB_Deploy_Use_Replication","Use global replication","Moderate","No","No","Replication ensures continuity and rapid recovery during disasters.","Replication ensures the continuity and rapid recovery during disasters. To add - Azure Portal --> Resource -> Replicate data globally. Select a secondary read region and save. Refer: https://docs.microsoft.com/en-in/azure/cosmos-db/distribute-data-globally","Yes","No","SDL, Best Practice, Automated, Deploy, CosmosDB"
"CosmosDB","Azure_CosmosDB_Deploy_Use_Automatic_Failover","Use automatic failover","Moderate","No","No","Automatic failover ensures continuity and auto recovery during disasters.","Automatic failover ensures the continuity and auto recovery during disasters. To configure, you must have at least 1 secondary replica enabled. To enabled replica - Azure Portal --> Resource -> Replicate data globally. Select a secondary read region and save. To set automatic failover - Azure Portal --> Resource -> Replicate data globally --> Automatic Failover. Turn 'ON' - 'Enable Automatic Failover', set the priorities and click 'OK'.","Yes","No","SDL, Best Practice, Automated, Deploy, CosmosDB"
"CosmosDB","Azure_CosmosDB_DP_Parameterized_Queries","Use parameterized SQL queries","Important","No","No","Parameterized SQL queries nullify the possibility of SQL injection by pre-compling the query. This will treat user input values purely as data.","Injection attacks are possible when using SQL queries. Use parameterized SQL queries to pass user inputs to the query. Refer: https://docs.microsoft.com/en-us/azure/cosmos-db/documentdb-sql-query#parameterized-sql-queries and https://docs.microsoft.com/en-us/azure/cosmos-db/documentdb-sql-query#a-iddotnetsdkac-net-sdk","No","No","SDL, Best Practice, Development, Manual, DP, CosmosDB"
"CosmosDB","Azure_CosmosDB_DP_Rotate_Keys","CosmosDb Account keys must be rotated periodically","Moderate","No","No","Periodic key/password rotation is a good security hygiene practice as, over time, it minimizes the likelihood of data loss/compromise which can arise from key theft/brute forcing/recovery attacks.","Rotate Cosmos DB account keys on a periodic basis. Refer: https://docs.microsoft.com/en-us/azure/cosmos-db/manage-account#regenerate-access-keys","No","No","SDL, Best Practice, StateManagement, DP, Manual, CosmosDB"
"CosmosDB","Azure_CosmosDB_AuthZ_Allow_Limited_Access_Resource_Token","Generate resource tokens with just enough privileges and expiry needed by clients","Important","No","No","Using appropriate ACLs ensures that data is protected and accessible only to the entities with the appropriate level of access.","Refer: https://docs.microsoft.com/en-us/azure/cosmos-db/secure-access-to-data#resource-tokens","No","No","SDL, Best Practice, Development, AuthZ, Manual, CosmosDB"
"CosmosDB","Azure_CosmosDB_DP_TTL_Dont_Send_RW_Resource_Tokens","Do not send resource token with read write (RW) permission to untrusted clients","Important","No","No","An untrusted client might use the read-write resource tokens that it received to make undesirable updates to the resource.","Manage all writes to Cosmos DB for untrusted clients from the middle tier (server side).","No","No","SDL, Best Practice, Development, DP, Manual, CosmosDB"
"VirtualMachine","Azure_VirtualMachine_Deploy_Latest_OS_Version","Virtual Machine should have latest OS version installed","Moderate","No","No","Being on the latest OS version significantly reduces risks from security design issues and security bugs that may be present in older versions.","Run command 'Update-AzVM -ResourceGroupName {resourceGroupName} -VM (Get-AzVM -ResourceGroupName {resourceGroupName} -Name {vmName})' . Run 'Get-Help Update-AzVM -full' for more help.","Yes","No","SDL, TCP, Automated, Deploy, Windows, Linux, ERvNet, VirtualMachine"
"VirtualMachine","Azure_VirtualMachine_SI_Enable_Antimalware","Antimalware must be enabled with real time protection on Windows Virtual Machine","Important","No","No","Enabling antimalware protection minimizes the risks from existing and new attacks from various types of malware. Microsoft Antimalware provide real-time protection, scheduled scanning, malware remediation, signature updates, engine updates, samples reporting, exclusion event collection etc.","To install antimalware, Go to Azure Portal --> VM Properties --> Extensions --> Add 'Microsoft Antimalware' --> Enable Real-Time Protection and Scheduled Scan --> Click Ok. If antimalware is already present on VM, validate and resolve endpoint protection recommendations in ASC. Refer: https://docs.microsoft.com/en-us/azure/security-center/security-center-install-endpoint-protection, https://docs.microsoft.com/en-us/azure/security/azure-security-antimalware","Yes","No","SDL, TCP, Automated, Config, Windows, SOX, SI, ERvNet, VirtualMachine"
"VirtualMachine","Azure_VirtualMachine_Config_Enable_NSG","NSG must be configured for Virtual Machine","Moderate","No","No","Restricting inbound and outbound traffic via NSGs limits the network exposure of a VM by reducing the attack surface.","Refer: https://docs.microsoft.com/en-us/azure/virtual-machines/windows/endpoints-in-resource-manager, https://docs.microsoft.com/en-us/azure/virtual-network/virtual-networks-create-nsg-arm-ps","Yes","No","SDL, TCP, Automated, Config, Windows, Linux, VirtualMachine"
"VirtualMachine","Azure_VirtualMachine_NetSec_Justify_PublicIPs","Public IPs on a Virtual Machine should be carefully reviewed","Important","No","Yes","Public IPs provide direct access over the internet exposing the VM to attacks over the public network. Hence each public IP on a VM must be reviewed carefully.","Go to Azure Portal --> VM Settings --> Networking --> Network Interfaces --> <Select NIC> --> IP Configurations --> <Select IP Configs with Public IP> --> Click 'Disabled' --> Save. Refer: https://docs.microsoft.com/en-us/azure/virtual-network/virtual-network-public-ip-address ","Yes","No","SDL, TCP, Automated, NetSec, Windows, Linux, ERvNet, VirtualMachine, FilterDatabricks"
"VirtualMachine","Azure_VirtualMachine_DP_Enable_Disk_Encryption","Disk encryption must be enabled on both OS and data disks for Windows Virtual Machine","Important","No","Yes","Using this feature ensures that sensitive data is stored encrypted at rest. This minimizes the risk of data loss from physical theft and also helps meet regulatory compliance requirements. In the case of VMs, both OS and data disks may contain sensitive information that needs to be protected at rest. Hence disk encryption must be enabled for both.","Refer: https://aka.ms/adewiki. Note: If enabling disk encryption through Azure Security Center (ASC), it will take some time for changes to reflect. If you scan immediately after enabling, the control may still fail even though the VM itself shows as encrypted. Please wait a few hours to validate the control state.","Yes","No","SDL, TCP, Automated, DP, Windows, ERvNet, VirtualMachine"
"VirtualMachine","Azure_VirtualMachine_SI_ASC_OS_Vulnerabilities","Virtual Machine must be in a healthy state in Azure Security Center","Important","No","No","Azure Security Center raises alerts (which are typically indicative of resources that are not compliant with some baseline security protection). It is important that these alerts/actions are resolved promptly in order to eliminate the exposure to attacks.","Refer: https://docs.microsoft.com/en-us/azure/security-center/security-center-remediate-os-vulnerabilities","Yes","No","SDL, TCP, Automated, Audit, Windows, Linux, VirtualMachine"
"VirtualMachine","Azure_VirtualMachine_SI_Missing_OS_Patches","Virtual Machine must have all the required OS patches installed.","Important","No","No","Un-patched VMs are easy targets for compromise from various malware/trojan attacks that exploit known vulnerabilities in operating systems and related software.","Refer: https://docs.microsoft.com/en-us/azure/security-center/security-center-apply-system-updates . It takes 24 hours to reflect the latest status at ASC.","Yes","No","SDL, TCP, Automated, Audit, Windows, SOX, SI, Linux, ERvNet, VirtualMachine"
"VirtualMachine","Azure_VirtualMachine_SI_ASC_Recommendations","Virtual Machine must implement all the flagged ASC recommendations.","Important","No","No","Azure Security Center provide various security recommendations for resources that are not compliant with some baseline security protection. It is important that these recommendations are resolved promptly in order to eliminate the exposure to attacks.","First, examine the detailed AzSK log file for this VM to find out the specific recommendations this control is currently failing for. Review the ASC documentation for those recommendations and implement the suggested fixes. (Note: Not all ASC recommendations are flagged by AzSK. So the first step is critical.). Refer: https://docs.microsoft.com/en-us/azure/security-center/security-center-virtual-machine-recommendations","Yes","No","SDL, TCP, Automated, Audit, Windows, Linux, ERvNet, VirtualMachine"
"VirtualMachine","Azure_VirtualMachine_Audit_Enable_Diagnostics","Diagnostics (IaaSDiagnostics extension on Windows; LinuxDiagnostic extension on Linux) must be enabled on Virtual Machine","Moderate","No","No","Diagnostics logs are needed for creating activity trail while investigating an incident or a compromise.","Go to Azure Portal --> VM Properties --> Diagnostics settings --> Enable guest-level-monitoring. Refer: https://docs.microsoft.com/en-us/azure/monitoring-and-diagnostics/azure-diagnostics","Yes","No","SDL, TCP, Automated, Audit, Windows, Linux, ERvNet, VirtualMachine"
"VirtualMachine","Azure_VirtualMachine_NetSec_Dont_Open_Management_Ports","Do not leave management ports open on Virtual Machines","Critical","No","No","Open remote management ports expose a VM/compute node to a high level of risk from internet-based attacks that attempt to brute force credentials to gain admin access to the machine.","Go to Azure Portal --> VM Settings --> Networking --> Inbound security rules --> Select security rule which allows management ports (e.g. RDP-3389, WINRM-5985, SSH-22) --> Click 'Deny' under Action --> Click Save.","Yes","No","SDL, TCP, Automated, NetSec, Windows, Linux, OwnerAccess, VirtualMachine"
"VirtualMachine","Azure_VirtualMachine_SI_Enable_Vuln_Solution","Vulnerability assessment solution should be installed on VM","Moderate","No","No","Known OS/framework vulnerabilities in a system can be easy targets for attackers. An attacker can start by compromising a VM/container with such a vulnerability and can eventually compromise the security of the entire network. A vulnerability assessment solution can help to detect/warn about vulnerabilities in the system and facilitate addressing them in a timely manner.","To install vulnerability assessment solution Qualys, please refer: https://aka.ms/devopskit/QualysAgent","Yes","No","SDL, TCP, Automated, Config, Windows, Linux, SI, ERvNet, VirtualMachine"
"VirtualMachine","Azure_VirtualMachine_SI_Deploy_GuestConfig_Extension","Guest Configuration extension must be deployed to the VM using Azure Policy assignment","Moderate","No","No","Installing Guest configuration extension on VM allows you to run In-Guest Policy on the VM, making it possible to monitor system and security policies for compliance checks in the VM.","This control checks that the VM meets the following criteria: [a] Guest Configuration Extension is installed and provisioned successfully, [b] the guest config policy is assigned and [c] 'SystemAssigned' managed identity (MSI) is enabled for the VM. Both, the required Guest Configuration extension and a system-assigned MSI, will be automatically deployed and configured when the machine is in scope for an Azure Policy assignment that includes definitions in the Guest Configuration category. You may need to remediate existing VMs. For new VMs you can ensure that the required Azure Policy is assigned when deploying the VMs.For detailed steps, see docs at: https://aka.ms/inguest and the script at: https://microsoftit.visualstudio.com/OneITVSO/_git/SI-HDC-Manage-CloudMS?path=%2FGuestConfiguration&version=GBNoPAK","Yes","No","SDL, TCP, Automated, Config, Windows, Linux, SI, ERvNet, VirtualMachine"
"VirtualMachine","Azure_VirtualMachine_SI_GuestConfig_Policy_Health","Guest config extension should report compliant status for all in-guest policies.","Moderate","No","No","In-guest policies cover various native (data-plane)  security requirements for a VM.  A VM that is compliant to these requirements has a lower overall exposure to getting compromised.","Run Get-AzVMGuestPolicyStatus -ResourceGroupName <VM Resource group name> -VMName <VM Name> to get further details like Compliance reason, last check time etc. and ensure that the issues are resolved.","Yes","No","SDL, TCP, Automated, Config, Windows, Linux, SI, ERvNet, VirtualMachine"
"DataLakeStore","Azure_DataLakeStore_AuthN_AAD_For_Client_AuthN","All users/applications are authenticated using Azure Active Directory (AAD) based credentials","Important","No","No","Using the native enterprise directory for authentication ensures that there is a built-in high level of assurance in the user identity established for subsequent access control. All Enterprise subscriptions are automatically associated with their enterprise directory (xxx.onmicrosoft.com) and users in the native directory are trusted for authentication to enterprise subscriptions.","No action required. ADLS supports only AAD authentication.","No","No","SDL, Information, Manual, AuthN, DataLakeStore"
"DataLakeStore","Azure_DataLakeStore_AuthZ_Grant_Min_RBAC_Access","All users/identities must be granted minimum required permissions using Role Based Access Control (RBAC)","Moderate","No","No","Granting minimum access by leveraging RBAC feature ensures that users are granted just enough permissions to perform their tasks. This minimizes exposure of the resources in case of user/service account compromise.","Assign 'Owner' role to Data Lake Store creator at resource group scope. Refer:  https://docs.microsoft.com/en-us/azure/active-directory/role-based-access-control-configure","Yes","No","SDL, TCP, Automated, AuthZ, RBAC, DataLakeStore"
"DataLakeStore","Azure_DataLakeStore_AuthZ_Assign_ACLs_On_FileSystem","Access to Data Lake Store file system must be limited by using appropriate Access Control List (ACL). The 'Other' group must not have any access","Important","No","No","Using appropriate ACLs ensures that data in ADLS is protected and accessible only to the entities with a legitimate need to access it.","Use PS command 'Set-AzDataLakeStoreItemAcl [-Account] <String> [-Path] <DataLakeStorePathInstance> [-Acl] <DataLakeStoreItemAcl>'. Refer: https://docs.microsoft.com/en-us/azure/data-lake-store/data-lake-store-secure-data#a-namefilepermissionsaassign-users-or-security-group-as-acls-to-the-azure-data-lake-store-file-system. To remove any user or group from ACLs refer: https://docs.microsoft.com/en-us/azure/data-lake-store/data-lake-store-secure-data#remove-security-group-acls-from-a-data-lake-storage-gen1-file-system","Yes","No","SDL, TCP, Automated, AuthZ, DataLakeStore"
"DataLakeStore","Azure_DataLakeStore_AuthZ_Enable_Firewall","Firewall should be enabled on Data Lake Store","Moderate","No","No","Using the firewall feature ensures that access to the data or the service is restricted to a specific set/group of clients. While this may not be feasible in all scenarios, when it can be used, it provides an extra layer of access control protection for critical assets.","Enable firewall and add rules for specific IP/IP ranges. Do not add the IP range 0.0.0.0-255.255.255.255 as it means open access for all IPs. Refer: https://docs.microsoft.com/en-us/powershell/module/az.datalakestore/add-azdatalakestorefirewallrule. Note: In case the IP range is indeterminate (for instance, if the client is a PaaS endpoint), you may need to attest this control.","Yes","No","SDL, TCP, Automated, AuthZ, DataLakeStore"
"DataLakeStore","Azure_DataLakeStore_DP_Use_AdlCopy_Securely","AdlCopy tool must be used securly while copying data from storage blobs to Data Lake Store","Important","No","No","Use of HTTPS ensures server/service authentication and protects data in transit from network layer man-in-the-middle, eavesdropping, session-hijacking attacks.???Incautious use of storage key in???AdlCopy command may result into exposure of the key to unauthorized users.","Use HTTPS URL for blob storage endpoint.","No","No","SDL, TCP, Manual, DP, DataLakeStore"
"DataLakeStore","Azure_DataLakeStore_AuthZ_Use_SP_For_ADLS_Access","Clients such as web jobs, standalone apps should use a service principal identity to access Data Lake Store","Important","No","No","Using a 'user' account should be avoided because, in general, a user account will likely have broader set of privileges to enterprise assets. Using a dedicated SPN ensures that the SPN does not have permissions beyond the ones specifically granted for the given scenario.","Create a service principal and use ACLs on ADLS to grant it the least required access. Refer: https://docs.microsoft.com/en-us/azure/data-lake-store/data-lake-store-secure-data#a-namefilepermissionsaassign-users-or-security-group-as-acls-to-the-azure-data-lake-store-file-system","No","No","SDL, Best Practice, Manual, AuthZ, DataLakeStore"
"DataLakeStore","Azure_DataLakeStore_DP_Encrypt_At_Rest","Sensitive data must be encrypted at rest","Important","Yes","No","Using this feature ensures that sensitive data is stored encrypted at rest. This minimizes the risk of data loss from physical theft and also helps meet regulatory compliance requirements.","Ensure that encryption is not disabled when creating a new Data Lake Store. Refer: https://docs.microsoft.com/en-us/azure/data-lake-store/data-lake-store-security-overview#data-protection. Encryption cannot be enabled after the fact for Data Lake Store.","Yes","No","SDL, TCP, Automated, DP, DataLakeStore"
"DataLakeStore","Azure_DataLakeStore_DP_Encrypt_In_Transit","Sensitive data must be encrypted in transit","Important","No","No","Use of HTTPS ensures server/service authentication and protects data in transit from network layer man-in-the-middle, eavesdropping, session-hijacking attacks.","No action required. ADLS provides encryption in transit using HTTPS transport layer security. Reference: https://docs.microsoft.com/en-us/azure/data-lake-store/data-lake-store-encryption","No","No","SDL, Information, Manual, DP, DataLakeStore"
"DataLakeStore","Azure_DataLakeStore_Audit_Enable_Diagnostics_Log","Diagnostics logs must be enabled with a retention period of at least 365 days.","Moderate","No","No","Logs should be retained for a long enough period so that activity trail can be recreated when investigations are required in the event of an incident or a compromise. A period of 1 year is typical for several compliance requirements as well.","You can change the diagnostic settings from the Azure Portal by following the steps given here: https://docs.microsoft.com/en-us/azure/monitoring-and-diagnostics/monitoring-archive-diagnostic-logs#archive-diagnostic-logs-using-the-portal","Yes","No","SDL, TCP, Automated, Audit, Diagnostics, DataLakeStore"
"DataLakeStore","Azure_DataLakeStore_Audit_Review_Logs","Diagnostic logs for Data Lake Store should be reviewed periodically","Moderate","No","No","Periodic reviews of diagnostics, activity and audit logs ensures that anomalous activity can be identified early enough instead of after a major compromise.","Review diagnostic/activity logs to check activities on the resource. Refer: https://docs.microsoft.com/en-us/azure/data-lake-store/data-lake-store-diagnostic-logs and https://docs.microsoft.com/en-us/azure/monitoring-and-diagnostics/monitoring-overview-activity-logs","No","No","SDL, Best Practice, Manual, Audit, DataLakeStore"
"DataLakeStore","Azure_DataLakeStore_BCDR_Plan","Backup and Disaster Recovery must be planned for Data Lake Store","Moderate","No","No","Data Lake Analytics does not offer features to cover backup/disaster recovery out-of-the-box. As a result, when processing critical workloads, a team must have adequate backups of the data.","Ensure the critical business data in the Data Lake Store has been backed up from a BC-DR standpoint.","No","No","SDL, TCP, Manual, BCDR, DataLakeStore"
"DataLakeStore","Azure_DataLakeStore_Config_Cleanup_Data","Data in Data Lake Store should be cleaned up using file retention","Moderate","No","No","Data should not be retained for periods longer than required for business use case scenarios. Purging/cleaning up data periodically minimizes risk from compromise while also helping limit the costs of maintaining it.","Set expiry date by navigating to file in ADLS data explorer and the 'Set Expiry' property or use PS Command 'Set-AzDataLakeStoreItemExpiry [-Account] <String> [-Path] <DataLakeStorePathInstance> [[-Expiration] <DateTimeOffset>]'","No","No","SDL, Best Practice, Manual, Config, DataLakeStore"
"SubscriptionCore","Azure_Subscription_AuthZ_Limit_Admin_Owner_Count","Minimize the number of admins/owners","Moderate","No","No","Each additional person in the Owner/Contributor role increases the attack surface for the entire subscription. The number of members in these roles should be kept to as low as possible.","There are 2 steps involved. (1) You need to remove any 'Classic Administrators/Co-Administrators' who should not be in the role. Please follow these steps: (a) Logon to https://portal.azure.com/ (b) Navigate to Subscriptions (c) Select the subscription (d) Go to 'Access Control (IAM)' (e) Select the co-administrator account that has to be removed and click on the 'Remove' button. (f) Perform this operation for all the co-administrators that need to be removed from the subscription. (2) You need to remove any unwanted members from the Owners group. To do this simply run the command 'Remove-AzRoleAssignment -SignInName '{signInName}' -Scope '/subscriptions/{subscriptionid}' -RoleDefinitionName Owner'.","Yes","No","SDL, Best Practice, Automated, AuthZ, SubscriptionCore"
"SubscriptionCore","Azure_Subscription_AuthZ_Justify_Admins_Owners","Justify all identities that are granted with admin/owner access on your subscription.","Moderate","No","No","Accounts that are a member of these groups without a legitimate business reason increase the risk for your subscription. By carefully reviewing and removing accounts that shouldn't be there in the first place, you can avoid attacks if those accounts are compromised.","There are 2 steps involved. (1) You need to remove any 'Classic Administrators/Co-Administrators/Owners' who should not be in the role. Please follow these steps: (a) Logon to https://portal.azure.com/ (b) Navigate to Subscriptions (c) Select the subscription (d) Go to 'Access Control (IAM)' (e) Right click the co-administrator account that has to be removed and click on the 'Remove co-administrator'. (f) Perform this operation for all the co-administrators that need to be removed from the subscription. (2) You need to remove any unwanted members from the Owners group. To do this simply run the command 'Remove-AzRoleAssignment -SignInName '{signInName}' -Scope '/subscriptions/{subscriptionid}' -RoleDefinitionName Owner'.","Yes","No","SDL, Best Practice, Automated, AuthZ, SubscriptionCore"
"SubscriptionCore","Azure_Subscription_AuthZ_Add_Required_Central_Accounts","Mandatory central accounts must be present on the subscription","Important","Yes","No","Certain central accounts are expected to be present in all subscriptions to support enterprise wide functions (e.g., security scanning, cost optimization, etc.). Certain other accounts may also be required depending on special functionality enabled in a subscription (e.g., Express Route network management). The script checks for presence of such 'mandatory' and 'scenario-specific' accounts. If these are not present per the current baseline, there may be security/functionality impact for your subscription.","Run command 'Set-AzSKSubscriptionRBAC'. This command sets up all mandatory accounts on the target subscription. Run 'Get-Help Set-AzSKSubscriptionRBAC -full' for more help. ","Yes","Yes","SDL, TCP, Automated, AuthZ, SubscriptionCore"
"SubscriptionCore","Azure_Subscription_AuthZ_Remove_Deprecated_Accounts","Deprecated/stale accounts must not be present on the subscription","Critical","Yes","No","Deprecated accounts are ones that were once deployed to your subscription for some trial/pilot initiative (or some other purpose). These are not required any more and are a standing risk if present in any role on the subscription.","Run command 'Remove-AzSKSubscriptionRBAC'. You can remove all the deprecated accounts using this command. Run 'Get-Help Remove-AzSKSubscriptionRBAC -full' for more help.","Yes","Yes","SDL, TCP, Automated, AuthZ, SubscriptionCore"
"SubscriptionCore","Azure_Subscription_AuthZ_Dont_Use_NonAD_Identities","Do not grant permissions to external accounts (i.e., accounts outside the native directory for the subscription)","Important","Yes","No","Non-AD accounts (such as xyz@hotmail.com, pqr@outlook.com, etc.) present at any scope within a subscription subject your cloud assets to undue risk. These accounts are not managed to the same standards as enterprise tenant identities. They don't have multi-factor authentication enabled. Etc.","Run command Remove-AzRoleAssignment -SignInName '{signInName}' -Scope '{scope}' -RoleDefinitionName '{role definition name}'. Run 'Get-Help Remove-AzRoleAssignment -full' for more help.","Yes","No","SDL, TCP, Automated, AuthZ, OwnerAccess, GraphRead, SubscriptionCore"
"SubscriptionCore","Azure_Subscription_AuthZ_Dont_Use_SVC_Accounts_No_MFA","Service accounts cannot support MFA and should not be used for subscription activity","Important","No","No","Service accounts are typically not multi-factor authentication capable. Quite often, teams who own these accounts don't exercise due care (e.g., someone may login interactively on servers using a service account exposing their credentials to attacks such as pass-the-hash, phishing, etc.) As a result, using service accounts in any privileged role in a subscription exposes the subscription to 'credential theft'-related attack vectors. (In effect, the subscription becomes accessible after just one factor (password) is compromised...this defeats the whole purpose of imposing the MFA requirement for cloud subscriptions.)","Run command Remove-AzRoleAssignment -SignInName '{signInName}' -Scope '{scope}' -RoleDefinitionName '{role definition name}'. Run 'Get-Help Remove-AzRoleAssignment -full' for more help.","Yes","No","SDL, TCP, Manual, AuthZ, OwnerAccess, GraphRead, SubscriptionCore"
"SubscriptionCore","Azure_Subscription_AuthZ_Limit_ClassicAdmin_Count","There should not be more than 2 classic administrators","Important","No","Yes","The v1 (ASM-based) version of Azure resource access model did not have much in terms of RBAC granularity. As a result, everyone who needed any access on a subscription or its resources had to be added to the Co-administrator role. These individuals are referred to as 'classic' administrators. In the v2 (ARM-based) model, this is not required at all and even the count of 2 classic admins currently permitted is for backward compatibility. (Some Azure services are still migrating onto the ARM-based model so creating/operating on them needs 'classic' admin privilege.)","You need to remove any 'Classic Administrators/Co-Administrators' who should not be in the role. Please follow these steps: (a) Logon to https://portal.azure.com/ (b) Navigate to Subscriptions (c) Select the subscription (d) Go to 'Access Control (IAM)' (e) Select the co-administrator account that has to be removed and click on the 'Remove' button. (f) Perform this operation for all the co-administrators that need to be removed from the subscription.","Yes","No","SDL, TCP, Automated, AuthZ, SubscriptionCore"
"SubscriptionCore","Azure_Subscription_AuthZ_Remove_Management_Certs","Use of management certificates is not permitted.","Important","Yes","No","Just like classic admins, management certificates were used in the v1 model for script/tool based automation on Azure subscriptions. These management certificates are risky because the (private) key management hygiene tends to be lax. These certificates have no role to play in the current ARM-based model and should be immediately cleaned up if found on a subscription. (VS-deployment certificates from v1 timeframe are a good example of these.)","You need to remove any management certificates that are not required. Please follow these steps: (a) Logon to https://portal.azure.com/ (b) Navigate to Subscriptions (c) Select the subscription (d) Go to Settings tab  --> Management Certificates tab --> Delete unwanted management certificates.","Yes","No","SDL, TCP, Automated, AuthZ, OwnerAccess, GraphRead, SubscriptionCore"
"SubscriptionCore","Azure_Subscription_Config_Azure_Security_Center","Azure Security Center (ASC) must be correctly configured on the subscription","Important","Yes","No","The Security Center feature in Azure helps with important central settings for the subscription such as configuring a security point of contact. It also supports key policy settings (e.g., is patching configured for VMs?, is threat detection enabled for SQL?, etc.) and alerts about resources which are not compliant to those policy settings. Correctly configuring ASC is critical as it gives a baseline layer of protection for the subscription and commonly used resource types.","Run command 'Set-AzSKAzureSecurityCenterPolicies -SubscriptionId '<SubscriptionId>' -SecurityContactEmails '<comma separated emails ids>' -SecurityPhoneNumber '<contact number>'. Run 'Get-Help Set-AzSKAzureSecurityCenterPolicies -full' for more help.","Yes","Yes","SDL, TCP, Automated, Config, SOX, SubscriptionCore"
"SubscriptionCore","Azure_Subscription_Audit_Resolve_Azure_Security_Center_Alerts","Pending Azure Security Center (ASC) alerts must be resolved","Important","No","Yes","Based on the policies that are enabled in the subscription, Azure Security Center raises alerts (which are typically indicative of resources that ASC suspects might be under attack or needing immediate attention). It is important that these alerts/actions are resolved promptly in order to eliminate the exposure to attacks.","You need to address all active alerts on Azure Security Center. Please follow these steps: (a) Logon to https://portal.azure.com/ (b) Navigate to Security Center. (c) Click on Security Alerts under 'Threat Protection' category. (d) Take appropriate actions on all active alerts. Note: If your subscription persistently fails the control to resolve ASC alerts after dismissing all security alerts in the portal, you may need to adjust the date filter to see all alerts. The filter is found in the top left corner of the 'Security alerts' view","Yes","No","SDL, TCP, Automated, Audit, SubscriptionCore"
"SubscriptionCore","Azure_Subscription_AuthZ_Dont_Add_SPNs_as_Owner","Service Principal Names (SPNs) should not be Owners or Contributors on the subscription","Moderate","No","No","Just like AD-based service accounts, SPNs have a single credential and most scenarios that use them cannot support multi-factor authentication. As a result, adding SPNs to a subscription in 'Owners' or 'Contributors' roles is risky.","If this SPN needs access to your subscription, make sure you add it at the specific permission scope and role required for your scenario. For example, sometimes 'Contributor' access at 'Resource Group' scope might work. In other scenarios you may need 'Reader' access at 'Subscription' scope. Exact permission will vary based on your use case. If you want to remove the SPN, run command Remove-AzRoleAssignment -ObjectId '{objectId}' -Scope '{scope}' -RoleDefinitionName '{role definition name}'. Run 'Get-Help Remove-AzRoleAssignment -full' for more help.","Yes","No","SDL, Best Practice, Automated, AuthZ, OwnerAccess, GraphRead, SubscriptionCore"
"SubscriptionCore","Azure_Subscription_SI_Lock_Critical_Resources","Critical application resources should be protected using a resource lock","Moderate","No","No","A resource lock protects a resource from getting accidentally deleted. With proper RBAC configuration, it is possible to setup critical resources in a subscription in such a way that people can perform most operations on them but cannot delete them. resource locks can help ensure that important data is not lost by accidental/malicious deletion of such resources (thus ensuring that availability is not impacted).","Consider using Azure resource locks to protect those resources in the subscription that you absolutely cannot afford to be deleted (by accident). You have to identify such resources and apply locks to them. Run command 'New-AzResourceLock'. Run 'Get-Help New-AzResourceLock -full' for more help.","Yes","No","SDL, Best Practice, Automated, SI, SubscriptionCore"
"SubscriptionCore","Azure_Subscription_Config_ARM_Policy","ARM policies should be used to audit or deny certain activities in the subscription that can impact security","Moderate","Yes","No","The AzSK subscription security setup configures a set of ARM policies which result in audit log entries upon actions that violate the policies. (For instance, an audit event is generated if someone creates a v1 resource in a subscription.) These policies help by raising visibility to potentially insecure actions. ","Run command 'Set-AzSKARMPolicies'. Run 'Get-Help Set-AzSKARMPolicies -full' for more help.","Yes","Yes","SDL, Best Practice, Automated, Config, SubscriptionCore"
"SubscriptionCore","Azure_Subscription_Audit_Configure_Critical_Alerts","Alerts must be configured for critical actions on subscription and resources","Important","Yes","No","The AzSK subscription security setup configures Insights-based alerts for sensitive operations in the subscription. These alerts notify the configured security point of contact about various sensitive activities on the subscription and its resources (for instance, adding a new member to subscription 'Owners' group or deleting a firewall setting or creating a new web app deployment, etc.)","Run command 'Set-AzSKAlerts'. Run 'Get-Help Set-AzSKAlerts -full' for more help.","Yes","Yes","SDL, Best Practice, Automated, Audit, SubscriptionCore"
"SubscriptionCore","Azure_Subscription_AuthZ_Custom_RBAC_Roles","Do not use custom-defined RBAC roles","Moderate","No","No","Custom RBAC role definitions are usually tricky to get right. A lot of threat modeling goes in when the product team works on and defines the various 'out-of-box' roles ('Owners', 'Contributors', etc.). As much as possible, teams should use these roles for their RBAC needs. Using custom roles is treated as an exception and requires a rigorous review.","Run command 'Remove-AzRoleDefinition -Id {id}'. Run 'Get-Help Remove-AzRoleDefinition -full' for more help.","Yes","No","SDL, Best Practice, Automated, AuthZ, SubscriptionCore"
"SubscriptionCore","Azure_Subscription_SI_Classic_Resources","Do not use any classic resources on a subscription","Important","No","Yes","You should use new ARM/v2 resources as the ARM model provides several security enhancements such as: stronger access control (RBAC), better auditing, ARM-based deployment/governance, access to managed identities, access to key vault for secrets, AAD-based authentication, support for tags and resource groups for easier security management, etc.","Migrate each v1/ASM-based resource in your app to a corresponding v2/ARM-based resource. Refer: https://docs.microsoft.com/en-us/azure/virtual-machines/windows/migration-classic-resource-manager-overview","Yes","No","SDL, Best Practice, Automated, AuthZ, SubscriptionCore"
"SubscriptionCore","Azure_Subscription_SI_Dont_Use_Classic_VMs","Do not use any classic virtual machines on your subscription.","Important","No","No","You should use new Azure (v2) resources as the ARM model provides several security enhancements such as: stronger access control (RBAC), better auditing, ARM-based deployment/governance, access to managed identities, access to key vault for secrets, AAD-based authentication, support for tags and resource groups for easier security management, etc.","Migrate each v1/ASM Virtual Machine in your subscription to a v2/ARM-based VM. Refer link https://docs.microsoft.com/en-us/azure/virtual-machines/windows/migration-classic-resource-manager-overview for resource migration.","Yes","No","SDL, Best Practice, Automated, AuthZ, SI, SubscriptionCore"
"SubscriptionCore","Azure_Subscription_NetSec_Justify_PublicIPs","Verify the list of public IP addresses on your subscription","Important","No","No","Public IPs provide direct access over the internet exposing a cloud resource to all type of attacks over the public network. Hence use of public IPs should be carefully scrutinized/reviewed.","Verify the list of public IP addresses used and delete the unwanted and unused ones immediately! To delete run 'Remove-AzPublicIpAddress -ResourceGroupName {ResourceGroupName} -Name {PublicIpAddressName}'. You might encounter an error if the public IP resource is associated with some other resource. Refer link: https://docs.microsoft.com/en-us/azure/virtual-network/virtual-network-public-ip-address#view-change-settings-for-or-delete-a-public-ip-address for more details.","Yes","No","SDL, Automated, Access, NetSec, SubscriptionCore"
"SubscriptionCore","Azure_Subscription_AuthZ_Dont_Grant_Persistent_Access","Permanent access should not be granted for privileged subscription level roles","Important","No","No","Permanent access increase the risk of a malicious user getting that access and inadvertently impacting a sensitive resource. To minimize this risk ensure that critical resources present in subscription are accessed only by the legitimate users when required. PIM facilitates this by limiting users to only assume higher privileges in a just in time (JIT) manner (or by assigning privileges for a shortened duration after which privileges are revoked automatically).","Use Privileged Identity Management (PIM) to grant access to privileged roles at subscription scope. To remove existing assignments run: 'Remove-AzRoleAssignment -SignInName '{signInName}' -Scope '/subscriptions/{subscriptionid}' -RoleDefinitionName {RoleDefinitionName}'. Refer https://docs.microsoft.com/en-us/azure/active-directory/privileged-identity-management/azure-pim-resource-rbac#assign-roles.","Yes","No","SDL, Automated, Access, AuthZ, SubscriptionCore"
"SubscriptionCore","Azure_Subscription_Config_Add_Required_Tags","Mandatory tags must be set per your organization policy","Important","No","Yes","Certain tags are expected to be present in all resources to support enterprise wide functions (e.g., security visibility based on environment, security scanning, cost optimization, etc.). The script checks for presence of such 'mandatory' and 'scenario-specific' tags. ","Refer: https://docs.microsoft.com/en-us/azure/azure-resource-manager/resource-group-using-tags#portal. You can learn more about Resource Group based tagging compliance here: https://aka.ms/rgtags.","Yes","No","SDL, TCP, Automated, AuthZ, SubscriptionCore"
"SubscriptionCore","Azure_Subscription_Config_ASC_Tier","Standard tier must be enabled for Azure Security Center","Important","No","No","ASC standard tier enables advanced threat detection capabilities, which uses built-in behavioral analytics and machine learning to identify attacks and zero-day exploits, access and application controls to reduce exposure to network attacks and malware, and more","Refer: https://docs.microsoft.com/en-us/azure/security-center/security-center-pricing","Yes","No","SDL, TCP, Automated, AuthZ, SubscriptionCore"
"DataLakeAnalytics","Azure_DataLakeAnalytics_AuthZ_Assign_Required_RBAC_To_Creator","Data Lake Analytics creator must be granted only required Role Based Access Control (RBAC) access on Subscription/Resource Group/Resource","Moderate","No","No","Granting minimum access by leveraging RBAC feature ensures that users are granted just enough permissions to perform their tasks. This minimizes exposure of the resources in case of user/service account compromise.","Assign 'Owner' privilege only at resource group and default data lake store account scope.","No","No","SDL, TCP, Manual, AuthZ, DataLakeAnalytics"
"DataLakeAnalytics","Azure_DataLakeAnalytics_AuthN_AAD_For_Client_AuthN","All Data Lake Analytics users/service principal must be authenticated using AAD backed credentials","Important","No","No","Using the native enterprise directory for authentication ensures that there is a built-in high level of assurance in the user identity established for subsequent access control. All Enterprise subscriptions are automatically associated with their enterprise directory (xxx.onmicrosoft.com) and users in the native directory are trusted for authentication to enterprise subscriptions.","No action required. ADLA supports only AAD authentication.","No","No","SDL, Information, Manual, AuthN, DataLakeAnalytics"
"DataLakeAnalytics","Azure_DataLakeAnalytics_AuthZ_Grant_Min_RBAC_Access","All users/identities must be granted minimum required permissions using Role Based Access Control (RBAC)","Moderate","No","No","Granting minimum access by leveraging RBAC feature ensures that users are granted just enough permissions to perform their tasks. This minimizes exposure of the resources in case of user/service account compromise.","Assign only the 'Data Lake Analytics Developer' RBAC role to developers who manage U-SQL jobs. Refer: https://docs.microsoft.com/en-us/azure/data-lake-analytics/data-lake-analytics-manage-use-portal#manage-users","Yes","No","SDL, TCP, Automated, AuthZ, RBAC, DataLakeAnalytics"
"DataLakeAnalytics","Azure_DataLakeAnalytics_AuthZ_Assign_Least_Privilege_ACL","Data Lake Analytics developer (user/service principal) must have least required ACLs on Catalog/Database and Data Lake Store file system","Moderate","No","No","Granting minimum permissions to users/security groups on data lake store file system by leveraging Access Control List (ACL) feature ensures that U-SQL jobs executed by users/security groups would perform only intended read/write operations. This minimizes exposure of the data in case of user credentials leak or faulty job programming.","Navigate to Azure Portal --> Data Lake Analytics Account --> Add User Wizard option to add users. Ensure least necessary privileges are granted.","No","No","SDL, TCP, Manual, AuthZ, DataLakeAnalytics"
"DataLakeAnalytics","Azure_DataLakeAnalytics_Config_Storage_Datasource_Securely","Storage account data source must be added securely","Moderate","No","No","Setting up storage data source using PowerShell command eliminates the risk of exposing storage account key (because the key itself is not displayed on the GUI at all).","Setup storage data source using PowerShell command 'Add-AzDataLakeAnalyticsDataSource -ResourceGroupName <ResourceGroup> -Account <ADLAAccount> -Blob <StorageAccount> -AccessKey ((Get-AzStorageAccountKey -ResourceGroupName <ResourceGroupOfStorageAccount> -Name <StorageAccountName>).Key1","No","No","SDL, Best Practice, Manual, Config, DataLakeAnalytics"
"DataLakeAnalytics","Azure_DataLakeAnalytics_DP_Encrypt_Connection_Strings","Secrets to access SQL Azure/SQL VM/SQL Data Warehouse must be securely stored under Catalog database credentials","Important","No","No","Credentials added in form of plain text in U-SQL job have higher chances of getting compromised. The job code is also likely check in into a code repository so the credential is visible to many parties.","Password of the account used to access SQL Azure must be created as a new catalog credential using the 'New-AzDataLakeAnalyticsCatalogCredential' PS command. Refer: https://docs.microsoft.com/en-us/powershell/module/az.datalakeanalytics/new-azdatalakeanalyticscatalogcredential, https://docs.microsoft.com/en-us/rest/api/datalakeanalytics/catalog/createcredential and https://docs.microsoft.com/en-us/azure/sql-data-warehouse/sql-data-warehouse-load-from-azure-data-lake-store#configure-the-data-source for details.","No","No","SDL, Best Practice, Manual, DP, DataLakeAnalytics"
"DataLakeAnalytics","Azure_DataLakeAnalytics_SI_USQL_Script_Integrity","U-SQL script file(s) must be uploaded from a secured/trusted location","Important","No","No","ADLA U-SQL File Import wizard does not impose any restrictions on file format nor does it scan uploaded files for security issues. If these files are at an insecure/untrustworthy location, they can be tampered/infested. This can lead to compromise of the ADLA jobs and data.","Make sure that the client machine used to upload scripts is secure (Antimalware, patching, etc.). Also, do not upload files that have originated from potentially untrusted sites.","No","No","SDL, TCP, Manual, SI, DataLakeAnalytics"
"DataLakeAnalytics","Azure_DataLakeAnalytics_Audit_Enable_Diagnostics_Log","Diagnostics logs must be enabled with a retention period of at least 365 days.","Moderate","No","No","Logs should be retained for a long enough period so that activity trail can be recreated when investigations are required in the event of an incident or a compromise. A period of 1 year is typical for several compliance requirements as well.","You can change the diagnostic settings from the Azure Portal by following the steps given here: https://docs.microsoft.com/en-us/azure/monitoring-and-diagnostics/monitoring-archive-diagnostic-logs#archive-diagnostic-logs-using-the-portal","Yes","No","SDL, TCP, Automated, Audit, Diagnostics, DataLakeAnalytics"
"DataLakeAnalytics","Azure_DataLakeAnalytics_DP_Encrypt_At_Rest","Sensitive data must be encrypted at rest","Important","No","Yes","Using this feature ensures that sensitive data is stored encrypted at rest. This minimizes the risk of data loss from physical theft and also helps meet regulatory compliance requirements.","Default Data Lake Store Account must have encryption enabled. Refer: https://docs.microsoft.com/en-us/azure/data-lake-store/data-lake-store-security-overview#data-protection","Yes","No","SDL, TCP, Automated, DP, DataLakeAnalytics"
"DataLakeAnalytics","Azure_DataLakeAnalytics_DP_Encrypt_In_Transit","Sensitive data must be encrypted in transit","Important","No","No","Use of HTTPS ensures server/service authentication and protects data in transit from network layer man-in-the-middle, eavesdropping, session-hijacking attacks.","No action required. ADLA provides encryption in transit using HTTPS transport layer security.","No","No","SDL, Information, Manual, DP, DataLakeAnalytics"
"DataLakeAnalytics","Azure_DataLakeAnalytics_BCDR_Plan_Default_Data_Lake_Store","Backup and Disaster Recovery must be planned for the default Data Lake Store account","Moderate","No","No","Data Lake Analytics does not offer features to cover backup/disaster recovery out-of-the-box. As a result, when processing critical workloads, a team must have adequate backups of the data and the jobs (catalog, code, etc.).","Ensure that any critical business/catalog data in the default Data Lake Store has been backed up from a BC-DR standpoint.","No","No","SDL, TCP, Manual, BCDR, DataLakeAnalytics"
"DataLakeAnalytics","Azure_DataLakeAnalytics_Audit_Review_Logs","Diagnostic and activity logs for Data Lake Analytics should be reviewed periodically","Moderate","No","No","Periodic reviews of diagnostics, activity and audit logs ensures that anomalous activity can be identified early enough instead of after a major compromise.","Review diagnostic/activity logs to check activities on the resource. Refer: https://docs.microsoft.com/en-us/azure/monitoring-and-diagnostics/monitoring-overview-of-diagnostic-logs and https://docs.microsoft.com/en-us/azure/monitoring-and-diagnostics/monitoring-overview-activity-logs","No","No","SDL, Best Practice, Manual, Audit, DataLakeAnalytics"
"ApplicationProxy","Azure_ApplicationProxy_Deploy_Only_Secure_Apps","Only security compliant apps should be onboarded to AAD App Proxy.","Important","No","No","AAD App proxy facilitates remote access to your on-prem apps. If these apps have not been designed and implemented securely, then security issues of your apps get exposed to the internet.","Ensure that apps you expose via App Proxy have been built using secure development standards/process such as SDL (Refer: https://www.microsoft.com/en-us/sdl)","No","No","SDL, TCP, Manual, Deploy, ApplicationProxy"
"ApplicationProxy","Azure_ApplicationProxy_AuthN_Use_AAD_PreAuth","AAD Authentication must be enabled as a pre-authentication method on your app.","Important","No","No","Pre-authentication by its very nature, blocks a significant number of anonymous attacks, because only authenticated identities can access the back-end application.","AAD Application Administrator (or higher privilege role) can check app pre-authentication configuration from portal or by running command 'Get-AzureADApplicationProxyApplication -ObjectId <AADAppID>'. To enable AAD Auth run command 'Set-AzureADApplicationProxyApplication -ObjectId <AppObjectID> -ExternalAuthenticationType AadPreAuthentication'. Refer: https://docs.microsoft.com/en-us/azure/active-directory/manage-apps/application-proxy-publish-azure-portal#publish-an-on-premises-app-for-remote-access.","No","No","SDL, TCP, Manual, AuthN, ApplicationProxy"
"ApplicationProxy","Azure_ApplicationProxy_DP_Remove_Connector_Machine_Logs","Delete personal data captured in logs on connector machine periodically or turn off connector machine logging if not required.","Important","No","No","Connector machine logs may contain personal data. This needs to be handled with care and purged when not needed in keeping with good privacy principles.","Turn off logging/delete personal data regularly on all connector machines. Refer: https://docs.microsoft.com/en-us/azure/active-directory/manage-apps/application-proxy-remove-personal-data","No","No","SDL, TCP, Manual, DP, ApplicationProxy"
"ApplicationProxy","Azure_ApplicationProxy_Config_Enable_HTTPOnly_Cookie","HTTP-Only cookie must be enabled while configuring App Proxy wherever possible.","Important","No","No","Using an HTTP-Only cookie protects against cross site scripting (XSS) attacks by disallowing cookie access to client side scripts.","AAD Application Administrator (or higher privilege role) can check app cookie setting from portal or by running command 'Get-AzureADApplicationProxyApplication -ObjectId <AADAppID>'. To enable HTTP-Only cookie, run command 'Set-AzureADApplicationProxyApplication -ObjectId <AADAppID> -IsHttpOnlyCookieEnabled $true'. Refer: https://docs.microsoft.com/en-us/azure/active-directory/manage-apps/application-proxy-publish-azure-portal#publish-an-on-premises-app-for-remote-access.","No","No","SDL, TCP, Manual, Config, ApplicationProxy"
"ApplicationProxy","Azure_ApplicationProxy_SI_Lockdown_ConnectorMachine","Use a security hardened, locked down OS image for the connector machine.","Important","No","No","The connector machine is serving as a 'gateway' into the corporate environment allowing internet based client endpoints access to enterprise data. Using a locked-down, secure baseline configuration ensures that this machine does not get leveraged as an entry point to attack the applications/corporate network.","Use a locked down OS configuration. Ensure that the system is always fully patched, has real-time malware protection enabled, OS firewall and disk encryption turned on, etc. Also, monitor this VM just like you'd monitor a high-value asset.","No","No","SDL, TCP, Manual, Config, ApplicationProxy"
"NotificationHub","Azure_NotificationHub_Deploy_Use_ARM_Model","Notification Hub must be created through Azure Resource Manager model","Important","No","No","The new ARM/v2 model must be used to create Notification Hub as the ARM model provides stronger access control (RBAC) and auditing features.","Notification hub must not be created on azure classic portal.You need to clean up any unexpected 'Notification hubs' present on the subscription. (1) Steps to clean up notification hubs through Azure portal - (a) Logon to https://portal.azure.com/ (b) Navigate to the 'Notification Hubs' (c) Navigate to the notification hub that has be removed and click on the 'Delete' icon. (d) Perform this operation for all the notification hubs that has to be removed from the subscription. (2) Steps to clean up notification hub through command - Run the command 'Remove-AzNotificationHub [-ResourceGroup] <String>  [-Namespace] <String> [-NotificationHub] <String> [-Confirm] [-Force] [-WhatIf] [<CommonParameters>]'","No","No","SDL, TCP, Manual, Deploy, NotificationHub"
"NotificationHub","Azure_NotificationHub_AuthZ_Grant_Min_RBAC_Access","All users/identities must be granted minimum required permissions using Role Based Access Control (RBAC)","Moderate","No","No","Granting minimum access by leveraging RBAC feature ensures that users are granted just enough permissions to perform their tasks. This minimizes exposure of the resources in case of user/service account compromise.","Remove any excessive privileges granted on the Notification hubs. Run command: Remove-AzRoleAssignment -SignInName '<SignInName>' -Scope '<Scope>' RoleDefinitionName '<RoleDefinitionName>'. Run 'Get-Help Remove-AzRoleAssignment -full' for more help.","Yes","No","SDL, TCP, Automated, AuthZ, RBAC, NotificationHub"
"NotificationHub","Azure_NotificationHub_AuthZ_Dont_Use_Policies_At_NotificationHub_Namespace","Applications must not use 'namespace' level access policies for the Notification Hub","Important","No","No","A 'namespace' level access policy provides access to all Notification Hubs in a namespace. However, using an access policy at Notification Hub level provides access only to the specific Notification Hub. Thus using the latter is inline with the principle of least privilege.","Create access policies for the respective Notification Hub representing the least access required and use them. Refer: https://docs.microsoft.com/en-us/azure/notification-hubs/notification-hubs-push-notification-security","No","No","SDL, TCP, Manual, AuthZ, NotificationHub"
"NotificationHub","Azure_NotificationHub_AuthZ_Use_Min_Permissions_Access_Policies","Access policies must be defined with minimum required permissions at Notification Hub level","Moderate","No","No","Granting minimum access ensures that users are granted just enough permissions to perform their tasks. This minimizes the set of operations that can be preformed on the resource by an attacker in case of access policy key compromise.","Ensure that policy definitions capture least required operations. E.g., if only 'Send' is necessary then 'Listen' should not be in the permission set. Refer for example of creation of policies for user https://docs.microsoft.com/en-us/azure/notification-hubs/notification-hubs-aspnet-backend-windows-dotnet-wns-notification","No","No","SDL, TCP, Manual, AuthZ, NotificationHub"
"NotificationHub","Azure_NotificationHub_AuthZ_Dont_Use_Manage_Access_Permission","Access policies on Notification Hub must not have Manage access permissions","Important","No","Yes","Manage security claim has the highest level of access (Create/Update/Read/Delete/Read registrations by tag) on Notification Hub. Using this key for runtime scenarios violates the principle of least privileged access. It is akin to running as 'sa' or 'localsystem'.","Use 'Send' and 'Listen' manage policies as access permissions for clients and back ends. Refer: https://docs.microsoft.com/en-us/azure/notification-hubs/notification-hubs-push-notification-security","Yes","No","SDL, TCP, Automated, AuthZ, NotificationHub"
"NotificationHub","Azure_NotificationHub_Deploy_Reg_Mngt_Not_From_Native_Device_App","Registration management must not be done from a native client or device app","Moderate","No","No","It is not possible to adequately authenticate/authorize registration requests if done directly from the native device app.","Registration management should be done through application backend. Refer: https://docs.microsoft.com/en-us/azure/notification-hubs/notification-hubs-push-notification-registration-management","No","No","SDL, TCP, Manual, Deploy, NotificationHub"
"NotificationHub","Azure_NotificationHub_DP_Msg_Body_Not_Contain_Sensitive_Data","Message body of a push notification must not contain sensitive data","Important","No","No","Due to risks of exposure along the path between the backend service and the client device, notifications should not include any sensitive data in the body of the push message.","Use the Secure Push pattern if there is a need to send senstive data. Refer: https://docs.microsoft.com/en-us/azure/notification-hubs/notification-hubs-aspnet-backend-windows-dotnet-wns-secure-push-notification","No","No","SDL, TCP, Manual, DP, SecIntell, NotificationHub"
"NotificationHub","Azure_NotificationHub_AuthZ_Limit_App_Team_Access","Developers of applications that use Notification Hubs must not be granted persistent access on the subscription","Moderate","No","No","Telemetry data can be accessed using Azure Service Management portal which will need subscription co-administrator permission. This can impose operational risk. Hence a user must not be granted persistent access on the subscription for such a scenario.","Remove any persistent access granted to app team members from the Azure portal.","No","No","SDL, TCP, Manual, AuthZ, NotificationHub"
"NotificationHub","Azure_NotificationHub_Audit_Enable_Logging_And_Monitoring","Audit logs for Notification Hub should be enabled","Moderate","No","No","Auditing enables log collection of important system events pertinent to security. Regular monitoring of audit logs can help to detect any suspicious and malicious activity early and respond in a timely manner.","Default behavior. No action needed.","No","No","SDL, Information, Manual, Audit, NotificationHub"
"NotificationHub","Azure_NotificationHub_BCDR_Plan","Backup and Disaster Recovery must be planned for Notification Hub","Moderate","No","No","Notification Hub does not offer features to cover backup/disaster recovery out-of-the-box. As a result, Notification Hub , a team must have adequate backups of the data.","Azure provides metadata disaster recovery coverage (the Notification Hub name, connection string, etc.). From a BC-DR standpoint, app teams must implement a solution to repopulate the Registration Data data into your new hub post-recovery. Refer: https://docs.microsoft.com/en-us/azure/notification-hubs/notification-hubs-push-notification-faq#what-support-is-provided-for-disaster-recovery","No","No","SDL, Manual, BCDR, NotificationHub"
"ERvNet","Azure_ERvNet_NetSec_Dont_Use_PublicIPs","There must not be any Public IPs (i.e., NICs with PublicIP) on ExpressRoute-connected VMs","Important","Yes","No","Public IP addresses on an ER-connected virtual network can expose the corporate network to security attacks from the internet.","Any Public IP addresses you added to an ER-connected virtual network must be removed. Refer: https://docs.microsoft.com/en-us/powershell/module/az.network/Remove-AzPublicIpAddress","Yes","No","SDL, TCP, Automated, NetSec, ERvNet"
"ERvNet","Azure_ERvNet_NetSec_Dont_Use_Multi_NIC_VMs","There must not be multiple NICs on ExpressRoute-connected VMs","Moderate","No","No","Using multiple NICs, one can route traffic between the ER-connected virtual network and another non-ER-connected virtual network. This can put the corporate network at risk. (Multi-NIC VMs on an ER-connected virtual network may be required in some advanced scenarios. You should engage the network security team for a review in such cases.)","Remove any additional NICs on VMs which are on an ER-connected virtual network. Refer: http://stackoverflow.com/questions/34526032/how-can-i-programmatically-detach-a-nic-from-its-vm-in-azure-arm","Yes","No","SDL, TCP, Automated, NetSec, ERvNet"
"ERvNet","Azure_ERvNet_NetSec_Dont_Enable_IPForwarding_for_NICs","The 'EnableIPForwarding' flag must not be set to true for NICs in the ExpressRoute-connected vNet","Important","Yes","No","Using IP Forwarding one can change the routing of packets from an ER-connected virtual network. This can lead to bypass of network protections that are required and applicable for corpnet traffic. (IP Forwarding on an ER-connected virtual network may be required only in advanced scenarios such as Network Virtual Applicances. You should engage the network security team for a review in such cases.)","IP Forwarding must be disabled on ExpressRoute-connected NICs. Refer: https://docs.microsoft.com/en-us/azure/virtual-network/virtual-networks-udr-overview","Yes","No","SDL, TCP, Automated, NetSec, ERvNet"
"ERvNet","Azure_ERvNet_NetSec_Dont_Use_NSGs_on_GatewaySubnet","There must not be any NSGs on the GatewaySubnet of the ExpressRoute-connected vNet","Moderate","No","No","Using NSGs on the Gateway subnet of an ER-connected virtual network can cause the connection to stop functioning and may impact availability.","If you added any NSGs to the Gateway Subnet of the ER-connected virtual network, remove them. Refer: https://docs.microsoft.com/en-us/azure/virtual-network/manage-network-security-group#delete-a-network-security-group","Yes","No","SDL, TCP, Automated, NetSec, ERvNet"
"ERvNet","Azure_ERvNet_NetSec_Dont_Add_UDRs_on_Subnets","There must not be a UDR on *any* subnet in an ExpressRoute-connected vNet","Important","Yes","No","Using UDRs on any subnet of an ER-connected virtual network can lead to security exposure for corpnet traffic by allowing it to be routed in a way that evades inspection from network security scanners.","Remove association between any UDRs you may have added and respective subnets using the 'Remove-AzureSubnetRouteTable' command. Run 'Get-Help Remove-AzureSubnetRouteTable -full' for more help.","Yes","No","SDL, TCP, Automated, NetSec, ERvNet"
"ERvNet","Azure_ERvNet_NetSec_Dont_Add_VPN_Gateways","There must not be another virtual network gateway (GatewayType = Vpn) in an ExpressRoute-connected vNet","Important","Yes","No","Using other gateway types on an ER-connected virtual network can lead to pathways for corpnet traffic where the traffic can get exposed to the internet or evade inspection from network security scanners. This creates a direct risk to corpnet security.","Remove any VPN Gateways from the ExpressRoute-connected virtual network. Refer: https://docs.microsoft.com/en-us/azure/vpn-gateway/vpn-gateway-delete-vnet-gateway-powershell","Yes","No","SDL, TCP, Automated, NetSec, ERvNet"
"ERvNet","Azure_ERvNet_NetSec_Dont_Use_VNet_Peerings","There must not be any virtual network peerings on an ExpressRoute-connected vNet","Important","Yes","No","A virtual network peering on an ER-connected circuit establishes a link to another virtual network whereby traffic egress and ingress can evade inspection from network security appliances. This creates a direct risk to corpnet security.","Remove any VNet peering you added using the 'Remove-AzVirtualNetworkPeering' PS command. Run 'Get-Help Remove-AzVirtualNetworkPeering -full' for more help.","Yes","No","SDL, TCP, Automated, NetSec, ERvNet"
"ERvNet","Azure_ERvNet_NetSec_Use_Only_Internal_Load_Balancers","Only internal load balancers (ILBs) may be used inside an ExpressRoute-connected vNet","Important","Yes","No","External load balancers on an ER-connected vNet can expose the corporate network to security attacks from the internet.","Remove any external load balancers you may have added using the 'Remove-AzLoadBalancer' PS command. Run 'Get-Help Remove-AzLoadBalancer -full' for more help.","Yes","No","SDL, TCP, Automated, NetSec, ERvNet"
"ERvNet","Azure_ERvNet_SI_Add_Only_Network_Resources","Only resources of type Microsoft.Network/* must be added in the ERNetwork resource group","Important","No","Yes","The ERNetwork resource group is a critical component that facilitates provisioning of an ER-connection for your subscription. This resource group is deployed and managed by the networking team and should not be used as a general purpose resource group or as a container for non-networking resources as it can impact the ER-connectivity of your subscription.","Move all other resources except Microsoft.Network/* to another resource group. To move a resource, simply go to the Overview tab for it in the Azure portal and select the Move option.","Yes","No","SDL, TCP, Automated, SI, ERvNet, CSE"
"ERvNet","Azure_ERvNet_SI_Dont_Remove_Resource_Lock","Ensure that the ERNetwork resource group is protected with a resource lock","Important","No","Yes","The ERNetwork resource group is a critical component that facilitates provisioning of an ER-connection for your subscription. A resource lock is deployed on the ERNetwork resource group to keep you from deleting it accidentally. Removing this lock increases the chances of accidental write/delete of this resource group and that can impact ER-connectivity of your subscription.","Create a ReadOnly resource lock for every ER Network resource group using command New-AzResourceLock -LockName '{LockName}' -LockLevel 'ReadOnly' -Scope '/subscriptions/{SubscriptionId}/resourceGroups/{ERNetworkResourceGroup}'. Run 'Get-Help New-AzResourceLock -full' for more help.","Yes","No","SDL, TCP, Automated, SI, ERvNet, CSE"
"ERvNet","Azure_ERvNet_SI_Dont_Remove_ARM_Policy","Ensure that ARM policies are deployed to protect the ERNetwork setup","Important","No","Yes","The ERNetwork resource group is a critical component that facilitates provisioning of an ER-connection for your subscription. This is a protective policy deployed to keep you from creating any network endpoint which can accidentally expose organization network.","ARM policy deployed during ER setup was removed. You need to set it up again. Review the docs on https://aka.ms/devopskit/recomm/ervnet","Yes","No","SDL, TCP, Automated, SI, ERvNet, CSE"
"KubernetesService","Azure_KubernetesService_Deploy_Enable_Cluster_RBAC","Cluster RBAC must be enabled in Kubernetes Service","Important","No","Yes","Enabling RBAC in a cluster lets you finely control access to various operations at the cluster/node/pod/namespace scopes for different stakeholders. Without RBAC enabled, every user has full access to the cluster which is a violation of the principle of least privilege. Note that Azure Kubernetes Service does not currently support other mechanisms to define authorization in Kubernetes (such as Attribute-based Access Control authorization or Node authorization).","RBAC flag must be enabled while creating the Kubernetes Service. Existing non-RBAC enabled Kubernetes Service clusters cannot currently be updated for RBAC use. Refer: https://docs.microsoft.com/en-us/azure/aks/aad-integration.","Yes","No","SDL, TCP, Automated, Deploy, RBAC, KubernetesService"
"KubernetesService","Azure_KubernetesService_AuthN_Enabled_AAD","AAD should be enabled in Kubernetes Service","Important","No","Yes","Using the native enterprise directory for authentication ensures that there is a built-in high level of assurance in the user identity established for subsequent access control.All Enterprise subscriptions are automatically associated with their enterprise directory (xxx.onmicrosoft.com) and users in the native directory are trusted for authentication to enterprise subscriptions.","Refer: https://docs.microsoft.com/en-us/azure/aks/aad-integration to configure AAD in Kubernetes Service.","Yes","No","SDL, Best Practice, Automated, AuthN, KubernetesService"
"KubernetesService","Azure_KubernetesService_AuthZ_Grant_Min_RBAC_Access","All users/identities must be granted minimum required permissions using Role Based Access Control (RBAC)","Moderate","No","No","Granting minimum access by leveraging RBAC feature ensures that users are granted just enough permissions to perform their tasks. This minimizes exposure of the resources in case of user/service account compromise.","Remove any excessive privileges granted on the Kubernetes Service. Run command: Remove-AzRoleAssignment -SignInName '<SignInName>' -Scope '<Scope>' RoleDefinitionName '<RoleDefinitionName>'. Run 'Get-Help Remove-AzRoleAssignment -full' for more help.","Yes","No","SDL, TCP, Automated, AuthZ, RBAC, KubernetesService"
"KubernetesService","Azure_KubernetesService_AuthN_Dont_Grant_ClusterAdmin_Permission_Developer","Do not directly or indirectly grant cluster admin level access to developers","Important","No","No","Cluster admin have full privileges to perform critical operations on Kubernetes cluster. Granting minimum required access ensures that developer are granted just enough permissions to perform their tasks.","Developer should be assigned 'Azure Kubernetes Service Cluster User Role' to Kubernetes Service. If you modify an existing role or create a custom role, be careful about operations that are granted to a developer. For example, if a developer can run the 'List clusterAdmin credential' operation, they can elevate access to cluster admin level.","No","No","SDL, TCP, Manual, AuthN, KubernetesService"
"KubernetesService","Azure_KubernetesService_Deploy_Use_Latest_Version","The latest version of Kubernetes should be used","Moderate","No","No","Running on older versions could mean you are not using latest security classes. Usage of such old classes and types can make your application vulnerable.","Refer: https://docs.microsoft.com/en-us/azure/aks/upgrade-cluster.","Yes","No","SDL, Best Practice, Automated, Deploy, KubernetesService"
"KubernetesService","Azure_KubernetesService_DP_Review_Image_Sources","Make sure container images (including nested images) deployed in Kubernetes are from a trustworthy source","Important","No","No","If a Kubernetes Service runs an untrusted container image (or an untrusted nested image), it can violate integrity of the infrastructure and lead to all types of security attacks.","Ensure that the source(s) for the container images comprising the Kubernetes Service are trustworthy. Review the repository locations specified in the YAML files for your environment and confirm that those locations will not have tampered/insecure images.","No","No","SDL, TCP, Manual, DP, KubernetesService"
"KubernetesService","Azure_KubernetesService_SI_Dont_Use_Default_Namespace","Do not use the default cluster namespace to deploy applications","Moderate","No","No","Resources/Applications in same namespace will have same access control (RBAC) policies. Users are granted permission on default namespace if no other namespace is provided in rolebindings. As a result, the permissions in the default namespace might not be appropriate if your application/workload is sensitive. It is hence better to create a separate namespace.","Ensure that the applications in Kubernetes are not deployed in default namespace.","No","No","SDL, TCP, Manual, SI, KubernetesService"
"KubernetesService","Azure_KubernetesService_DP_Store_Secrets_in_Key_Vault","All Kubernetes Service secrets should be stored in Key Vault","Moderate","No","No","Keeping secrets such as DB connection strings, passwords, keys, etc. in clear text can lead to easy compromise at various avenues during an application's lifecycle. Storing them in a key vault ensures that they are protected at rest.","Refer: https://github.com/Azure/kubernetes-keyvault-flexvol for configuring Key Vault and storing secrets.","No","No","SDL, TCP, Manual, AuthZ, DP, KubernetesService"
"KubernetesService","Azure_KubernetesService_SI_Cluster_Node_Missing_OS_Patches","All the Kubernetes cluster nodes must have all the required OS patches installed","Moderate","No","No","Unpatched cluster nodes (VMs) are easy targets for compromise from various malware/trojan attacks that exploit known vulnerabilities in operating systems and related software.","Refer: https://github.com/weaveworks/kured for install patch and reboot management without impacting Kubernetes workloads.","No","No","SDL, TCP, Manual, SI, KubernetesService"
"KubernetesService","Azure_KubernetesService_AuthN_Use_POD_Identity","Pod Identity must be used for accessing other AAD-protected resources from the Kubernetes Service.","Moderate","No","No","Pod Identity allows your Kubernetes Service to easily access other AAD-protected resources such as Azure Key Vault. The identity is managed by the Azure platform and eliminates the need to provision/manage/rotate any secrets thus reducing the overall risk.","Refer: https://github.com/Azure/aad-pod-identity to configure Pod Identity in your Kubernetes Cluster.","No","No","SDL, TCP, Manual, AuthN, KubernetesService"
"KubernetesService","Azure_KubernetesService_SI_Review_Kube_Advisor_Issues","Issues/recommendations provided by kube advisor should be reviewed periodically","Moderate","No","No","The kube-advisor tool scans Kubernets cluster and reports on issues related to CPU and memory resource consumption limits. If resource quotas are not applied then by default pod consumes all the CPU and memory available, which impacts availability of another POD/application.","Refer: https://github.com/Azure/kube-advisor to scan Kubernetes cluster using Kube Advisor.","No","No","SDL, Best Practice, Manual, SI, KubernetesService"
"KubernetesService","Azure_KubernetesService_Audit_Enable_Monitoring","Monitoring must be enabled for Azure Kubernetes Service","Moderate","No","No","Auditing enables log collection of important system events pertinent to security. Regular monitoring of audit logs can help to detect any suspicious and malicious activity early and respond in a timely manner.","Refer: https://docs.microsoft.com/en-us/azure/azure-monitor/insights/container-insights-overview.","Yes","No","SDL, TCP, Automated, Audit, KubernetesService"
"KubernetesService","Azure_KubernetesService_NetSec_Dont_Open_Management_Ports","Do not leave management ports open on Kubernetes nodes unless required","Moderate","No","No","Open remote management ports expose a VM/compute node to a high level of risk from internet-based attacks that attempt to brute force credentials to gain admin access to the machine.","Go to Azure Portal --> VM Settings --> Networking --> Inbound security rules --> Select security rule which allows management ports (e.g. RDP-3389, WINRM-5985, SSH-22) --> Click 'Deny' under Action --> Click Save.","Yes","No","SDL, TCP, Manual, NetSec, KubernetesService"
"KubernetesService","Azure_KubernetesService_DP_Encrypt_Data_In_Transit","Data transit inside/across Kubernetes must use encrypted channel","Important","No","No","Use of HTTPS ensures server/service authentication and protects data in transit from network layer man-in-the-middle, eavesdropping, session-hijacking attacks.","Refer: https://docs.microsoft.com/en-us/azure/aks/ingress-tls.","No","No","SDL, TCP, Manual, DP, KubernetesService"
"KubernetesService","Azure_KubernetesService_Audit_Enable_Diagnostics_Log","Diagnostics logs must be enabled with a retention period of at least 365 days.","Moderate","No","No","Logs should be retained for a long enough period so that activity trail can be recreated when investigations are required in the event of an incident or a compromise. A period of 1 year is typical for several compliance requirements as well.","You can change the diagnostic settings from the Azure Portal by following the steps given here: https://docs.microsoft.com/en-us/azure/monitoring-and-diagnostics/monitoring-archive-diagnostic-logs#archive-diagnostic-logs-using-the-portal.","Yes","No","SDL, TCP, Automated, Audit, Diagnostics, KubernetesService"
"ContainerInstances","Azure_ContainerInstances_NetSec_Justify_PublicIP_and_Ports","Use of public IP address and ports should be carefully reviewed","Important","No","No","Public IP address provides direct access over the internet exposing the container to all type of attacks over the public network.","Add public IP address and ports to a container only as required. Ensure that the resulting data flows are carefully reviewed.","Yes","No","SDL, TCP, Automated, NetSec, ContainerInstances"
"ContainerInstances","Azure_ContainerInstances_SI_Review_Image","Make sure container images (including nested images) are from a trustworthy source","Important","No","No","If a container runs an untrusted image (or an untrusted nested image), it can violate integrity of the infrastructure and lead to all types of security attacks.","Ensure that the image source(s) for the image comprising the container are trustworthy. Review image configurations carefully for any misconfigurations.","Yes","No","SDL, TCP, Automated, SI, ContainerInstances"
"ContainerInstances","Azure_ContainerInstances_DP_Review_Registry","Make sure container images are hosted on a trustworthy registry that has strong authentication, authorization and data protection mechanisms","Important","No","No","If a container image is served from an untrusted registry, the image itself may not be trustworthy. Running such a compromised image can lead to loss of sensitive enterprise data.","Ensure that the registry, which hosts the image, is trustworthy. Review registry configurations carefully for any misconfigurations related to authentication, authorization, etc. ","Yes","No","SDL, TCP, Automated, DP, ContainerInstances"
"ContainerInstances","Azure_ContainerInstances_AuthZ_Container_Segregation","A container group must contain only containers which trust each other","Important","No","Yes","Containers hosted in the same container group can monitor traffic of other containers within the group and can also access the file system of the host OS. Hence a container group must not host containers which do not trust each other. In other words, do not mix containers across trust boundaries in the same group.","Carefully review the role and privileges required by each container in a container group. If the privilege levels and access requirements are different, then consider segregating the containers into separate groups.","Yes","No","SDL, TCP, Automated, AuthZ, ContainerInstances"
"BotService","Azure_BotService_Enable_Required_Channels_Only","Only specific/required channels must be configured to allow traffic to bot service.","Important","No","No","Each channel enabled for the Bot exposes the bot to activity on that channel. If a channel that is not actually required is enabled for the bot, it introduces unnecessary avenues for attack.","Verify the configured channels and to add more supported channels refer: https://docs.microsoft.com/en-us/azure/bot-service/bot-service-manage-channels?view=azure-bot-service-3.0","Yes","No","SDL, TCP, BotService"
"BotService","Azure_BotService_DP_Encrypt_At_Rest","Ensure to use own storage adapter instead of Bot Framework State Service API.","Important","No","No","Using this feature ensures that sensitive data is stored encrypted at rest. This minimizes the risk of data loss from physical theft and also helps meet regulatory compliance requirements.","Default behavior. No action required.","No","No","SDL, Information, Manual, BotService"
"BotService","Azure_BotService_DP_Protect_Secrets","Secrets in Bot Service must be handled properly.","Important","No","No","Keeping secrets such as passwords, keys, etc. in clear text can lead to easy compromise at various avenues during an application's lifecycle.","It is recommended to handle the secrets properly.","No","No","SDL, TCP, Manual, BotService"
"BotService","Azure_BotService_Audit_Enable_Monitoring","Make sure important activities and events during Bot interactions are logged.","Moderate","No","No","Analytics can be useful to detect unusual usage behavior patterns.","Follow https://docs.microsoft.com/en-us/azure/bot-service/bot-service-manage-analytics?view=azure-bot-service-3.0 for configuring Application Insight with Bot Service.","Yes","No","SDL, TCP, BotService"
"BotService","Azure_BotService_DP_Dont_Allow_HTTP_Access","Bot Service API must only be accessible over HTTPS","Important","No","No","Use of HTTPS ensures server/service authentication and protects data in transit from network layer eavesdropping attacks.","Make Web App linked to Bot Service to use Https using command 'Set-AzResource -ResourceName '<WebAppName>' -ResourceGroupName '<RGName>' -ResourceType 'Microsoft.Web/sites' -Properties @{httpsOnly='true'} -Force '. Run 'Get-Help Set-AzResource -full' for more help.","No","No","SDL, TCP, Manual, BotService"
"ODG","Azure_ODG_Config_Lockdown_Server","ODG must be installed on a hardened locked down VM","Important","No","No","The ODG machine is serving as a 'gateway' into the corporate environment allowing endpoint in the cloud access to enteprise data. Using a locked-down, secure baseline configuration ensures that this machine does not get leveraged as an entry point to the downstream data server/service.","Locking down machine isolates ODG tool and prevents malfunctioning programs from damaging or snooping on the data source machine. ","No","No","SDL, TCP, Manual, Config, ODG"
"ODG","Azure_ODG_DP_Disabled_Additional_Log","Additional logging in diagnostics should be disabled","Low","No","No","Additional logs feature of ODG tool contains all the records/data that pass through the ODG. Those logs may contain customer's PII and other sensitive data.","Additional logs in ODG tool contains all the data passing through ODG. If its required to enable additional logs than keep/share the logs in encrypted format.","No","No","SDL, Best Practice, Manual, DP, ODG"
"ODG","Azure_ODG_ACL_DataSource_Privacy","Privacy level setting must be configured to private while using ODG in PowerBI.","Important","No","No","Granting minimum permission ensures that users are granted just enough permissions to perform their tasks. This minimizes exposure of the resources in case of user/service account compromise.","With privacy level settings, user can specify an isolation level that defines the degree that one data source must be isolated from other data sources. Refer: https://support.office.com/en-us/article/Privacy-levels-Power-Query-CC3EDE4D-359E-4B28-BC72-9BEE7900B540?ui=en-US&rs=en-US&ad=US","No","No","SDL, TCP, Manual, ACL, ODG"
"ODG","Azure_ODG_ACL_Least_Permission_While_Sharing","Must use the least required permission based on scenario while sharing gateways through PowerApps/Flow","Important","No","No","Granting minimum permission ensures that users are granted just enough permissions to perform their tasks. This minimizes exposure of the resources in case of user/service account compromise.","Any one from these permissions must be provided while sharing gateways through PowerApps. Can use - Can use the gateway to use and create apps and flows. Can use + share - Can use the gateway to use and create apps and flows, and can share the gateway for others to use. Admin - Manages the gateway, can use the gateway to create apps and flows, can share the gateway with users tenant wide, can specify the type of connections that can be used with the gateway, and can delete the gateway. Refer: https://powerapps.microsoft.com/en-us/tutorials/share-app-resources/#on-premises-data-gateways","No","No","SDL, TCP, Manual, ACL, ODG"
"ODG","Azure_ODG_BCDR_Design_Failover_Plan","Failover plan should be designed as per business requirements.","Moderate","No","No","ODG service does not offer features to cover backup/disaster recovery out-of-the-box. As a result, when processing critical workloads, a team must have adequate backups of the data.","Out of the box no failover support is provided with ODG. So custom failover plan should be designed (e.g. To minimize the response time, ODG should be setup on another machine from where data source is accessible.)","No","No","SDL, TCP, Manual, BCDR, ODG"
"ODG","Azure_ODG_AuthZ_Grant_Min_Access","User accounts/roles connecting to data source must have minimum required permissions","Moderate","No","No","Granting minimum access ensures that users are granted just enough permissions to perform their tasks. This minimizes exposure of the resources in case of user/service account compromise.","All user accounts/roles which are involved in ODG must have minimum required access rights to data source. (e.g. If Gateway is fetching data from data source then user role must have read-only access.)","No","No","SDL, TCP, Manual, AuthZ, ODG"
"CDN","Azure_CDN_AuthZ_Grant_Min_RBAC_Access","All users/identities must be granted minimum required permissions using Role Based Access Control (RBAC)","Moderate","No","No","Granting minimum access by leveraging RBAC feature ensures that users are granted just enough permissions to perform their tasks. This minimizes exposure of the resources in case of user/service account compromise.","Remove any excessive privileges granted on the CDN. Run command Remove-AzRoleAssignment -SignInName '{signInName}' -Scope '{scope}' -RoleDefinitionName '{role definition name}'. Run 'Get-Help Remove-AzRoleAssignment -full' for more help.","Yes","No","SDL, TCP, Automated, AuthZ, RBAC"
"CDN","Azure_CDN_AuthN_Config_Token_AuthN","CDN profile endpoints must use token authentication","Moderate","No","No","Using token authentication prevents Azure CDN from serving assets to unauthorized clients. This keeps other sites from 'hotlinking' content and using your assets without permission","To enable token authentication (currently available on Premium Verizon tier), go to Azure Portal --> your CDN Profile --> Manage --> HTTP LARGE --> Token Auth. Please refer https://docs.microsoft.com/en-us/azure/cdn/cdn-token-auth for more details on token authentication.","No","No","SDL, Best Practice, Manual, AuthN"
"CDN","Azure_CDN_DP_TokenKey_Protection","Token encryption key must be protected in a key vault (when a website generates tokens via code).","Important","No","No","Keeping secrets such as DB connection strings, passwords, keys, etc. in clear text can lead to easy compromise at various avenues during an application's lifecycle. Storing them in a key vault ensures that they are protected at rest.","Refer https://azure.microsoft.com/en-in/documentation/articles/key-vault-get-started/ (Key Vault) and  https://docs.microsoft.com/en-us/azure/cdn/cdn-token-auth (token-based authentication in CDN).","No","No","SDL, TCP, Manual, DP"
"CDN","Azure_CDN_DP_Enable_Https","CDN endpoints must use HTTPS protocol while providing data to the client browser/machine or while fetching data from the origin server","Important","Yes","No","Use of HTTPS ensures server/service authentication and protects data in transit from network layer man-in-the-middle, eavesdropping, session-hijacking attacks.","To enable HTTPS protocol: Go to Azure Portal --> your CDN Profile --> your CDN Endpoint --> Origin --> Select HTTPS --> Save. Else implement through PowerShell as follows: $ce= Get-AzCdnEndpoint -EndpointName <EndpointName> ?ProfileName <CDNprofile> -ResourceGroupName <RGName>; $ce.IsHttpAllowed =$false; $ce.IsHttpsAllowed =$true; Set-AzCdnEndpoint -CdnEndpoint $ce","Yes","Yes","SDL, TCP, Automated, DP"
"CDN","Azure_CDN_DP_Use_Only_For_Public_Data","Do not put any sensitive data in a CDN. CDN is suitable only for resources where anonymous access is not a concern","Important","No","No","Azure CDN does not provide any access control feature to restrict/secure access to content. Thus no private data should be stored in CDN.","Refer: https://docs.microsoft.com/en-gb/azure/architecture/best-practices/cdn.","No","No","SDL, Best Practice, Manual, DP"
"CDN","Azure_CDN_Audit_Configure_Real_Time_Alerts","Configure real time alerts on status code 403 to be observant of any unauthorized request for CDN endpoint","Moderate","No","No","Setting up real-time alerts provides real-time notifications about the performance of the endpoints and any unauthorized request in your CDN profile.","To set up alerts: Go to Azure Portal --> your CDN Profile --> Manage --> Analytics --> Real-Time Stats --> Real-Time Alerts.","No","No","SDL, TCP, Manual, Audit"
